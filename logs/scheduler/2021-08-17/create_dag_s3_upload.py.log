[2021-08-17 16:04:14,490] {scheduler_job.py:182} INFO - Started process (PID=25) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:04:14,502] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 16:04:14,504] {logging_mixin.py:104} INFO - [2021-08-17 16:04:14,504] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:04:17,714] {logging_mixin.py:104} INFO - [2021-08-17 16:04:17,685] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 16:04:17,729] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:04:17,759] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 3.281 seconds
[2021-08-17 16:04:48,701] {scheduler_job.py:182} INFO - Started process (PID=92) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:04:48,703] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 16:04:48,705] {logging_mixin.py:104} INFO - [2021-08-17 16:04:48,705] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:04:49,522] {logging_mixin.py:104} INFO - [2021-08-17 16:04:49,518] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 16:04:49,527] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:04:49,549] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.854 seconds
[2021-08-17 16:05:19,720] {scheduler_job.py:182} INFO - Started process (PID=157) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:05:19,721] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 16:05:19,722] {logging_mixin.py:104} INFO - [2021-08-17 16:05:19,722] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:05:20,929] {logging_mixin.py:104} INFO - [2021-08-17 16:05:20,926] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 16:05:20,932] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:05:20,961] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 1.243 seconds
[2021-08-17 16:05:51,427] {scheduler_job.py:182} INFO - Started process (PID=224) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:05:51,428] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 16:05:51,428] {logging_mixin.py:104} INFO - [2021-08-17 16:05:51,428] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:05:52,049] {logging_mixin.py:104} INFO - [2021-08-17 16:05:52,047] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 16:05:52,053] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:05:52,063] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.638 seconds
[2021-08-17 16:06:22,173] {scheduler_job.py:182} INFO - Started process (PID=291) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:06:22,176] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 16:06:22,178] {logging_mixin.py:104} INFO - [2021-08-17 16:06:22,178] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:06:22,921] {logging_mixin.py:104} INFO - [2021-08-17 16:06:22,918] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 16:06:22,924] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:06:22,935] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.764 seconds
[2021-08-17 16:06:53,031] {scheduler_job.py:182} INFO - Started process (PID=351) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:06:53,032] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 16:06:53,033] {logging_mixin.py:104} INFO - [2021-08-17 16:06:53,033] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:06:53,594] {logging_mixin.py:104} INFO - [2021-08-17 16:06:53,590] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 16:06:53,597] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:06:53,610] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.581 seconds
[2021-08-17 16:07:23,648] {scheduler_job.py:182} INFO - Started process (PID=422) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:07:23,651] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 16:07:23,653] {logging_mixin.py:104} INFO - [2021-08-17 16:07:23,652] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:07:24,167] {logging_mixin.py:104} INFO - [2021-08-17 16:07:24,165] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 16:07:24,170] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:07:24,181] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.536 seconds
[2021-08-17 16:07:54,888] {scheduler_job.py:182} INFO - Started process (PID=486) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:07:54,889] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 16:07:54,889] {logging_mixin.py:104} INFO - [2021-08-17 16:07:54,889] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:07:55,387] {logging_mixin.py:104} INFO - [2021-08-17 16:07:55,384] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 16:07:55,390] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:07:55,401] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.515 seconds
[2021-08-17 16:08:26,035] {scheduler_job.py:182} INFO - Started process (PID=550) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:08:26,036] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 16:08:26,037] {logging_mixin.py:104} INFO - [2021-08-17 16:08:26,037] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:08:26,529] {logging_mixin.py:104} INFO - [2021-08-17 16:08:26,527] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 16:08:26,532] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:08:26,544] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.510 seconds
[2021-08-17 16:08:57,183] {scheduler_job.py:182} INFO - Started process (PID=615) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:08:57,184] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 16:08:57,185] {logging_mixin.py:104} INFO - [2021-08-17 16:08:57,185] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:08:57,690] {logging_mixin.py:104} INFO - [2021-08-17 16:08:57,688] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 16:08:57,693] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:08:57,705] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.524 seconds
[2021-08-17 16:09:28,402] {scheduler_job.py:182} INFO - Started process (PID=678) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:09:28,403] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 16:09:28,404] {logging_mixin.py:104} INFO - [2021-08-17 16:09:28,404] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:09:28,911] {logging_mixin.py:104} INFO - [2021-08-17 16:09:28,908] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 16:09:28,914] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:09:28,925] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.525 seconds
[2021-08-17 16:09:59,791] {scheduler_job.py:182} INFO - Started process (PID=744) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:09:59,792] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 16:09:59,793] {logging_mixin.py:104} INFO - [2021-08-17 16:09:59,793] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:10:00,351] {logging_mixin.py:104} INFO - [2021-08-17 16:10:00,348] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 16:10:00,355] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:10:00,369] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.579 seconds
[2021-08-17 16:10:30,874] {scheduler_job.py:182} INFO - Started process (PID=808) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:10:30,874] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 16:10:30,875] {logging_mixin.py:104} INFO - [2021-08-17 16:10:30,875] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:10:31,422] {logging_mixin.py:104} INFO - [2021-08-17 16:10:31,419] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 16:10:31,425] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:10:31,438] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.566 seconds
[2021-08-17 16:11:02,077] {scheduler_job.py:182} INFO - Started process (PID=872) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:11:02,078] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 16:11:02,078] {logging_mixin.py:104} INFO - [2021-08-17 16:11:02,078] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:11:02,640] {logging_mixin.py:104} INFO - [2021-08-17 16:11:02,634] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 16:11:02,643] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:11:02,662] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.587 seconds
[2021-08-17 16:11:33,264] {scheduler_job.py:182} INFO - Started process (PID=942) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:11:33,265] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 16:11:33,266] {logging_mixin.py:104} INFO - [2021-08-17 16:11:33,266] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:11:33,934] {logging_mixin.py:104} INFO - [2021-08-17 16:11:33,921] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 16:11:33,941] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:11:34,003] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.740 seconds
[2021-08-17 16:12:04,418] {scheduler_job.py:182} INFO - Started process (PID=1006) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:12:04,419] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 16:12:04,420] {logging_mixin.py:104} INFO - [2021-08-17 16:12:04,420] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:12:04,976] {logging_mixin.py:104} INFO - [2021-08-17 16:12:04,973] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 16:12:04,979] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:12:04,992] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.576 seconds
[2021-08-17 16:12:35,683] {scheduler_job.py:182} INFO - Started process (PID=1068) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:12:35,685] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 16:12:35,686] {logging_mixin.py:104} INFO - [2021-08-17 16:12:35,686] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:12:36,430] {logging_mixin.py:104} INFO - [2021-08-17 16:12:36,427] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 16:12:36,434] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:12:36,464] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.787 seconds
[2021-08-17 16:13:06,841] {scheduler_job.py:182} INFO - Started process (PID=1127) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:13:06,850] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 16:13:06,850] {logging_mixin.py:104} INFO - [2021-08-17 16:13:06,850] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:13:07,449] {logging_mixin.py:104} INFO - [2021-08-17 16:13:07,445] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 16:13:07,452] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:13:07,470] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.631 seconds
[2021-08-17 16:13:38,042] {scheduler_job.py:182} INFO - Started process (PID=1190) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:13:38,043] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 16:13:38,044] {logging_mixin.py:104} INFO - [2021-08-17 16:13:38,044] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:13:38,694] {logging_mixin.py:104} INFO - [2021-08-17 16:13:38,678] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 16:13:38,700] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:13:38,747] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.708 seconds
[2021-08-17 16:14:09,497] {scheduler_job.py:182} INFO - Started process (PID=1256) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:14:09,498] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 16:14:09,499] {logging_mixin.py:104} INFO - [2021-08-17 16:14:09,499] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:14:11,231] {logging_mixin.py:104} INFO - [2021-08-17 16:14:10,962] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 16:14:12,270] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:14:12,555] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 3.061 seconds
[2021-08-17 16:14:42,756] {scheduler_job.py:182} INFO - Started process (PID=1322) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:14:42,757] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 16:14:42,757] {logging_mixin.py:104} INFO - [2021-08-17 16:14:42,757] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:14:43,358] {logging_mixin.py:104} INFO - [2021-08-17 16:14:43,355] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 16:14:43,361] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:14:43,375] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.621 seconds
[2021-08-17 16:15:13,896] {scheduler_job.py:182} INFO - Started process (PID=1390) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:15:13,896] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 16:15:13,897] {logging_mixin.py:104} INFO - [2021-08-17 16:15:13,897] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:15:14,429] {logging_mixin.py:104} INFO - [2021-08-17 16:15:14,426] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 16:15:14,431] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:15:14,445] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.551 seconds
[2021-08-17 16:15:45,117] {scheduler_job.py:182} INFO - Started process (PID=1459) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:15:45,119] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 16:15:45,119] {logging_mixin.py:104} INFO - [2021-08-17 16:15:45,119] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:15:45,656] {logging_mixin.py:104} INFO - [2021-08-17 16:15:45,653] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 16:15:45,659] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:15:45,670] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.555 seconds
[2021-08-17 16:16:16,270] {scheduler_job.py:182} INFO - Started process (PID=1527) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:16:16,271] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 16:16:16,272] {logging_mixin.py:104} INFO - [2021-08-17 16:16:16,272] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:16:16,828] {logging_mixin.py:104} INFO - [2021-08-17 16:16:16,825] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 16:16:16,830] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:16:16,841] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.573 seconds
[2021-08-17 16:16:47,419] {scheduler_job.py:182} INFO - Started process (PID=1591) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:16:47,420] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 16:16:47,421] {logging_mixin.py:104} INFO - [2021-08-17 16:16:47,421] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:16:47,956] {logging_mixin.py:104} INFO - [2021-08-17 16:16:47,953] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 16:16:47,958] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:16:47,971] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.553 seconds
[2021-08-17 16:17:18,546] {scheduler_job.py:182} INFO - Started process (PID=1655) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:17:18,547] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 16:17:18,547] {logging_mixin.py:104} INFO - [2021-08-17 16:17:18,547] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:17:19,076] {logging_mixin.py:104} INFO - [2021-08-17 16:17:19,073] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 16:17:19,079] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:17:19,090] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.546 seconds
[2021-08-17 16:17:49,690] {scheduler_job.py:182} INFO - Started process (PID=1720) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:17:49,692] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 16:17:49,692] {logging_mixin.py:104} INFO - [2021-08-17 16:17:49,692] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:17:50,216] {logging_mixin.py:104} INFO - [2021-08-17 16:17:50,213] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 16:17:50,218] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:17:50,231] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.543 seconds
[2021-08-17 16:18:20,945] {scheduler_job.py:182} INFO - Started process (PID=1785) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:18:20,946] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 16:18:20,947] {logging_mixin.py:104} INFO - [2021-08-17 16:18:20,947] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:18:21,515] {logging_mixin.py:104} INFO - [2021-08-17 16:18:21,513] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 16:18:21,518] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:18:21,530] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.589 seconds
[2021-08-17 16:18:52,220] {scheduler_job.py:182} INFO - Started process (PID=1851) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:18:52,221] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 16:18:52,222] {logging_mixin.py:104} INFO - [2021-08-17 16:18:52,222] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:18:52,817] {logging_mixin.py:104} INFO - [2021-08-17 16:18:52,814] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 16:18:52,820] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:18:52,832] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.614 seconds
[2021-08-17 16:19:23,773] {scheduler_job.py:182} INFO - Started process (PID=1907) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:19:23,774] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 16:19:23,775] {logging_mixin.py:104} INFO - [2021-08-17 16:19:23,774] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:19:24,323] {logging_mixin.py:104} INFO - [2021-08-17 16:19:24,321] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 16:19:24,326] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:19:24,338] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.567 seconds
[2021-08-17 16:19:55,320] {scheduler_job.py:182} INFO - Started process (PID=1972) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:19:55,321] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 16:19:55,321] {logging_mixin.py:104} INFO - [2021-08-17 16:19:55,321] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:19:55,858] {logging_mixin.py:104} INFO - [2021-08-17 16:19:55,855] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 16:19:55,860] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:19:55,872] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.554 seconds
[2021-08-17 16:20:26,427] {scheduler_job.py:182} INFO - Started process (PID=2035) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:20:26,428] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 16:20:26,428] {logging_mixin.py:104} INFO - [2021-08-17 16:20:26,428] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:20:26,985] {logging_mixin.py:104} INFO - [2021-08-17 16:20:26,983] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 16:20:26,988] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:20:26,998] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.574 seconds
[2021-08-17 16:20:57,951] {scheduler_job.py:182} INFO - Started process (PID=2098) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:20:57,951] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 16:20:57,952] {logging_mixin.py:104} INFO - [2021-08-17 16:20:57,952] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:20:58,509] {logging_mixin.py:104} INFO - [2021-08-17 16:20:58,506] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 16:20:58,512] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:20:58,524] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.575 seconds
[2021-08-17 16:21:29,078] {scheduler_job.py:182} INFO - Started process (PID=2165) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:21:29,080] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 16:21:29,081] {logging_mixin.py:104} INFO - [2021-08-17 16:21:29,080] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:21:29,804] {logging_mixin.py:104} INFO - [2021-08-17 16:21:29,800] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 16:21:29,806] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:21:29,820] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.743 seconds
[2021-08-17 16:22:00,056] {scheduler_job.py:182} INFO - Started process (PID=2238) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:22:00,057] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 16:22:00,057] {logging_mixin.py:104} INFO - [2021-08-17 16:22:00,057] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:22:00,704] {logging_mixin.py:104} INFO - [2021-08-17 16:22:00,702] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 16:22:00,708] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:22:00,719] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.665 seconds
[2021-08-17 16:22:30,894] {scheduler_job.py:182} INFO - Started process (PID=2307) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:22:30,895] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 16:22:30,896] {logging_mixin.py:104} INFO - [2021-08-17 16:22:30,896] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:22:31,509] {logging_mixin.py:104} INFO - [2021-08-17 16:22:31,505] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 16:22:31,513] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:22:31,524] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.631 seconds
[2021-08-17 16:23:02,492] {scheduler_job.py:182} INFO - Started process (PID=2374) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:23:02,493] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 16:23:02,493] {logging_mixin.py:104} INFO - [2021-08-17 16:23:02,493] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:23:02,992] {logging_mixin.py:104} INFO - [2021-08-17 16:23:02,989] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 16:23:02,995] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:23:03,007] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.517 seconds
[2021-08-17 16:23:33,907] {scheduler_job.py:182} INFO - Started process (PID=2442) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:23:33,908] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 16:23:33,909] {logging_mixin.py:104} INFO - [2021-08-17 16:23:33,909] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:23:34,411] {logging_mixin.py:104} INFO - [2021-08-17 16:23:34,409] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 16:23:34,414] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:23:34,426] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.521 seconds
[2021-08-17 16:24:05,162] {scheduler_job.py:182} INFO - Started process (PID=2506) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:24:05,163] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 16:24:05,163] {logging_mixin.py:104} INFO - [2021-08-17 16:24:05,163] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:24:05,662] {logging_mixin.py:104} INFO - [2021-08-17 16:24:05,660] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 16:24:05,665] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:24:05,677] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.516 seconds
[2021-08-17 16:24:36,504] {scheduler_job.py:182} INFO - Started process (PID=2570) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:24:36,505] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 16:24:36,506] {logging_mixin.py:104} INFO - [2021-08-17 16:24:36,506] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:24:36,998] {logging_mixin.py:104} INFO - [2021-08-17 16:24:36,996] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 16:24:37,001] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:24:37,012] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.510 seconds
[2021-08-17 16:25:07,680] {scheduler_job.py:182} INFO - Started process (PID=2624) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:25:07,681] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 16:25:07,682] {logging_mixin.py:104} INFO - [2021-08-17 16:25:07,682] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:25:08,189] {logging_mixin.py:104} INFO - [2021-08-17 16:25:08,187] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 16:25:08,192] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:25:08,203] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.525 seconds
[2021-08-17 16:25:38,928] {scheduler_job.py:182} INFO - Started process (PID=2689) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:25:38,928] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 16:25:38,929] {logging_mixin.py:104} INFO - [2021-08-17 16:25:38,929] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:25:39,417] {logging_mixin.py:104} INFO - [2021-08-17 16:25:39,414] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 16:25:39,420] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:25:39,434] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.508 seconds
[2021-08-17 16:26:10,039] {scheduler_job.py:182} INFO - Started process (PID=2752) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:26:10,039] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 16:26:10,040] {logging_mixin.py:104} INFO - [2021-08-17 16:26:10,040] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:26:10,586] {logging_mixin.py:104} INFO - [2021-08-17 16:26:10,582] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 16:26:10,589] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:26:10,601] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.564 seconds
[2021-08-17 16:26:40,955] {scheduler_job.py:182} INFO - Started process (PID=2820) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:26:40,957] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 16:26:40,958] {logging_mixin.py:104} INFO - [2021-08-17 16:26:40,957] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:26:41,458] {logging_mixin.py:104} INFO - [2021-08-17 16:26:41,456] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 16:26:41,461] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:26:41,474] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.520 seconds
[2021-08-17 16:27:12,216] {scheduler_job.py:182} INFO - Started process (PID=2884) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:27:12,217] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 16:27:12,218] {logging_mixin.py:104} INFO - [2021-08-17 16:27:12,217] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:27:12,706] {logging_mixin.py:104} INFO - [2021-08-17 16:27:12,704] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 16:27:12,709] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:27:12,727] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.513 seconds
[2021-08-17 16:27:43,410] {scheduler_job.py:182} INFO - Started process (PID=2950) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:27:43,411] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 16:27:43,412] {logging_mixin.py:104} INFO - [2021-08-17 16:27:43,412] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:27:43,912] {logging_mixin.py:104} INFO - [2021-08-17 16:27:43,909] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 16:27:43,915] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:27:43,928] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.519 seconds
[2021-08-17 16:28:14,555] {scheduler_job.py:182} INFO - Started process (PID=3014) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:28:14,556] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 16:28:14,556] {logging_mixin.py:104} INFO - [2021-08-17 16:28:14,556] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:28:15,052] {logging_mixin.py:104} INFO - [2021-08-17 16:28:15,050] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 16:28:15,055] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:28:15,067] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.514 seconds
[2021-08-17 16:28:45,743] {scheduler_job.py:182} INFO - Started process (PID=3075) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:28:45,744] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 16:28:45,745] {logging_mixin.py:104} INFO - [2021-08-17 16:28:45,745] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:28:46,288] {logging_mixin.py:104} INFO - [2021-08-17 16:28:46,285] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 16:28:46,290] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:28:46,304] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.563 seconds
[2021-08-17 16:29:16,913] {scheduler_job.py:182} INFO - Started process (PID=3130) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:29:16,914] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 16:29:16,915] {logging_mixin.py:104} INFO - [2021-08-17 16:29:16,915] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:29:17,415] {logging_mixin.py:104} INFO - [2021-08-17 16:29:17,413] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 16:29:17,418] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:29:17,429] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.518 seconds
[2021-08-17 16:29:48,295] {scheduler_job.py:182} INFO - Started process (PID=3195) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:29:48,296] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 16:29:48,296] {logging_mixin.py:104} INFO - [2021-08-17 16:29:48,296] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:29:48,792] {logging_mixin.py:104} INFO - [2021-08-17 16:29:48,789] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 16:29:48,795] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:29:48,807] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.514 seconds
[2021-08-17 16:30:19,432] {scheduler_job.py:182} INFO - Started process (PID=3260) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:30:19,433] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 16:30:19,434] {logging_mixin.py:104} INFO - [2021-08-17 16:30:19,433] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:30:19,975] {logging_mixin.py:104} INFO - [2021-08-17 16:30:19,972] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 16:30:19,977] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:30:19,990] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.560 seconds
[2021-08-17 16:30:50,739] {scheduler_job.py:182} INFO - Started process (PID=3325) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:30:50,739] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 16:30:50,740] {logging_mixin.py:104} INFO - [2021-08-17 16:30:50,740] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:30:51,258] {logging_mixin.py:104} INFO - [2021-08-17 16:30:51,255] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 16:30:51,262] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:30:51,282] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.545 seconds
[2021-08-17 16:31:22,001] {scheduler_job.py:182} INFO - Started process (PID=3389) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:31:22,003] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 16:31:22,003] {logging_mixin.py:104} INFO - [2021-08-17 16:31:22,003] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:31:22,503] {logging_mixin.py:104} INFO - [2021-08-17 16:31:22,500] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 16:31:22,506] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:31:22,517] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.518 seconds
[2021-08-17 16:31:53,208] {scheduler_job.py:182} INFO - Started process (PID=3459) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:31:53,209] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 16:31:53,210] {logging_mixin.py:104} INFO - [2021-08-17 16:31:53,210] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:31:53,739] {logging_mixin.py:104} INFO - [2021-08-17 16:31:53,736] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 16:31:53,741] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:31:53,757] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.551 seconds
[2021-08-17 16:32:24,351] {scheduler_job.py:182} INFO - Started process (PID=3526) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:32:24,352] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 16:32:24,353] {logging_mixin.py:104} INFO - [2021-08-17 16:32:24,353] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:32:24,860] {logging_mixin.py:104} INFO - [2021-08-17 16:32:24,858] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 16:32:24,863] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:32:24,875] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.525 seconds
[2021-08-17 16:32:55,590] {scheduler_job.py:182} INFO - Started process (PID=3589) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:32:55,590] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 16:32:55,591] {logging_mixin.py:104} INFO - [2021-08-17 16:32:55,591] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:32:56,086] {logging_mixin.py:104} INFO - [2021-08-17 16:32:56,084] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 16:32:56,089] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:32:56,101] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.513 seconds
[2021-08-17 16:33:26,791] {scheduler_job.py:182} INFO - Started process (PID=3657) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:33:26,792] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 16:33:26,792] {logging_mixin.py:104} INFO - [2021-08-17 16:33:26,792] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:33:27,406] {logging_mixin.py:104} INFO - [2021-08-17 16:33:27,403] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 16:33:27,408] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:33:27,422] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.633 seconds
[2021-08-17 16:33:58,284] {scheduler_job.py:182} INFO - Started process (PID=3721) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:33:58,291] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 16:33:58,293] {logging_mixin.py:104} INFO - [2021-08-17 16:33:58,293] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:33:58,843] {logging_mixin.py:104} INFO - [2021-08-17 16:33:58,841] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 16:33:58,852] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:33:58,865] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.590 seconds
[2021-08-17 16:34:28,969] {scheduler_job.py:182} INFO - Started process (PID=3791) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:34:28,970] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 16:34:28,970] {logging_mixin.py:104} INFO - [2021-08-17 16:34:28,970] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:34:29,585] {logging_mixin.py:104} INFO - [2021-08-17 16:34:29,581] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 16:34:29,588] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:34:29,604] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.636 seconds
[2021-08-17 16:35:00,133] {scheduler_job.py:182} INFO - Started process (PID=3843) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:35:00,134] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 16:35:00,135] {logging_mixin.py:104} INFO - [2021-08-17 16:35:00,135] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:35:00,752] {logging_mixin.py:104} INFO - [2021-08-17 16:35:00,743] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 16:35:00,759] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:35:00,815] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.684 seconds
[2021-08-17 16:35:31,645] {scheduler_job.py:182} INFO - Started process (PID=3908) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:35:31,646] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 16:35:31,647] {logging_mixin.py:104} INFO - [2021-08-17 16:35:31,647] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:35:32,601] {logging_mixin.py:104} INFO - [2021-08-17 16:35:32,598] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 16:35:32,605] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:35:32,616] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.974 seconds
[2021-08-17 16:36:03,087] {scheduler_job.py:182} INFO - Started process (PID=3974) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:36:03,088] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 16:36:03,088] {logging_mixin.py:104} INFO - [2021-08-17 16:36:03,088] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:36:03,830] {logging_mixin.py:104} INFO - [2021-08-17 16:36:03,808] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 16:36:03,839] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:36:03,881] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.796 seconds
[2021-08-17 16:36:34,661] {scheduler_job.py:182} INFO - Started process (PID=4040) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:36:34,663] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 16:36:34,664] {logging_mixin.py:104} INFO - [2021-08-17 16:36:34,664] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:36:35,316] {logging_mixin.py:104} INFO - [2021-08-17 16:36:35,311] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 16:36:35,319] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:36:35,336] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.677 seconds
[2021-08-17 16:37:05,981] {scheduler_job.py:182} INFO - Started process (PID=4103) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:37:05,986] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 16:37:05,990] {logging_mixin.py:104} INFO - [2021-08-17 16:37:05,990] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:37:06,618] {logging_mixin.py:104} INFO - [2021-08-17 16:37:06,615] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 16:37:06,620] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:37:06,640] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.661 seconds
[2021-08-17 16:37:37,454] {scheduler_job.py:182} INFO - Started process (PID=4170) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:37:37,455] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 16:37:37,456] {logging_mixin.py:104} INFO - [2021-08-17 16:37:37,456] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:37:38,023] {logging_mixin.py:104} INFO - [2021-08-17 16:37:38,020] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 16:37:38,026] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:37:38,040] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.588 seconds
[2021-08-17 16:38:08,815] {scheduler_job.py:182} INFO - Started process (PID=4232) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:38:08,816] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 16:38:08,817] {logging_mixin.py:104} INFO - [2021-08-17 16:38:08,817] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:38:09,395] {logging_mixin.py:104} INFO - [2021-08-17 16:38:09,390] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 16:38:09,398] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:38:09,427] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.613 seconds
[2021-08-17 16:38:40,213] {scheduler_job.py:182} INFO - Started process (PID=4301) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:38:40,215] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 16:38:40,221] {logging_mixin.py:104} INFO - [2021-08-17 16:38:40,220] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:38:40,815] {logging_mixin.py:104} INFO - [2021-08-17 16:38:40,813] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 16:38:40,818] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:38:40,828] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.616 seconds
[2021-08-17 16:39:11,076] {scheduler_job.py:182} INFO - Started process (PID=4372) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:39:11,077] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 16:39:11,078] {logging_mixin.py:104} INFO - [2021-08-17 16:39:11,078] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:39:11,671] {logging_mixin.py:104} INFO - [2021-08-17 16:39:11,668] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 16:39:11,673] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:39:11,686] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.612 seconds
[2021-08-17 16:39:41,803] {scheduler_job.py:182} INFO - Started process (PID=4442) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:39:41,804] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 16:39:41,805] {logging_mixin.py:104} INFO - [2021-08-17 16:39:41,805] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:39:42,362] {logging_mixin.py:104} INFO - [2021-08-17 16:39:42,360] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 16:39:42,365] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:39:42,376] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.575 seconds
[2021-08-17 16:40:12,723] {scheduler_job.py:182} INFO - Started process (PID=4512) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:40:12,724] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 16:40:12,725] {logging_mixin.py:104} INFO - [2021-08-17 16:40:12,725] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:40:13,231] {logging_mixin.py:104} INFO - [2021-08-17 16:40:13,228] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 16:40:13,234] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:40:13,246] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.524 seconds
[2021-08-17 16:40:44,122] {scheduler_job.py:182} INFO - Started process (PID=4576) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:40:44,123] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 16:40:44,123] {logging_mixin.py:104} INFO - [2021-08-17 16:40:44,123] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:40:44,668] {logging_mixin.py:104} INFO - [2021-08-17 16:40:44,666] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 16:40:44,671] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:40:44,682] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.562 seconds
[2021-08-17 16:41:15,545] {scheduler_job.py:182} INFO - Started process (PID=4639) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:41:15,545] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 16:41:15,546] {logging_mixin.py:104} INFO - [2021-08-17 16:41:15,546] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:41:16,111] {logging_mixin.py:104} INFO - [2021-08-17 16:41:16,109] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 16:41:16,114] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:41:16,126] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.584 seconds
[2021-08-17 16:41:47,086] {scheduler_job.py:182} INFO - Started process (PID=4694) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:41:47,088] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 16:41:47,088] {logging_mixin.py:104} INFO - [2021-08-17 16:41:47,088] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:41:47,837] {logging_mixin.py:104} INFO - [2021-08-17 16:41:47,835] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 16:41:47,840] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:41:47,852] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.767 seconds
[2021-08-17 16:42:18,441] {scheduler_job.py:182} INFO - Started process (PID=4759) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:42:18,442] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 16:42:18,443] {logging_mixin.py:104} INFO - [2021-08-17 16:42:18,443] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:42:18,948] {logging_mixin.py:104} INFO - [2021-08-17 16:42:18,945] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 16:42:18,951] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:42:18,963] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.523 seconds
[2021-08-17 16:42:49,803] {scheduler_job.py:182} INFO - Started process (PID=4824) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:42:49,804] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 16:42:49,804] {logging_mixin.py:104} INFO - [2021-08-17 16:42:49,804] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:42:50,366] {logging_mixin.py:104} INFO - [2021-08-17 16:42:50,363] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 16:42:50,368] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:42:50,380] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.578 seconds
[2021-08-17 16:43:20,496] {scheduler_job.py:182} INFO - Started process (PID=4889) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:43:20,497] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 16:43:20,498] {logging_mixin.py:104} INFO - [2021-08-17 16:43:20,498] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:43:20,983] {logging_mixin.py:104} INFO - [2021-08-17 16:43:20,981] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 16:43:20,986] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:43:20,997] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.503 seconds
[2021-08-17 16:43:51,585] {scheduler_job.py:182} INFO - Started process (PID=4952) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:43:51,585] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 16:43:51,586] {logging_mixin.py:104} INFO - [2021-08-17 16:43:51,586] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:43:52,147] {logging_mixin.py:104} INFO - [2021-08-17 16:43:52,144] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 16:43:52,152] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:43:52,165] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.582 seconds
[2021-08-17 16:44:22,813] {scheduler_job.py:182} INFO - Started process (PID=5016) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:44:22,814] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 16:44:22,815] {logging_mixin.py:104} INFO - [2021-08-17 16:44:22,815] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:44:23,310] {logging_mixin.py:104} INFO - [2021-08-17 16:44:23,307] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 16:44:23,312] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:44:23,323] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.512 seconds
[2021-08-17 16:44:53,589] {scheduler_job.py:182} INFO - Started process (PID=5081) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:44:53,590] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 16:44:53,590] {logging_mixin.py:104} INFO - [2021-08-17 16:44:53,590] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:44:54,085] {logging_mixin.py:104} INFO - [2021-08-17 16:44:54,083] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 16:44:54,088] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:44:54,100] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.513 seconds
[2021-08-17 16:45:24,804] {scheduler_job.py:182} INFO - Started process (PID=5150) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:45:24,809] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 16:45:24,809] {logging_mixin.py:104} INFO - [2021-08-17 16:45:24,809] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:45:25,373] {logging_mixin.py:104} INFO - [2021-08-17 16:45:25,370] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 16:45:25,376] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:45:25,396] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.593 seconds
[2021-08-17 16:45:56,123] {scheduler_job.py:182} INFO - Started process (PID=5214) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:45:56,124] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 16:45:56,124] {logging_mixin.py:104} INFO - [2021-08-17 16:45:56,124] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:45:56,632] {logging_mixin.py:104} INFO - [2021-08-17 16:45:56,630] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 16:45:56,635] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:45:56,647] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.526 seconds
[2021-08-17 16:46:27,580] {scheduler_job.py:182} INFO - Started process (PID=5266) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:46:27,581] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 16:46:27,582] {logging_mixin.py:104} INFO - [2021-08-17 16:46:27,582] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:46:28,084] {logging_mixin.py:104} INFO - [2021-08-17 16:46:28,074] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 16:46:28,088] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:46:28,102] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.523 seconds
[2021-08-17 16:46:58,360] {scheduler_job.py:182} INFO - Started process (PID=5330) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:46:58,360] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 16:46:58,361] {logging_mixin.py:104} INFO - [2021-08-17 16:46:58,361] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:46:58,904] {logging_mixin.py:104} INFO - [2021-08-17 16:46:58,901] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 16:46:58,906] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:46:58,918] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.560 seconds
[2021-08-17 16:47:29,356] {scheduler_job.py:182} INFO - Started process (PID=5395) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:47:29,357] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 16:47:29,358] {logging_mixin.py:104} INFO - [2021-08-17 16:47:29,357] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:47:29,867] {logging_mixin.py:104} INFO - [2021-08-17 16:47:29,865] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 16:47:29,870] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:47:29,882] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.527 seconds
[2021-08-17 16:48:00,219] {scheduler_job.py:182} INFO - Started process (PID=5461) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:48:00,220] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 16:48:00,220] {logging_mixin.py:104} INFO - [2021-08-17 16:48:00,220] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:48:00,770] {logging_mixin.py:104} INFO - [2021-08-17 16:48:00,768] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 16:48:00,773] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:48:00,783] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.567 seconds
[2021-08-17 16:48:31,123] {scheduler_job.py:182} INFO - Started process (PID=5525) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:48:31,123] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 16:48:31,124] {logging_mixin.py:104} INFO - [2021-08-17 16:48:31,124] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:48:31,638] {logging_mixin.py:104} INFO - [2021-08-17 16:48:31,635] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 16:48:31,641] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:48:31,652] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.531 seconds
[2021-08-17 16:49:01,954] {scheduler_job.py:182} INFO - Started process (PID=5591) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:49:01,956] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 16:49:01,956] {logging_mixin.py:104} INFO - [2021-08-17 16:49:01,956] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:49:02,453] {logging_mixin.py:104} INFO - [2021-08-17 16:49:02,446] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 16:49:02,458] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:49:02,478] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.525 seconds
[2021-08-17 16:49:33,040] {scheduler_job.py:182} INFO - Started process (PID=5656) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:49:33,041] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 16:49:33,042] {logging_mixin.py:104} INFO - [2021-08-17 16:49:33,042] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:49:33,572] {logging_mixin.py:104} INFO - [2021-08-17 16:49:33,569] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 16:49:33,574] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:49:33,586] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.547 seconds
[2021-08-17 16:50:21,930] {scheduler_job.py:182} INFO - Started process (PID=5704) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:50:21,933] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 16:50:21,936] {logging_mixin.py:104} INFO - [2021-08-17 16:50:21,936] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:50:23,088] {logging_mixin.py:104} INFO - [2021-08-17 16:50:23,084] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 16:50:23,113] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:50:23,126] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 1.201 seconds
[2021-08-17 16:50:53,193] {scheduler_job.py:182} INFO - Started process (PID=5779) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:50:53,197] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 16:50:53,198] {logging_mixin.py:104} INFO - [2021-08-17 16:50:53,198] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:50:53,770] {logging_mixin.py:104} INFO - [2021-08-17 16:50:53,768] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 16:50:53,788] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:50:53,800] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.608 seconds
[2021-08-17 16:51:24,466] {scheduler_job.py:182} INFO - Started process (PID=5846) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:51:24,467] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 16:51:24,468] {logging_mixin.py:104} INFO - [2021-08-17 16:51:24,468] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:51:24,874] {logging_mixin.py:104} INFO - [2021-08-17 16:51:24,873] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 16:51:24,877] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:51:24,889] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.425 seconds
[2021-08-17 16:51:55,692] {scheduler_job.py:182} INFO - Started process (PID=5910) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:51:55,693] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 16:51:55,694] {logging_mixin.py:104} INFO - [2021-08-17 16:51:55,693] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:51:56,241] {logging_mixin.py:104} INFO - [2021-08-17 16:51:56,237] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 16:51:56,245] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:51:56,260] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.570 seconds
[2021-08-17 16:52:26,856] {scheduler_job.py:182} INFO - Started process (PID=5975) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:52:26,857] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 16:52:26,857] {logging_mixin.py:104} INFO - [2021-08-17 16:52:26,857] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:52:27,352] {logging_mixin.py:104} INFO - [2021-08-17 16:52:27,349] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 16:52:27,354] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:52:27,366] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.512 seconds
[2021-08-17 16:52:58,281] {scheduler_job.py:182} INFO - Started process (PID=6039) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:52:58,281] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 16:52:58,282] {logging_mixin.py:104} INFO - [2021-08-17 16:52:58,282] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:52:58,787] {logging_mixin.py:104} INFO - [2021-08-17 16:52:58,785] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 16:52:58,791] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:52:58,802] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.523 seconds
[2021-08-17 16:53:29,612] {scheduler_job.py:182} INFO - Started process (PID=6104) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:53:29,613] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 16:53:29,613] {logging_mixin.py:104} INFO - [2021-08-17 16:53:29,613] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:53:30,177] {logging_mixin.py:104} INFO - [2021-08-17 16:53:30,155] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 16:53:30,180] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:53:30,194] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.585 seconds
[2021-08-17 16:54:00,862] {scheduler_job.py:182} INFO - Started process (PID=6170) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:54:00,863] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 16:54:00,863] {logging_mixin.py:104} INFO - [2021-08-17 16:54:00,863] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:54:01,363] {logging_mixin.py:104} INFO - [2021-08-17 16:54:01,360] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 16:54:01,365] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:54:01,387] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.526 seconds
[2021-08-17 16:54:32,044] {scheduler_job.py:182} INFO - Started process (PID=6234) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:54:32,045] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 16:54:32,046] {logging_mixin.py:104} INFO - [2021-08-17 16:54:32,046] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:54:32,522] {logging_mixin.py:104} INFO - [2021-08-17 16:54:32,520] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 16:54:32,525] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:54:32,536] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.494 seconds
[2021-08-17 16:55:03,216] {scheduler_job.py:182} INFO - Started process (PID=6297) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:55:03,217] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 16:55:03,217] {logging_mixin.py:104} INFO - [2021-08-17 16:55:03,217] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:55:03,897] {logging_mixin.py:104} INFO - [2021-08-17 16:55:03,892] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 16:55:03,905] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:55:03,945] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.731 seconds
[2021-08-17 16:55:34,417] {scheduler_job.py:182} INFO - Started process (PID=6360) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:55:34,418] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 16:55:34,419] {logging_mixin.py:104} INFO - [2021-08-17 16:55:34,419] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:55:34,928] {logging_mixin.py:104} INFO - [2021-08-17 16:55:34,925] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 16:55:34,931] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:55:34,958] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.543 seconds
[2021-08-17 16:56:05,638] {scheduler_job.py:182} INFO - Started process (PID=6424) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:56:05,639] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 16:56:05,640] {logging_mixin.py:104} INFO - [2021-08-17 16:56:05,640] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:56:06,158] {logging_mixin.py:104} INFO - [2021-08-17 16:56:06,156] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 16:56:06,161] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:56:06,185] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.549 seconds
[2021-08-17 16:56:36,271] {scheduler_job.py:182} INFO - Started process (PID=6487) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:56:36,274] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 16:56:36,274] {logging_mixin.py:104} INFO - [2021-08-17 16:56:36,274] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:56:36,846] {logging_mixin.py:104} INFO - [2021-08-17 16:56:36,838] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 16:56:36,863] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:56:36,904] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.636 seconds
[2021-08-17 16:57:07,056] {scheduler_job.py:182} INFO - Started process (PID=6541) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:57:07,057] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 16:57:07,058] {logging_mixin.py:104} INFO - [2021-08-17 16:57:07,057] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:57:07,586] {logging_mixin.py:104} INFO - [2021-08-17 16:57:07,583] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 16:57:07,589] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:57:07,609] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.555 seconds
[2021-08-17 16:57:38,254] {scheduler_job.py:182} INFO - Started process (PID=6605) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:57:38,255] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 16:57:38,256] {logging_mixin.py:104} INFO - [2021-08-17 16:57:38,255] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:57:38,804] {logging_mixin.py:104} INFO - [2021-08-17 16:57:38,801] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 16:57:38,807] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:57:38,819] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.567 seconds
[2021-08-17 16:58:09,465] {scheduler_job.py:182} INFO - Started process (PID=6670) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:58:09,466] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 16:58:09,467] {logging_mixin.py:104} INFO - [2021-08-17 16:58:09,467] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:58:10,068] {logging_mixin.py:104} INFO - [2021-08-17 16:58:10,063] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 16:58:10,071] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:58:10,085] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.622 seconds
[2021-08-17 16:58:40,594] {scheduler_job.py:182} INFO - Started process (PID=6735) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:58:40,595] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 16:58:40,596] {logging_mixin.py:104} INFO - [2021-08-17 16:58:40,596] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:58:41,135] {logging_mixin.py:104} INFO - [2021-08-17 16:58:41,129] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 16:58:41,141] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:58:41,166] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.573 seconds
[2021-08-17 16:59:11,718] {scheduler_job.py:182} INFO - Started process (PID=6798) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:59:11,721] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 16:59:11,722] {logging_mixin.py:104} INFO - [2021-08-17 16:59:11,722] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:59:12,503] {logging_mixin.py:104} INFO - [2021-08-17 16:59:12,475] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 16:59:12,526] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:59:12,599] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.885 seconds
[2021-08-17 16:59:42,916] {scheduler_job.py:182} INFO - Started process (PID=6864) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:59:42,918] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 16:59:42,918] {logging_mixin.py:104} INFO - [2021-08-17 16:59:42,918] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:59:44,768] {logging_mixin.py:104} INFO - [2021-08-17 16:59:44,765] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 16:59:44,771] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 16:59:44,784] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 1.870 seconds
[2021-08-17 17:00:15,058] {scheduler_job.py:182} INFO - Started process (PID=6931) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:00:15,059] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 17:00:15,060] {logging_mixin.py:104} INFO - [2021-08-17 17:00:15,060] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:00:15,693] {logging_mixin.py:104} INFO - [2021-08-17 17:00:15,687] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 17:00:15,696] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:00:15,742] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.685 seconds
[2021-08-17 17:00:46,305] {scheduler_job.py:182} INFO - Started process (PID=6995) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:00:46,306] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 17:00:46,307] {logging_mixin.py:104} INFO - [2021-08-17 17:00:46,307] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:00:46,995] {logging_mixin.py:104} INFO - [2021-08-17 17:00:46,992] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 17:00:46,998] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:00:47,015] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.713 seconds
[2021-08-17 17:01:17,560] {scheduler_job.py:182} INFO - Started process (PID=7057) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:01:17,562] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 17:01:17,564] {logging_mixin.py:104} INFO - [2021-08-17 17:01:17,563] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:01:18,244] {logging_mixin.py:104} INFO - [2021-08-17 17:01:18,242] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 17:01:18,247] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:01:18,266] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.711 seconds
[2021-08-17 17:01:48,674] {scheduler_job.py:182} INFO - Started process (PID=7122) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:01:48,675] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 17:01:48,676] {logging_mixin.py:104} INFO - [2021-08-17 17:01:48,676] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:01:49,140] {logging_mixin.py:104} INFO - [2021-08-17 17:01:49,138] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 17:01:49,142] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:01:49,153] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.483 seconds
[2021-08-17 17:02:20,134] {scheduler_job.py:182} INFO - Started process (PID=7185) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:02:20,135] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 17:02:20,136] {logging_mixin.py:104} INFO - [2021-08-17 17:02:20,136] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:02:20,616] {logging_mixin.py:104} INFO - [2021-08-17 17:02:20,615] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 17:02:20,619] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:02:20,630] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.501 seconds
[2021-08-17 17:02:51,443] {scheduler_job.py:182} INFO - Started process (PID=7247) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:02:51,444] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 17:02:51,445] {logging_mixin.py:104} INFO - [2021-08-17 17:02:51,445] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:02:51,889] {logging_mixin.py:104} INFO - [2021-08-17 17:02:51,887] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 17:02:51,895] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:02:51,911] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.469 seconds
[2021-08-17 17:03:22,612] {scheduler_job.py:182} INFO - Started process (PID=7313) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:03:22,613] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 17:03:22,614] {logging_mixin.py:104} INFO - [2021-08-17 17:03:22,614] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:03:23,063] {logging_mixin.py:104} INFO - [2021-08-17 17:03:23,062] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 17:03:23,066] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:03:23,077] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.466 seconds
[2021-08-17 17:03:53,866] {scheduler_job.py:182} INFO - Started process (PID=7379) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:03:53,867] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 17:03:53,868] {logging_mixin.py:104} INFO - [2021-08-17 17:03:53,868] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:03:54,338] {logging_mixin.py:104} INFO - [2021-08-17 17:03:54,337] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 17:03:54,341] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:03:54,354] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.491 seconds
[2021-08-17 17:04:25,346] {scheduler_job.py:182} INFO - Started process (PID=7443) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:04:25,347] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 17:04:25,347] {logging_mixin.py:104} INFO - [2021-08-17 17:04:25,347] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:04:25,821] {logging_mixin.py:104} INFO - [2021-08-17 17:04:25,819] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 17:04:25,826] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:04:25,836] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.493 seconds
[2021-08-17 17:04:56,420] {scheduler_job.py:182} INFO - Started process (PID=7505) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:04:56,422] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 17:04:56,423] {logging_mixin.py:104} INFO - [2021-08-17 17:04:56,422] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:04:56,876] {logging_mixin.py:104} INFO - [2021-08-17 17:04:56,874] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 17:04:56,879] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:04:56,890] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.473 seconds
[2021-08-17 17:05:27,611] {scheduler_job.py:182} INFO - Started process (PID=7575) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:05:27,612] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 17:05:27,613] {logging_mixin.py:104} INFO - [2021-08-17 17:05:27,613] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:05:28,082] {logging_mixin.py:104} INFO - [2021-08-17 17:05:28,080] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 17:05:28,084] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:05:28,095] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.486 seconds
[2021-08-17 17:05:58,168] {scheduler_job.py:182} INFO - Started process (PID=7636) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:05:58,169] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 17:05:58,170] {logging_mixin.py:104} INFO - [2021-08-17 17:05:58,170] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:05:58,731] {logging_mixin.py:104} INFO - [2021-08-17 17:05:58,729] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 17:05:58,733] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:05:58,744] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.586 seconds
[2021-08-17 17:06:29,115] {scheduler_job.py:182} INFO - Started process (PID=7693) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:06:29,116] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 17:06:29,117] {logging_mixin.py:104} INFO - [2021-08-17 17:06:29,117] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:06:29,592] {logging_mixin.py:104} INFO - [2021-08-17 17:06:29,590] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 17:06:29,594] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:06:29,609] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.497 seconds
[2021-08-17 17:06:59,747] {scheduler_job.py:182} INFO - Started process (PID=7757) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:06:59,748] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 17:06:59,750] {logging_mixin.py:104} INFO - [2021-08-17 17:06:59,750] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:07:00,231] {logging_mixin.py:104} INFO - [2021-08-17 17:07:00,229] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 17:07:00,234] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:07:00,244] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.500 seconds
[2021-08-17 17:07:31,176] {scheduler_job.py:182} INFO - Started process (PID=7824) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:07:31,177] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 17:07:31,178] {logging_mixin.py:104} INFO - [2021-08-17 17:07:31,178] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:07:31,633] {logging_mixin.py:104} INFO - [2021-08-17 17:07:31,628] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 17:07:31,635] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:07:31,646] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.472 seconds
[2021-08-17 17:08:01,706] {scheduler_job.py:182} INFO - Started process (PID=7896) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:08:01,710] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 17:08:01,711] {logging_mixin.py:104} INFO - [2021-08-17 17:08:01,711] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:08:02,205] {logging_mixin.py:104} INFO - [2021-08-17 17:08:02,203] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 17:08:02,208] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:08:02,219] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.514 seconds
[2021-08-17 17:08:33,037] {scheduler_job.py:182} INFO - Started process (PID=7963) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:08:33,038] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 17:08:33,038] {logging_mixin.py:104} INFO - [2021-08-17 17:08:33,038] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:08:33,535] {logging_mixin.py:104} INFO - [2021-08-17 17:08:33,534] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 17:08:33,538] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:08:33,547] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.513 seconds
[2021-08-17 17:09:03,608] {scheduler_job.py:182} INFO - Started process (PID=8035) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:09:03,610] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 17:09:03,610] {logging_mixin.py:104} INFO - [2021-08-17 17:09:03,610] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:09:04,120] {logging_mixin.py:104} INFO - [2021-08-17 17:09:04,118] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 17:09:04,122] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:09:04,135] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.529 seconds
[2021-08-17 17:09:35,019] {scheduler_job.py:182} INFO - Started process (PID=8104) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:09:35,020] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 17:09:35,021] {logging_mixin.py:104} INFO - [2021-08-17 17:09:35,021] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:09:35,503] {logging_mixin.py:104} INFO - [2021-08-17 17:09:35,502] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 17:09:35,506] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:09:35,517] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.500 seconds
[2021-08-17 17:10:05,622] {scheduler_job.py:182} INFO - Started process (PID=8173) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:10:05,623] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 17:10:05,624] {logging_mixin.py:104} INFO - [2021-08-17 17:10:05,624] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:10:06,092] {logging_mixin.py:104} INFO - [2021-08-17 17:10:06,091] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 17:10:06,095] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:10:06,107] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.487 seconds
[2021-08-17 17:10:36,223] {scheduler_job.py:182} INFO - Started process (PID=8237) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:10:36,224] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 17:10:36,224] {logging_mixin.py:104} INFO - [2021-08-17 17:10:36,224] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:10:36,702] {logging_mixin.py:104} INFO - [2021-08-17 17:10:36,700] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 17:10:36,704] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:10:36,722] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.502 seconds
[2021-08-17 17:11:06,868] {scheduler_job.py:182} INFO - Started process (PID=8302) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:11:06,871] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 17:11:06,871] {logging_mixin.py:104} INFO - [2021-08-17 17:11:06,871] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:11:07,377] {logging_mixin.py:104} INFO - [2021-08-17 17:11:07,375] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 17:11:07,380] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:11:07,391] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.524 seconds
[2021-08-17 17:11:38,151] {scheduler_job.py:182} INFO - Started process (PID=8371) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:11:38,152] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 17:11:38,152] {logging_mixin.py:104} INFO - [2021-08-17 17:11:38,152] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:11:38,599] {logging_mixin.py:104} INFO - [2021-08-17 17:11:38,598] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 17:11:38,602] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:11:38,613] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.464 seconds
[2021-08-17 17:12:09,348] {scheduler_job.py:182} INFO - Started process (PID=8435) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:12:09,349] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 17:12:09,350] {logging_mixin.py:104} INFO - [2021-08-17 17:12:09,349] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:12:09,787] {logging_mixin.py:104} INFO - [2021-08-17 17:12:09,786] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 17:12:09,790] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:12:09,801] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.455 seconds
[2021-08-17 17:12:40,597] {scheduler_job.py:182} INFO - Started process (PID=8499) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:12:40,598] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 17:12:40,599] {logging_mixin.py:104} INFO - [2021-08-17 17:12:40,599] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:12:41,031] {logging_mixin.py:104} INFO - [2021-08-17 17:12:41,029] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 17:12:41,033] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:12:41,046] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.450 seconds
[2021-08-17 17:13:11,763] {scheduler_job.py:182} INFO - Started process (PID=8565) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:13:11,764] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 17:13:11,765] {logging_mixin.py:104} INFO - [2021-08-17 17:13:11,765] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:13:12,218] {logging_mixin.py:104} INFO - [2021-08-17 17:13:12,216] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 17:13:12,220] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:13:12,231] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.470 seconds
[2021-08-17 17:13:42,989] {scheduler_job.py:182} INFO - Started process (PID=8630) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:13:42,990] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 17:13:42,991] {logging_mixin.py:104} INFO - [2021-08-17 17:13:42,991] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:13:43,421] {logging_mixin.py:104} INFO - [2021-08-17 17:13:43,419] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 17:13:43,424] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:13:43,442] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.454 seconds
[2021-08-17 17:14:14,113] {scheduler_job.py:182} INFO - Started process (PID=8694) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:14:14,114] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 17:14:14,114] {logging_mixin.py:104} INFO - [2021-08-17 17:14:14,114] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:14:14,563] {logging_mixin.py:104} INFO - [2021-08-17 17:14:14,562] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 17:14:14,566] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:14:14,577] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.466 seconds
[2021-08-17 17:14:45,217] {scheduler_job.py:182} INFO - Started process (PID=8756) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:14:45,218] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 17:14:45,219] {logging_mixin.py:104} INFO - [2021-08-17 17:14:45,219] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:14:45,664] {logging_mixin.py:104} INFO - [2021-08-17 17:14:45,662] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 17:14:45,667] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:14:45,678] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.463 seconds
[2021-08-17 17:15:16,369] {scheduler_job.py:182} INFO - Started process (PID=8816) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:15:16,370] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 17:15:16,370] {logging_mixin.py:104} INFO - [2021-08-17 17:15:16,370] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:15:16,795] {logging_mixin.py:104} INFO - [2021-08-17 17:15:16,794] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 17:15:16,798] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:15:16,809] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.442 seconds
[2021-08-17 17:15:47,530] {scheduler_job.py:182} INFO - Started process (PID=8871) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:15:47,531] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 17:15:47,532] {logging_mixin.py:104} INFO - [2021-08-17 17:15:47,532] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:15:48,022] {logging_mixin.py:104} INFO - [2021-08-17 17:15:48,019] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 17:15:48,027] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:15:48,042] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.514 seconds
[2021-08-17 17:16:18,648] {scheduler_job.py:182} INFO - Started process (PID=8938) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:16:18,650] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 17:16:18,650] {logging_mixin.py:104} INFO - [2021-08-17 17:16:18,650] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:16:19,089] {logging_mixin.py:104} INFO - [2021-08-17 17:16:19,088] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 17:16:19,092] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:16:19,110] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.464 seconds
[2021-08-17 17:16:49,904] {scheduler_job.py:182} INFO - Started process (PID=9002) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:16:49,905] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 17:16:49,906] {logging_mixin.py:104} INFO - [2021-08-17 17:16:49,906] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:16:50,362] {logging_mixin.py:104} INFO - [2021-08-17 17:16:50,360] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 17:16:50,364] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:16:50,375] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.474 seconds
[2021-08-17 17:17:21,026] {scheduler_job.py:182} INFO - Started process (PID=9066) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:17:21,027] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 17:17:21,028] {logging_mixin.py:104} INFO - [2021-08-17 17:17:21,028] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:17:21,801] {logging_mixin.py:104} INFO - [2021-08-17 17:17:21,800] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 17:17:21,804] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:17:21,823] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.799 seconds
[2021-08-17 17:17:52,170] {scheduler_job.py:182} INFO - Started process (PID=9130) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:17:52,172] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 17:17:52,172] {logging_mixin.py:104} INFO - [2021-08-17 17:17:52,172] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:17:52,613] {logging_mixin.py:104} INFO - [2021-08-17 17:17:52,612] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 17:17:52,616] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:17:52,627] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.458 seconds
[2021-08-17 17:18:23,272] {scheduler_job.py:182} INFO - Started process (PID=9194) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:18:23,273] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 17:18:23,274] {logging_mixin.py:104} INFO - [2021-08-17 17:18:23,274] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:18:23,717] {logging_mixin.py:104} INFO - [2021-08-17 17:18:23,715] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 17:18:23,719] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:18:23,731] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.462 seconds
[2021-08-17 17:18:54,418] {scheduler_job.py:182} INFO - Started process (PID=9258) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:18:54,418] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 17:18:54,419] {logging_mixin.py:104} INFO - [2021-08-17 17:18:54,419] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:18:54,912] {logging_mixin.py:104} INFO - [2021-08-17 17:18:54,910] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 17:18:54,915] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:18:54,928] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.512 seconds
[2021-08-17 17:19:25,832] {scheduler_job.py:182} INFO - Started process (PID=9325) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:19:25,833] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 17:19:25,834] {logging_mixin.py:104} INFO - [2021-08-17 17:19:25,834] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:19:26,286] {logging_mixin.py:104} INFO - [2021-08-17 17:19:26,284] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 17:19:26,288] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:19:26,300] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.470 seconds
[2021-08-17 17:19:57,049] {scheduler_job.py:182} INFO - Started process (PID=9390) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:19:57,050] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 17:19:57,051] {logging_mixin.py:104} INFO - [2021-08-17 17:19:57,051] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:19:57,512] {logging_mixin.py:104} INFO - [2021-08-17 17:19:57,510] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 17:19:57,515] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:19:57,525] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.478 seconds
[2021-08-17 17:20:28,217] {scheduler_job.py:182} INFO - Started process (PID=9453) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:20:28,218] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 17:20:28,219] {logging_mixin.py:104} INFO - [2021-08-17 17:20:28,219] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:20:28,669] {logging_mixin.py:104} INFO - [2021-08-17 17:20:28,667] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 17:20:28,671] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:20:28,686] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.471 seconds
[2021-08-17 17:20:59,494] {scheduler_job.py:182} INFO - Started process (PID=9516) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:20:59,495] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 17:20:59,496] {logging_mixin.py:104} INFO - [2021-08-17 17:20:59,496] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:20:59,958] {logging_mixin.py:104} INFO - [2021-08-17 17:20:59,957] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 17:20:59,961] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:20:59,974] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.482 seconds
[2021-08-17 17:21:30,617] {scheduler_job.py:182} INFO - Started process (PID=9580) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:21:30,619] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 17:21:30,620] {logging_mixin.py:104} INFO - [2021-08-17 17:21:30,620] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:21:31,084] {logging_mixin.py:104} INFO - [2021-08-17 17:21:31,082] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 17:21:31,086] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:21:31,097] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.481 seconds
[2021-08-17 17:22:01,757] {scheduler_job.py:182} INFO - Started process (PID=9645) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:22:01,758] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 17:22:01,758] {logging_mixin.py:104} INFO - [2021-08-17 17:22:01,758] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:22:02,206] {logging_mixin.py:104} INFO - [2021-08-17 17:22:02,205] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 17:22:02,209] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:22:02,220] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.465 seconds
[2021-08-17 17:22:32,986] {scheduler_job.py:182} INFO - Started process (PID=9712) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:22:32,987] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 17:22:32,988] {logging_mixin.py:104} INFO - [2021-08-17 17:22:32,988] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:22:33,435] {logging_mixin.py:104} INFO - [2021-08-17 17:22:33,433] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 17:22:33,437] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:22:33,448] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.464 seconds
[2021-08-17 17:23:04,212] {scheduler_job.py:182} INFO - Started process (PID=9776) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:23:04,213] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 17:23:04,214] {logging_mixin.py:104} INFO - [2021-08-17 17:23:04,213] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:23:04,665] {logging_mixin.py:104} INFO - [2021-08-17 17:23:04,664] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 17:23:04,668] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:23:04,678] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.468 seconds
[2021-08-17 17:23:35,346] {scheduler_job.py:182} INFO - Started process (PID=9842) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:23:35,347] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 17:23:35,348] {logging_mixin.py:104} INFO - [2021-08-17 17:23:35,348] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:23:35,785] {logging_mixin.py:104} INFO - [2021-08-17 17:23:35,778] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 17:23:35,788] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:23:35,798] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.454 seconds
[2021-08-17 17:24:06,714] {scheduler_job.py:182} INFO - Started process (PID=9907) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:24:06,715] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 17:24:06,716] {logging_mixin.py:104} INFO - [2021-08-17 17:24:06,716] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:24:07,258] {logging_mixin.py:104} INFO - [2021-08-17 17:24:07,256] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 17:24:07,261] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:24:07,296] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.584 seconds
[2021-08-17 17:24:38,311] {scheduler_job.py:182} INFO - Started process (PID=9973) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:24:38,312] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 17:24:38,313] {logging_mixin.py:104} INFO - [2021-08-17 17:24:38,313] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:24:38,975] {logging_mixin.py:104} INFO - [2021-08-17 17:24:38,973] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 17:24:38,977] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:24:38,988] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.679 seconds
[2021-08-17 17:25:09,158] {scheduler_job.py:182} INFO - Started process (PID=10044) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:25:09,159] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 17:25:09,170] {logging_mixin.py:104} INFO - [2021-08-17 17:25:09,170] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:25:09,679] {logging_mixin.py:104} INFO - [2021-08-17 17:25:09,678] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 17:25:09,682] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:25:09,700] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.545 seconds
[2021-08-17 17:25:40,688] {scheduler_job.py:182} INFO - Started process (PID=10115) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:25:40,689] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 17:25:40,690] {logging_mixin.py:104} INFO - [2021-08-17 17:25:40,690] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:25:41,290] {logging_mixin.py:104} INFO - [2021-08-17 17:25:41,289] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 17:25:41,293] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:25:41,304] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.618 seconds
[2021-08-17 17:26:12,430] {scheduler_job.py:182} INFO - Started process (PID=10185) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:26:12,431] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 17:26:12,431] {logging_mixin.py:104} INFO - [2021-08-17 17:26:12,431] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:26:13,391] {logging_mixin.py:104} INFO - [2021-08-17 17:26:13,390] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 17:26:13,395] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:26:13,410] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.982 seconds
[2021-08-17 17:26:43,865] {scheduler_job.py:182} INFO - Started process (PID=10256) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:26:43,867] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 17:26:43,868] {logging_mixin.py:104} INFO - [2021-08-17 17:26:43,868] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:26:44,374] {logging_mixin.py:104} INFO - [2021-08-17 17:26:44,372] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 17:26:44,378] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:26:44,390] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.526 seconds
[2021-08-17 17:27:14,680] {scheduler_job.py:182} INFO - Started process (PID=10324) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:27:14,681] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 17:27:14,682] {logging_mixin.py:104} INFO - [2021-08-17 17:27:14,681] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:27:15,156] {logging_mixin.py:104} INFO - [2021-08-17 17:27:15,150] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 17:27:15,163] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:27:15,185] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.507 seconds
[2021-08-17 17:27:45,224] {scheduler_job.py:182} INFO - Started process (PID=10393) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:27:45,229] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 17:27:45,230] {logging_mixin.py:104} INFO - [2021-08-17 17:27:45,230] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:27:45,681] {logging_mixin.py:104} INFO - [2021-08-17 17:27:45,679] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 17:27:45,684] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:27:45,696] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.474 seconds
[2021-08-17 17:28:16,659] {scheduler_job.py:182} INFO - Started process (PID=10458) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:28:16,660] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 17:28:16,660] {logging_mixin.py:104} INFO - [2021-08-17 17:28:16,660] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:28:17,098] {logging_mixin.py:104} INFO - [2021-08-17 17:28:17,096] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 17:28:17,101] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:28:17,112] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.456 seconds
[2021-08-17 17:28:47,182] {scheduler_job.py:182} INFO - Started process (PID=10514) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:28:47,183] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 17:28:47,183] {logging_mixin.py:104} INFO - [2021-08-17 17:28:47,183] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:28:47,625] {logging_mixin.py:104} INFO - [2021-08-17 17:28:47,624] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 17:28:47,628] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:28:47,639] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.459 seconds
[2021-08-17 17:29:17,714] {scheduler_job.py:182} INFO - Started process (PID=10579) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:29:17,715] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 17:29:17,716] {logging_mixin.py:104} INFO - [2021-08-17 17:29:17,716] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:29:18,150] {logging_mixin.py:104} INFO - [2021-08-17 17:29:18,149] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 17:29:18,152] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:29:18,164] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.451 seconds
[2021-08-17 17:29:48,478] {scheduler_job.py:182} INFO - Started process (PID=10644) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:29:48,479] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 17:29:48,480] {logging_mixin.py:104} INFO - [2021-08-17 17:29:48,480] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:29:48,924] {logging_mixin.py:104} INFO - [2021-08-17 17:29:48,922] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 17:29:48,926] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:29:48,937] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.461 seconds
[2021-08-17 17:30:19,338] {scheduler_job.py:182} INFO - Started process (PID=10708) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:30:19,339] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 17:30:19,339] {logging_mixin.py:104} INFO - [2021-08-17 17:30:19,339] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:30:19,781] {logging_mixin.py:104} INFO - [2021-08-17 17:30:19,779] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 17:30:19,785] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:30:19,797] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.462 seconds
[2021-08-17 17:30:50,736] {scheduler_job.py:182} INFO - Started process (PID=10772) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:30:50,737] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 17:30:50,738] {logging_mixin.py:104} INFO - [2021-08-17 17:30:50,738] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:30:51,166] {logging_mixin.py:104} INFO - [2021-08-17 17:30:51,164] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 17:30:51,168] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:30:51,179] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.445 seconds
[2021-08-17 17:31:21,217] {scheduler_job.py:182} INFO - Started process (PID=10838) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:31:21,218] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 17:31:21,219] {logging_mixin.py:104} INFO - [2021-08-17 17:31:21,219] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:31:21,636] {logging_mixin.py:104} INFO - [2021-08-17 17:31:21,634] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 17:31:21,638] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:31:21,649] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.434 seconds
[2021-08-17 17:31:51,808] {scheduler_job.py:182} INFO - Started process (PID=10901) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:31:51,809] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 17:31:51,810] {logging_mixin.py:104} INFO - [2021-08-17 17:31:51,810] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:31:52,239] {logging_mixin.py:104} INFO - [2021-08-17 17:31:52,237] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 17:31:52,241] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:31:52,261] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.454 seconds
[2021-08-17 17:32:22,633] {scheduler_job.py:182} INFO - Started process (PID=10966) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:32:22,635] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 17:32:22,636] {logging_mixin.py:104} INFO - [2021-08-17 17:32:22,636] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:32:23,080] {logging_mixin.py:104} INFO - [2021-08-17 17:32:23,079] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 17:32:23,083] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:32:23,095] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.465 seconds
[2021-08-17 17:32:54,064] {scheduler_job.py:182} INFO - Started process (PID=11032) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:32:54,065] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 17:32:54,065] {logging_mixin.py:104} INFO - [2021-08-17 17:32:54,065] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:32:55,050] {logging_mixin.py:104} INFO - [2021-08-17 17:32:55,048] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 17:32:55,053] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:32:55,065] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 1.002 seconds
[2021-08-17 17:33:25,363] {scheduler_job.py:182} INFO - Started process (PID=11095) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:33:25,364] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 17:33:25,365] {logging_mixin.py:104} INFO - [2021-08-17 17:33:25,365] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:33:25,795] {logging_mixin.py:104} INFO - [2021-08-17 17:33:25,793] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 17:33:25,797] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:33:25,815] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.453 seconds
[2021-08-17 17:33:55,846] {scheduler_job.py:182} INFO - Started process (PID=11160) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:33:55,847] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 17:33:55,848] {logging_mixin.py:104} INFO - [2021-08-17 17:33:55,848] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:33:56,266] {logging_mixin.py:104} INFO - [2021-08-17 17:33:56,264] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 17:33:56,268] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:33:56,286] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.442 seconds
[2021-08-17 17:34:26,365] {scheduler_job.py:182} INFO - Started process (PID=11227) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:34:26,366] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 17:34:26,366] {logging_mixin.py:104} INFO - [2021-08-17 17:34:26,366] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:34:26,797] {logging_mixin.py:104} INFO - [2021-08-17 17:34:26,796] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 17:34:26,800] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:34:26,818] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.455 seconds
[2021-08-17 17:34:57,745] {scheduler_job.py:182} INFO - Started process (PID=11295) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:34:57,745] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 17:34:57,746] {logging_mixin.py:104} INFO - [2021-08-17 17:34:57,746] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:34:58,208] {logging_mixin.py:104} INFO - [2021-08-17 17:34:58,206] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 17:34:58,210] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:34:58,221] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.478 seconds
[2021-08-17 17:35:29,143] {scheduler_job.py:182} INFO - Started process (PID=11359) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:35:29,144] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 17:35:29,145] {logging_mixin.py:104} INFO - [2021-08-17 17:35:29,145] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:35:29,568] {logging_mixin.py:104} INFO - [2021-08-17 17:35:29,566] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 17:35:29,570] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:35:29,581] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.440 seconds
[2021-08-17 17:36:00,481] {scheduler_job.py:182} INFO - Started process (PID=11422) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:36:00,482] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 17:36:00,482] {logging_mixin.py:104} INFO - [2021-08-17 17:36:00,482] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:36:00,913] {logging_mixin.py:104} INFO - [2021-08-17 17:36:00,912] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 17:36:00,916] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:36:00,926] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.447 seconds
[2021-08-17 17:36:31,795] {scheduler_job.py:182} INFO - Started process (PID=11486) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:36:31,797] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 17:36:31,798] {logging_mixin.py:104} INFO - [2021-08-17 17:36:31,798] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:36:32,331] {logging_mixin.py:104} INFO - [2021-08-17 17:36:32,329] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 17:36:32,333] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:36:32,345] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.552 seconds
[2021-08-17 17:37:03,123] {scheduler_job.py:182} INFO - Started process (PID=11550) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:37:03,124] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 17:37:03,125] {logging_mixin.py:104} INFO - [2021-08-17 17:37:03,125] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:37:03,577] {logging_mixin.py:104} INFO - [2021-08-17 17:37:03,575] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 17:37:03,580] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:37:03,591] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.473 seconds
[2021-08-17 17:37:34,533] {scheduler_job.py:182} INFO - Started process (PID=11613) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:37:34,533] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 17:37:34,534] {logging_mixin.py:104} INFO - [2021-08-17 17:37:34,534] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:37:35,020] {logging_mixin.py:104} INFO - [2021-08-17 17:37:35,018] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 17:37:35,023] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:37:35,039] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.508 seconds
[2021-08-17 17:38:05,870] {scheduler_job.py:182} INFO - Started process (PID=11680) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:38:05,871] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 17:38:05,872] {logging_mixin.py:104} INFO - [2021-08-17 17:38:05,872] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:38:06,299] {logging_mixin.py:104} INFO - [2021-08-17 17:38:06,298] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 17:38:06,302] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:38:06,316] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.448 seconds
[2021-08-17 17:38:37,245] {scheduler_job.py:182} INFO - Started process (PID=11745) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:38:37,246] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 17:38:37,246] {logging_mixin.py:104} INFO - [2021-08-17 17:38:37,246] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:38:37,694] {logging_mixin.py:104} INFO - [2021-08-17 17:38:37,692] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 17:38:37,696] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:38:37,706] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.463 seconds
[2021-08-17 17:39:08,634] {scheduler_job.py:182} INFO - Started process (PID=11808) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:39:08,635] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 17:39:08,635] {logging_mixin.py:104} INFO - [2021-08-17 17:39:08,635] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:39:09,110] {logging_mixin.py:104} INFO - [2021-08-17 17:39:09,108] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 17:39:09,113] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:39:09,123] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.492 seconds
[2021-08-17 17:39:39,953] {scheduler_job.py:182} INFO - Started process (PID=11867) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:39:39,954] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 17:39:39,954] {logging_mixin.py:104} INFO - [2021-08-17 17:39:39,954] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:39:40,415] {logging_mixin.py:104} INFO - [2021-08-17 17:39:40,413] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 17:39:40,417] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:39:40,427] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.477 seconds
[2021-08-17 17:40:11,313] {scheduler_job.py:182} INFO - Started process (PID=11933) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:40:11,314] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 17:40:11,315] {logging_mixin.py:104} INFO - [2021-08-17 17:40:11,314] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:40:11,738] {logging_mixin.py:104} INFO - [2021-08-17 17:40:11,737] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 17:40:11,740] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:40:11,763] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.452 seconds
[2021-08-17 17:40:42,736] {scheduler_job.py:182} INFO - Started process (PID=11999) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:40:42,737] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 17:40:42,737] {logging_mixin.py:104} INFO - [2021-08-17 17:40:42,737] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:40:43,170] {logging_mixin.py:104} INFO - [2021-08-17 17:40:43,169] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 17:40:43,173] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:40:43,191] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.457 seconds
[2021-08-17 17:41:14,165] {scheduler_job.py:182} INFO - Started process (PID=12067) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:41:14,166] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 17:41:14,169] {logging_mixin.py:104} INFO - [2021-08-17 17:41:14,169] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:41:15,158] {logging_mixin.py:104} INFO - [2021-08-17 17:41:15,156] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 17:41:15,161] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:41:15,171] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 1.008 seconds
[2021-08-17 17:41:45,501] {scheduler_job.py:182} INFO - Started process (PID=12129) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:41:45,502] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 17:41:45,503] {logging_mixin.py:104} INFO - [2021-08-17 17:41:45,503] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:41:45,954] {logging_mixin.py:104} INFO - [2021-08-17 17:41:45,952] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 17:41:45,956] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:41:45,974] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.475 seconds
[2021-08-17 17:42:16,927] {scheduler_job.py:182} INFO - Started process (PID=12194) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:42:16,928] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 17:42:16,929] {logging_mixin.py:104} INFO - [2021-08-17 17:42:16,929] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:42:17,374] {logging_mixin.py:104} INFO - [2021-08-17 17:42:17,372] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 17:42:17,377] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:42:17,388] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.463 seconds
[2021-08-17 17:42:48,087] {scheduler_job.py:182} INFO - Started process (PID=12261) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:42:48,087] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 17:42:48,088] {logging_mixin.py:104} INFO - [2021-08-17 17:42:48,088] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:42:48,549] {logging_mixin.py:104} INFO - [2021-08-17 17:42:48,548] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 17:42:48,552] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:42:48,563] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.478 seconds
[2021-08-17 17:43:19,425] {scheduler_job.py:182} INFO - Started process (PID=12326) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:43:19,426] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 17:43:19,426] {logging_mixin.py:104} INFO - [2021-08-17 17:43:19,426] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:43:19,863] {logging_mixin.py:104} INFO - [2021-08-17 17:43:19,862] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 17:43:19,866] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:43:19,876] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.454 seconds
[2021-08-17 17:43:50,776] {scheduler_job.py:182} INFO - Started process (PID=12391) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:43:50,777] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 17:43:50,778] {logging_mixin.py:104} INFO - [2021-08-17 17:43:50,778] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:43:51,226] {logging_mixin.py:104} INFO - [2021-08-17 17:43:51,224] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 17:43:51,228] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:43:51,239] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.465 seconds
[2021-08-17 17:44:22,028] {scheduler_job.py:182} INFO - Started process (PID=12455) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:44:22,029] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 17:44:22,029] {logging_mixin.py:104} INFO - [2021-08-17 17:44:22,029] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:44:22,456] {logging_mixin.py:104} INFO - [2021-08-17 17:44:22,455] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 17:44:22,459] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:44:22,469] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.443 seconds
[2021-08-17 17:44:53,391] {scheduler_job.py:182} INFO - Started process (PID=12522) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:44:53,392] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 17:44:53,393] {logging_mixin.py:104} INFO - [2021-08-17 17:44:53,393] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:44:53,848] {logging_mixin.py:104} INFO - [2021-08-17 17:44:53,847] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 17:44:53,851] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:44:53,863] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.477 seconds
[2021-08-17 17:45:24,803] {scheduler_job.py:182} INFO - Started process (PID=12591) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:45:24,805] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 17:45:24,807] {logging_mixin.py:104} INFO - [2021-08-17 17:45:24,807] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:45:25,284] {logging_mixin.py:104} INFO - [2021-08-17 17:45:25,282] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 17:45:25,286] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:45:25,299] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.498 seconds
[2021-08-17 17:45:56,406] {scheduler_job.py:182} INFO - Started process (PID=12664) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:45:56,407] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 17:45:56,408] {logging_mixin.py:104} INFO - [2021-08-17 17:45:56,408] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:45:56,860] {logging_mixin.py:104} INFO - [2021-08-17 17:45:56,858] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 17:45:56,863] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:45:56,873] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.469 seconds
[2021-08-17 17:46:26,920] {scheduler_job.py:182} INFO - Started process (PID=12735) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:46:26,921] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 17:46:26,921] {logging_mixin.py:104} INFO - [2021-08-17 17:46:26,921] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:46:27,405] {logging_mixin.py:104} INFO - [2021-08-17 17:46:27,403] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 17:46:27,407] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:46:27,427] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.509 seconds
[2021-08-17 17:46:58,373] {scheduler_job.py:182} INFO - Started process (PID=12803) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:46:58,374] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 17:46:58,375] {logging_mixin.py:104} INFO - [2021-08-17 17:46:58,375] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:46:58,818] {logging_mixin.py:104} INFO - [2021-08-17 17:46:58,816] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 17:46:58,820] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:46:58,831] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.459 seconds
[2021-08-17 17:47:29,554] {scheduler_job.py:182} INFO - Started process (PID=12872) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:47:29,554] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 17:47:29,555] {logging_mixin.py:104} INFO - [2021-08-17 17:47:29,555] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:47:30,008] {logging_mixin.py:104} INFO - [2021-08-17 17:47:30,006] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 17:47:30,010] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:47:30,020] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.469 seconds
[2021-08-17 17:48:00,879] {scheduler_job.py:182} INFO - Started process (PID=12938) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:48:00,880] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 17:48:00,881] {logging_mixin.py:104} INFO - [2021-08-17 17:48:00,881] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:48:01,325] {logging_mixin.py:104} INFO - [2021-08-17 17:48:01,324] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 17:48:01,328] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:48:01,337] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.460 seconds
[2021-08-17 17:48:32,288] {scheduler_job.py:182} INFO - Started process (PID=13006) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:48:32,289] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 17:48:32,290] {logging_mixin.py:104} INFO - [2021-08-17 17:48:32,290] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:48:32,828] {logging_mixin.py:104} INFO - [2021-08-17 17:48:32,826] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 17:48:32,830] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:48:32,840] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.554 seconds
[2021-08-17 17:49:02,930] {scheduler_job.py:182} INFO - Started process (PID=13073) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:49:02,931] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 17:49:02,932] {logging_mixin.py:104} INFO - [2021-08-17 17:49:02,932] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:49:03,358] {logging_mixin.py:104} INFO - [2021-08-17 17:49:03,357] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 17:49:03,361] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:49:03,379] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.450 seconds
[2021-08-17 17:49:34,062] {scheduler_job.py:182} INFO - Started process (PID=13140) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:49:34,063] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 17:49:34,063] {logging_mixin.py:104} INFO - [2021-08-17 17:49:34,063] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:49:34,490] {logging_mixin.py:104} INFO - [2021-08-17 17:49:34,489] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 17:49:34,492] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:49:34,502] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.442 seconds
[2021-08-17 17:50:05,308] {scheduler_job.py:182} INFO - Started process (PID=13204) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:50:05,309] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 17:50:05,310] {logging_mixin.py:104} INFO - [2021-08-17 17:50:05,310] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:50:05,751] {logging_mixin.py:104} INFO - [2021-08-17 17:50:05,749] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 17:50:05,754] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:50:05,764] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.458 seconds
[2021-08-17 17:50:36,599] {scheduler_job.py:182} INFO - Started process (PID=13269) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:50:36,600] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 17:50:36,600] {logging_mixin.py:104} INFO - [2021-08-17 17:50:36,600] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:50:37,050] {logging_mixin.py:104} INFO - [2021-08-17 17:50:37,048] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 17:50:37,052] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:50:37,063] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.466 seconds
[2021-08-17 17:51:07,836] {scheduler_job.py:182} INFO - Started process (PID=13333) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:51:07,837] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 17:51:07,838] {logging_mixin.py:104} INFO - [2021-08-17 17:51:07,838] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:51:08,294] {logging_mixin.py:104} INFO - [2021-08-17 17:51:08,292] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 17:51:08,296] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:51:08,308] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.474 seconds
[2021-08-17 17:51:39,041] {scheduler_job.py:182} INFO - Started process (PID=13397) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:51:39,043] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 17:51:39,043] {logging_mixin.py:104} INFO - [2021-08-17 17:51:39,043] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:51:39,518] {logging_mixin.py:104} INFO - [2021-08-17 17:51:39,516] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 17:51:39,520] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:51:39,532] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.493 seconds
[2021-08-17 17:52:10,464] {scheduler_job.py:182} INFO - Started process (PID=13463) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:52:10,465] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 17:52:10,466] {logging_mixin.py:104} INFO - [2021-08-17 17:52:10,466] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:52:10,891] {logging_mixin.py:104} INFO - [2021-08-17 17:52:10,889] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 17:52:10,894] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:52:10,909] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.446 seconds
[2021-08-17 17:52:41,760] {scheduler_job.py:182} INFO - Started process (PID=13528) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:52:41,761] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 17:52:41,762] {logging_mixin.py:104} INFO - [2021-08-17 17:52:41,762] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:52:42,206] {logging_mixin.py:104} INFO - [2021-08-17 17:52:42,204] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 17:52:42,208] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:52:42,219] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.461 seconds
[2021-08-17 17:53:12,948] {scheduler_job.py:182} INFO - Started process (PID=13592) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:53:12,949] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 17:53:12,950] {logging_mixin.py:104} INFO - [2021-08-17 17:53:12,950] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:53:13,364] {logging_mixin.py:104} INFO - [2021-08-17 17:53:13,362] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 17:53:13,366] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:53:13,378] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.431 seconds
[2021-08-17 17:53:44,184] {scheduler_job.py:182} INFO - Started process (PID=13660) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:53:44,185] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 17:53:44,186] {logging_mixin.py:104} INFO - [2021-08-17 17:53:44,186] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:53:44,607] {logging_mixin.py:104} INFO - [2021-08-17 17:53:44,606] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 17:53:44,610] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:53:44,621] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.438 seconds
[2021-08-17 17:54:15,397] {scheduler_job.py:182} INFO - Started process (PID=13723) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:54:15,398] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 17:54:15,399] {logging_mixin.py:104} INFO - [2021-08-17 17:54:15,399] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:54:15,825] {logging_mixin.py:104} INFO - [2021-08-17 17:54:15,824] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 17:54:15,828] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:54:15,839] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.443 seconds
[2021-08-17 17:54:46,650] {scheduler_job.py:182} INFO - Started process (PID=13786) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:54:46,653] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 17:54:46,654] {logging_mixin.py:104} INFO - [2021-08-17 17:54:46,654] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:54:47,104] {logging_mixin.py:104} INFO - [2021-08-17 17:54:47,102] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 17:54:47,107] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:54:47,119] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.471 seconds
[2021-08-17 17:55:17,842] {scheduler_job.py:182} INFO - Started process (PID=13851) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:55:17,843] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 17:55:17,844] {logging_mixin.py:104} INFO - [2021-08-17 17:55:17,844] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:55:18,265] {logging_mixin.py:104} INFO - [2021-08-17 17:55:18,263] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 17:55:18,267] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:55:18,278] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.438 seconds
[2021-08-17 17:55:49,002] {scheduler_job.py:182} INFO - Started process (PID=13916) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:55:49,002] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 17:55:49,003] {logging_mixin.py:104} INFO - [2021-08-17 17:55:49,003] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:55:49,933] {logging_mixin.py:104} INFO - [2021-08-17 17:55:49,931] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 17:55:49,936] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:55:49,947] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.948 seconds
[2021-08-17 17:56:20,168] {scheduler_job.py:182} INFO - Started process (PID=13981) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:56:20,170] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 17:56:20,170] {logging_mixin.py:104} INFO - [2021-08-17 17:56:20,170] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:56:20,887] {logging_mixin.py:104} INFO - [2021-08-17 17:56:20,884] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 17:56:20,889] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:56:20,900] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.734 seconds
[2021-08-17 17:56:51,343] {scheduler_job.py:182} INFO - Started process (PID=14036) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:56:51,344] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 17:56:51,346] {logging_mixin.py:104} INFO - [2021-08-17 17:56:51,345] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:56:51,811] {logging_mixin.py:104} INFO - [2021-08-17 17:56:51,810] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 17:56:51,814] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:56:51,832] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.492 seconds
[2021-08-17 17:57:22,536] {scheduler_job.py:182} INFO - Started process (PID=14104) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:57:22,537] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 17:57:22,538] {logging_mixin.py:104} INFO - [2021-08-17 17:57:22,538] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:57:22,978] {logging_mixin.py:104} INFO - [2021-08-17 17:57:22,974] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 17:57:22,980] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:57:22,991] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.457 seconds
[2021-08-17 17:57:53,733] {scheduler_job.py:182} INFO - Started process (PID=14170) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:57:53,733] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 17:57:53,734] {logging_mixin.py:104} INFO - [2021-08-17 17:57:53,734] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:57:54,177] {logging_mixin.py:104} INFO - [2021-08-17 17:57:54,176] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 17:57:54,180] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:57:54,193] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.462 seconds
[2021-08-17 17:58:24,935] {scheduler_job.py:182} INFO - Started process (PID=14234) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:58:24,936] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 17:58:24,937] {logging_mixin.py:104} INFO - [2021-08-17 17:58:24,936] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:58:25,415] {logging_mixin.py:104} INFO - [2021-08-17 17:58:25,413] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 17:58:25,417] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:58:25,427] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.494 seconds
[2021-08-17 17:58:56,088] {scheduler_job.py:182} INFO - Started process (PID=14303) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:58:56,088] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 17:58:56,089] {logging_mixin.py:104} INFO - [2021-08-17 17:58:56,089] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:58:56,518] {logging_mixin.py:104} INFO - [2021-08-17 17:58:56,516] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 17:58:56,520] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:58:56,530] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.445 seconds
[2021-08-17 17:59:27,421] {scheduler_job.py:182} INFO - Started process (PID=14367) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:59:27,422] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 17:59:27,423] {logging_mixin.py:104} INFO - [2021-08-17 17:59:27,423] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:59:27,857] {logging_mixin.py:104} INFO - [2021-08-17 17:59:27,855] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 17:59:27,859] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:59:27,870] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.451 seconds
[2021-08-17 17:59:58,561] {scheduler_job.py:182} INFO - Started process (PID=14433) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:59:58,562] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 17:59:58,563] {logging_mixin.py:104} INFO - [2021-08-17 17:59:58,563] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:59:58,986] {logging_mixin.py:104} INFO - [2021-08-17 17:59:58,984] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 17:59:58,990] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 17:59:59,003] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.444 seconds
[2021-08-17 18:00:29,741] {scheduler_job.py:182} INFO - Started process (PID=14500) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:00:29,742] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 18:00:29,743] {logging_mixin.py:104} INFO - [2021-08-17 18:00:29,742] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:00:30,448] {logging_mixin.py:104} INFO - [2021-08-17 18:00:30,446] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 18:00:30,450] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:00:30,461] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.722 seconds
[2021-08-17 18:01:00,912] {scheduler_job.py:182} INFO - Started process (PID=14567) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:01:00,913] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 18:01:00,914] {logging_mixin.py:104} INFO - [2021-08-17 18:01:00,914] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:01:01,343] {logging_mixin.py:104} INFO - [2021-08-17 18:01:01,341] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 18:01:01,345] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:01:01,364] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.458 seconds
[2021-08-17 18:01:31,550] {scheduler_job.py:182} INFO - Started process (PID=14628) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:01:31,551] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 18:01:31,552] {logging_mixin.py:104} INFO - [2021-08-17 18:01:31,551] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:01:32,014] {logging_mixin.py:104} INFO - [2021-08-17 18:01:32,012] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 18:01:32,016] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:01:32,027] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.479 seconds
[2021-08-17 18:02:02,736] {scheduler_job.py:182} INFO - Started process (PID=14693) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:02:02,739] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 18:02:02,740] {logging_mixin.py:104} INFO - [2021-08-17 18:02:02,740] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:02:03,337] {logging_mixin.py:104} INFO - [2021-08-17 18:02:03,335] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 18:02:03,339] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:02:03,351] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.617 seconds
[2021-08-17 18:02:34,081] {scheduler_job.py:182} INFO - Started process (PID=14767) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:02:34,082] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 18:02:34,082] {logging_mixin.py:104} INFO - [2021-08-17 18:02:34,082] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:02:34,554] {logging_mixin.py:104} INFO - [2021-08-17 18:02:34,553] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 18:02:34,557] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:02:34,577] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.498 seconds
[2021-08-17 18:03:04,647] {scheduler_job.py:182} INFO - Started process (PID=14836) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:03:04,647] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 18:03:04,648] {logging_mixin.py:104} INFO - [2021-08-17 18:03:04,648] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:03:05,131] {logging_mixin.py:104} INFO - [2021-08-17 18:03:05,129] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 18:03:05,134] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:03:05,144] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.499 seconds
[2021-08-17 18:03:35,806] {scheduler_job.py:182} INFO - Started process (PID=14902) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:03:35,807] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 18:03:35,807] {logging_mixin.py:104} INFO - [2021-08-17 18:03:35,807] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:03:36,262] {logging_mixin.py:104} INFO - [2021-08-17 18:03:36,260] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 18:03:36,264] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:03:36,275] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.471 seconds
[2021-08-17 18:04:06,324] {scheduler_job.py:182} INFO - Started process (PID=14971) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:04:06,325] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 18:04:06,326] {logging_mixin.py:104} INFO - [2021-08-17 18:04:06,326] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:04:06,794] {logging_mixin.py:104} INFO - [2021-08-17 18:04:06,793] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 18:04:06,797] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:04:06,815] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.493 seconds
[2021-08-17 18:04:37,585] {scheduler_job.py:182} INFO - Started process (PID=15038) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:04:37,586] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 18:04:37,586] {logging_mixin.py:104} INFO - [2021-08-17 18:04:37,586] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:04:38,077] {logging_mixin.py:104} INFO - [2021-08-17 18:04:38,075] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 18:04:38,080] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:04:38,090] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.508 seconds
[2021-08-17 18:05:08,743] {scheduler_job.py:182} INFO - Started process (PID=15104) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:05:08,744] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 18:05:08,744] {logging_mixin.py:104} INFO - [2021-08-17 18:05:08,744] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:05:09,734] {logging_mixin.py:104} INFO - [2021-08-17 18:05:09,733] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 18:05:09,737] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:05:09,748] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 1.007 seconds
[2021-08-17 18:05:40,131] {scheduler_job.py:182} INFO - Started process (PID=15172) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:05:40,132] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 18:05:40,133] {logging_mixin.py:104} INFO - [2021-08-17 18:05:40,133] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:05:40,552] {logging_mixin.py:104} INFO - [2021-08-17 18:05:40,551] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 18:05:40,555] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:05:40,565] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.436 seconds
[2021-08-17 18:06:11,352] {scheduler_job.py:182} INFO - Started process (PID=15239) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:06:11,353] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 18:06:11,353] {logging_mixin.py:104} INFO - [2021-08-17 18:06:11,353] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:06:11,793] {logging_mixin.py:104} INFO - [2021-08-17 18:06:11,791] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 18:06:11,795] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:06:11,806] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.456 seconds
[2021-08-17 18:06:42,444] {scheduler_job.py:182} INFO - Started process (PID=15303) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:06:42,445] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 18:06:42,446] {logging_mixin.py:104} INFO - [2021-08-17 18:06:42,446] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:06:42,891] {logging_mixin.py:104} INFO - [2021-08-17 18:06:42,889] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 18:06:42,894] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:06:42,904] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.462 seconds
[2021-08-17 18:07:13,551] {scheduler_job.py:182} INFO - Started process (PID=15366) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:07:13,552] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 18:07:13,552] {logging_mixin.py:104} INFO - [2021-08-17 18:07:13,552] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:07:14,039] {logging_mixin.py:104} INFO - [2021-08-17 18:07:14,038] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 18:07:14,042] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:07:14,054] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.505 seconds
[2021-08-17 18:07:44,107] {scheduler_job.py:182} INFO - Started process (PID=15430) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:07:44,108] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 18:07:44,109] {logging_mixin.py:104} INFO - [2021-08-17 18:07:44,109] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:07:44,580] {logging_mixin.py:104} INFO - [2021-08-17 18:07:44,574] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 18:07:44,582] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:07:44,605] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.499 seconds
[2021-08-17 18:08:14,669] {scheduler_job.py:182} INFO - Started process (PID=15483) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:08:14,670] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 18:08:14,670] {logging_mixin.py:104} INFO - [2021-08-17 18:08:14,670] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:08:15,126] {logging_mixin.py:104} INFO - [2021-08-17 18:08:15,124] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 18:08:15,128] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:08:15,138] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.471 seconds
[2021-08-17 18:08:45,218] {scheduler_job.py:182} INFO - Started process (PID=15550) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:08:45,219] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 18:08:45,220] {logging_mixin.py:104} INFO - [2021-08-17 18:08:45,220] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:08:45,657] {logging_mixin.py:104} INFO - [2021-08-17 18:08:45,655] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 18:08:45,659] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:08:45,669] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.453 seconds
[2021-08-17 18:09:15,726] {scheduler_job.py:182} INFO - Started process (PID=15612) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:09:15,727] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 18:09:15,728] {logging_mixin.py:104} INFO - [2021-08-17 18:09:15,728] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:09:16,189] {logging_mixin.py:104} INFO - [2021-08-17 18:09:16,188] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 18:09:16,192] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:09:16,202] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.478 seconds
[2021-08-17 18:09:46,264] {scheduler_job.py:182} INFO - Started process (PID=15677) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:09:46,265] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 18:09:46,265] {logging_mixin.py:104} INFO - [2021-08-17 18:09:46,265] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:09:46,696] {logging_mixin.py:104} INFO - [2021-08-17 18:09:46,694] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 18:09:46,698] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:09:46,709] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.447 seconds
[2021-08-17 18:10:16,785] {scheduler_job.py:182} INFO - Started process (PID=15739) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:10:16,786] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 18:10:16,787] {logging_mixin.py:104} INFO - [2021-08-17 18:10:16,787] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:10:17,227] {logging_mixin.py:104} INFO - [2021-08-17 18:10:17,225] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 18:10:17,230] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:10:17,240] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.457 seconds
[2021-08-17 18:10:47,295] {scheduler_job.py:182} INFO - Started process (PID=15806) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:10:47,296] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 18:10:47,297] {logging_mixin.py:104} INFO - [2021-08-17 18:10:47,297] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:10:47,760] {logging_mixin.py:104} INFO - [2021-08-17 18:10:47,759] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 18:10:47,763] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:10:47,774] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.480 seconds
[2021-08-17 18:11:17,926] {scheduler_job.py:182} INFO - Started process (PID=15870) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:11:17,929] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 18:11:17,929] {logging_mixin.py:104} INFO - [2021-08-17 18:11:17,929] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:11:18,414] {logging_mixin.py:104} INFO - [2021-08-17 18:11:18,412] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 18:11:18,417] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:11:18,429] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.505 seconds
[2021-08-17 18:11:49,134] {scheduler_job.py:182} INFO - Started process (PID=15937) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:11:49,135] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 18:11:49,136] {logging_mixin.py:104} INFO - [2021-08-17 18:11:49,136] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:11:49,612] {logging_mixin.py:104} INFO - [2021-08-17 18:11:49,610] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 18:11:49,614] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:11:49,626] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.494 seconds
[2021-08-17 18:12:19,654] {scheduler_job.py:182} INFO - Started process (PID=16002) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:12:19,655] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 18:12:19,656] {logging_mixin.py:104} INFO - [2021-08-17 18:12:19,656] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:12:20,098] {logging_mixin.py:104} INFO - [2021-08-17 18:12:20,096] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 18:12:20,100] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:12:20,111] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.459 seconds
[2021-08-17 18:12:50,235] {scheduler_job.py:182} INFO - Started process (PID=16068) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:12:50,236] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 18:12:50,236] {logging_mixin.py:104} INFO - [2021-08-17 18:12:50,236] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:12:50,674] {logging_mixin.py:104} INFO - [2021-08-17 18:12:50,672] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 18:12:50,677] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:12:50,687] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.454 seconds
[2021-08-17 18:13:20,779] {scheduler_job.py:182} INFO - Started process (PID=16128) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:13:20,780] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 18:13:20,781] {logging_mixin.py:104} INFO - [2021-08-17 18:13:20,781] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:13:21,204] {logging_mixin.py:104} INFO - [2021-08-17 18:13:21,202] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 18:13:21,206] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:13:21,217] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.440 seconds
[2021-08-17 18:13:51,264] {scheduler_job.py:182} INFO - Started process (PID=16182) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:13:51,265] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 18:13:51,266] {logging_mixin.py:104} INFO - [2021-08-17 18:13:51,266] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:13:51,772] {logging_mixin.py:104} INFO - [2021-08-17 18:13:51,770] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 18:13:51,774] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:13:51,783] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.522 seconds
[2021-08-17 18:14:22,414] {scheduler_job.py:182} INFO - Started process (PID=16247) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:14:22,415] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 18:14:22,415] {logging_mixin.py:104} INFO - [2021-08-17 18:14:22,415] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:14:23,404] {logging_mixin.py:104} INFO - [2021-08-17 18:14:23,403] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 18:14:23,407] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:14:23,417] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 1.005 seconds
[2021-08-17 18:14:53,532] {scheduler_job.py:182} INFO - Started process (PID=16311) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:14:53,533] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 18:14:53,534] {logging_mixin.py:104} INFO - [2021-08-17 18:14:53,534] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:14:53,974] {logging_mixin.py:104} INFO - [2021-08-17 18:14:53,973] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 18:14:53,977] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:14:53,989] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.458 seconds
[2021-08-17 18:15:24,770] {scheduler_job.py:182} INFO - Started process (PID=16376) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:15:24,771] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 18:15:24,771] {logging_mixin.py:104} INFO - [2021-08-17 18:15:24,771] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:15:25,184] {logging_mixin.py:104} INFO - [2021-08-17 18:15:25,182] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 18:15:25,186] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:15:25,198] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.430 seconds
[2021-08-17 18:15:55,970] {scheduler_job.py:182} INFO - Started process (PID=16438) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:15:55,971] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 18:15:55,972] {logging_mixin.py:104} INFO - [2021-08-17 18:15:55,972] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:15:56,418] {logging_mixin.py:104} INFO - [2021-08-17 18:15:56,417] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 18:15:56,421] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:15:56,431] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.463 seconds
[2021-08-17 18:16:27,175] {scheduler_job.py:182} INFO - Started process (PID=16501) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:16:27,177] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 18:16:27,177] {logging_mixin.py:104} INFO - [2021-08-17 18:16:27,177] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:16:27,624] {logging_mixin.py:104} INFO - [2021-08-17 18:16:27,623] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 18:16:27,627] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:16:27,638] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.464 seconds
[2021-08-17 18:16:58,342] {scheduler_job.py:182} INFO - Started process (PID=16563) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:16:58,343] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 18:16:58,344] {logging_mixin.py:104} INFO - [2021-08-17 18:16:58,344] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:16:58,818] {logging_mixin.py:104} INFO - [2021-08-17 18:16:58,817] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 18:16:58,821] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:16:58,832] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.491 seconds
[2021-08-17 18:17:29,568] {scheduler_job.py:182} INFO - Started process (PID=16627) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:17:29,569] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 18:17:29,570] {logging_mixin.py:104} INFO - [2021-08-17 18:17:29,570] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:17:30,017] {logging_mixin.py:104} INFO - [2021-08-17 18:17:30,015] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 18:17:30,019] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:17:30,030] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.464 seconds
[2021-08-17 18:18:00,795] {scheduler_job.py:182} INFO - Started process (PID=16694) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:18:00,796] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 18:18:00,796] {logging_mixin.py:104} INFO - [2021-08-17 18:18:00,796] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:18:01,234] {logging_mixin.py:104} INFO - [2021-08-17 18:18:01,232] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 18:18:01,236] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:18:01,248] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.454 seconds
[2021-08-17 18:18:31,991] {scheduler_job.py:182} INFO - Started process (PID=16759) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:18:31,992] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 18:18:31,992] {logging_mixin.py:104} INFO - [2021-08-17 18:18:31,992] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:18:32,757] {logging_mixin.py:104} INFO - [2021-08-17 18:18:32,756] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 18:18:32,760] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:18:32,777] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.788 seconds
[2021-08-17 18:19:03,308] {scheduler_job.py:182} INFO - Started process (PID=16823) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:19:03,309] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 18:19:03,309] {logging_mixin.py:104} INFO - [2021-08-17 18:19:03,309] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:19:03,740] {logging_mixin.py:104} INFO - [2021-08-17 18:19:03,738] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 18:19:03,743] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:19:03,756] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.451 seconds
[2021-08-17 18:19:34,530] {scheduler_job.py:182} INFO - Started process (PID=16885) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:19:34,530] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 18:19:34,531] {logging_mixin.py:104} INFO - [2021-08-17 18:19:34,531] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:19:34,951] {logging_mixin.py:104} INFO - [2021-08-17 18:19:34,950] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 18:19:34,954] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:19:34,963] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.436 seconds
[2021-08-17 18:20:05,687] {scheduler_job.py:182} INFO - Started process (PID=16950) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:20:05,695] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 18:20:05,696] {logging_mixin.py:104} INFO - [2021-08-17 18:20:05,696] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:20:06,134] {logging_mixin.py:104} INFO - [2021-08-17 18:20:06,132] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 18:20:06,136] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:20:06,148] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.464 seconds
[2021-08-17 18:20:36,921] {scheduler_job.py:182} INFO - Started process (PID=17018) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:20:36,922] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 18:20:36,923] {logging_mixin.py:104} INFO - [2021-08-17 18:20:36,923] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:20:37,394] {logging_mixin.py:104} INFO - [2021-08-17 18:20:37,392] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 18:20:37,396] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:20:37,411] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.498 seconds
[2021-08-17 18:21:08,116] {scheduler_job.py:182} INFO - Started process (PID=17080) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:21:08,117] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 18:21:08,118] {logging_mixin.py:104} INFO - [2021-08-17 18:21:08,118] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:21:08,597] {logging_mixin.py:104} INFO - [2021-08-17 18:21:08,596] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 18:21:08,600] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:21:08,610] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.495 seconds
[2021-08-17 18:21:39,369] {scheduler_job.py:182} INFO - Started process (PID=17145) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:21:39,370] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 18:21:39,371] {logging_mixin.py:104} INFO - [2021-08-17 18:21:39,371] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:21:39,804] {logging_mixin.py:104} INFO - [2021-08-17 18:21:39,802] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 18:21:39,807] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:21:39,817] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.450 seconds
[2021-08-17 18:22:10,552] {scheduler_job.py:182} INFO - Started process (PID=17209) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:22:10,553] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 18:22:10,554] {logging_mixin.py:104} INFO - [2021-08-17 18:22:10,554] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:22:10,991] {logging_mixin.py:104} INFO - [2021-08-17 18:22:10,986] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 18:22:10,996] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:22:11,014] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.464 seconds
[2021-08-17 18:22:41,786] {scheduler_job.py:182} INFO - Started process (PID=17271) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:22:41,787] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 18:22:41,787] {logging_mixin.py:104} INFO - [2021-08-17 18:22:41,787] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:22:42,292] {logging_mixin.py:104} INFO - [2021-08-17 18:22:42,291] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 18:22:42,295] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:22:42,305] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.521 seconds
[2021-08-17 18:23:12,985] {scheduler_job.py:182} INFO - Started process (PID=17340) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:23:12,986] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 18:23:12,987] {logging_mixin.py:104} INFO - [2021-08-17 18:23:12,987] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:23:13,407] {logging_mixin.py:104} INFO - [2021-08-17 18:23:13,405] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 18:23:13,409] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:23:13,428] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.444 seconds
[2021-08-17 18:23:44,170] {scheduler_job.py:182} INFO - Started process (PID=17405) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:23:44,171] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 18:23:44,172] {logging_mixin.py:104} INFO - [2021-08-17 18:23:44,172] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:23:44,624] {logging_mixin.py:104} INFO - [2021-08-17 18:23:44,622] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 18:23:44,626] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:23:44,638] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.469 seconds
[2021-08-17 18:24:15,284] {scheduler_job.py:182} INFO - Started process (PID=17469) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:24:15,285] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 18:24:15,286] {logging_mixin.py:104} INFO - [2021-08-17 18:24:15,286] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:24:15,753] {logging_mixin.py:104} INFO - [2021-08-17 18:24:15,751] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 18:24:15,755] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:24:15,766] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.485 seconds
[2021-08-17 18:24:46,722] {scheduler_job.py:182} INFO - Started process (PID=17538) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:24:46,723] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 18:24:46,724] {logging_mixin.py:104} INFO - [2021-08-17 18:24:46,724] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:24:47,173] {logging_mixin.py:104} INFO - [2021-08-17 18:24:47,171] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 18:24:47,175] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:24:47,186] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.466 seconds
[2021-08-17 18:25:17,837] {scheduler_job.py:182} INFO - Started process (PID=17601) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:25:17,838] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 18:25:17,839] {logging_mixin.py:104} INFO - [2021-08-17 18:25:17,839] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:25:18,261] {logging_mixin.py:104} INFO - [2021-08-17 18:25:18,259] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 18:25:18,263] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:25:18,275] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.439 seconds
[2021-08-17 18:25:48,380] {scheduler_job.py:182} INFO - Started process (PID=17665) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:25:48,381] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 18:25:48,382] {logging_mixin.py:104} INFO - [2021-08-17 18:25:48,381] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:25:49,074] {logging_mixin.py:104} INFO - [2021-08-17 18:25:49,072] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 18:25:49,077] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:25:49,088] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.710 seconds
[2021-08-17 18:26:19,844] {scheduler_job.py:182} INFO - Started process (PID=17737) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:26:19,846] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 18:26:19,846] {logging_mixin.py:104} INFO - [2021-08-17 18:26:19,846] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:26:20,305] {logging_mixin.py:104} INFO - [2021-08-17 18:26:20,302] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 18:26:20,307] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:26:20,317] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.475 seconds
[2021-08-17 18:26:50,365] {scheduler_job.py:182} INFO - Started process (PID=17808) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:26:50,366] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 18:26:50,367] {logging_mixin.py:104} INFO - [2021-08-17 18:26:50,367] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:26:50,809] {logging_mixin.py:104} INFO - [2021-08-17 18:26:50,807] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 18:26:50,811] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:26:50,822] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.459 seconds
[2021-08-17 18:27:21,594] {scheduler_job.py:182} INFO - Started process (PID=17872) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:27:21,595] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 18:27:21,595] {logging_mixin.py:104} INFO - [2021-08-17 18:27:21,595] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:27:22,059] {logging_mixin.py:104} INFO - [2021-08-17 18:27:22,058] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 18:27:22,062] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:27:22,072] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.483 seconds
[2021-08-17 18:27:52,966] {scheduler_job.py:182} INFO - Started process (PID=17937) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:27:52,968] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 18:27:52,969] {logging_mixin.py:104} INFO - [2021-08-17 18:27:52,969] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:27:53,413] {logging_mixin.py:104} INFO - [2021-08-17 18:27:53,411] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 18:27:53,415] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:27:53,426] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.463 seconds
[2021-08-17 18:28:24,243] {scheduler_job.py:182} INFO - Started process (PID=17996) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:28:24,244] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 18:28:24,244] {logging_mixin.py:104} INFO - [2021-08-17 18:28:24,244] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:28:24,677] {logging_mixin.py:104} INFO - [2021-08-17 18:28:24,676] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 18:28:24,682] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:28:24,695] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.455 seconds
[2021-08-17 18:28:55,346] {scheduler_job.py:182} INFO - Started process (PID=18052) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:28:55,347] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 18:28:55,347] {logging_mixin.py:104} INFO - [2021-08-17 18:28:55,347] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:28:55,862] {logging_mixin.py:104} INFO - [2021-08-17 18:28:55,861] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 18:28:55,865] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:28:55,881] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.537 seconds
[2021-08-17 18:29:26,517] {scheduler_job.py:182} INFO - Started process (PID=18114) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:29:26,518] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 18:29:26,518] {logging_mixin.py:104} INFO - [2021-08-17 18:29:26,518] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:29:27,453] {logging_mixin.py:104} INFO - [2021-08-17 18:29:27,451] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 18:29:27,456] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:29:27,465] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.951 seconds
[2021-08-17 18:29:57,702] {scheduler_job.py:182} INFO - Started process (PID=18181) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:29:57,703] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 18:29:57,703] {logging_mixin.py:104} INFO - [2021-08-17 18:29:57,703] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:29:58,149] {logging_mixin.py:104} INFO - [2021-08-17 18:29:58,147] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 18:29:58,151] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:29:58,172] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.472 seconds
[2021-08-17 18:30:28,934] {scheduler_job.py:182} INFO - Started process (PID=18250) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:30:28,935] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 18:30:28,936] {logging_mixin.py:104} INFO - [2021-08-17 18:30:28,936] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:30:29,391] {logging_mixin.py:104} INFO - [2021-08-17 18:30:29,389] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 18:30:29,394] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:30:29,406] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.473 seconds
[2021-08-17 18:31:00,144] {scheduler_job.py:182} INFO - Started process (PID=18316) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:31:00,145] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 18:31:00,146] {logging_mixin.py:104} INFO - [2021-08-17 18:31:00,146] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:31:00,595] {logging_mixin.py:104} INFO - [2021-08-17 18:31:00,593] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 18:31:00,597] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:31:00,615] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.473 seconds
[2021-08-17 18:31:31,344] {scheduler_job.py:182} INFO - Started process (PID=18380) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:31:31,345] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 18:31:31,346] {logging_mixin.py:104} INFO - [2021-08-17 18:31:31,346] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:31:31,766] {logging_mixin.py:104} INFO - [2021-08-17 18:31:31,764] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 18:31:31,768] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:31:31,779] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.437 seconds
[2021-08-17 18:32:01,961] {scheduler_job.py:182} INFO - Started process (PID=18447) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:32:01,962] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 18:32:01,963] {logging_mixin.py:104} INFO - [2021-08-17 18:32:01,963] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:32:02,414] {logging_mixin.py:104} INFO - [2021-08-17 18:32:02,412] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 18:32:02,416] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:32:02,427] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.468 seconds
[2021-08-17 18:32:33,020] {scheduler_job.py:182} INFO - Started process (PID=18513) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:32:33,021] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 18:32:33,022] {logging_mixin.py:104} INFO - [2021-08-17 18:32:33,022] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:32:33,617] {logging_mixin.py:104} INFO - [2021-08-17 18:32:33,615] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 18:32:33,620] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:32:33,631] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.612 seconds
[2021-08-17 18:33:04,260] {scheduler_job.py:182} INFO - Started process (PID=18578) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:33:04,261] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 18:33:04,262] {logging_mixin.py:104} INFO - [2021-08-17 18:33:04,262] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:33:04,709] {logging_mixin.py:104} INFO - [2021-08-17 18:33:04,708] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 18:33:04,712] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:33:04,724] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.465 seconds
[2021-08-17 18:33:35,626] {scheduler_job.py:182} INFO - Started process (PID=18644) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:33:35,627] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 18:33:35,627] {logging_mixin.py:104} INFO - [2021-08-17 18:33:35,627] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:33:36,075] {logging_mixin.py:104} INFO - [2021-08-17 18:33:36,073] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 18:33:36,077] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:33:36,095] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.472 seconds
[2021-08-17 18:34:06,925] {scheduler_job.py:182} INFO - Started process (PID=18713) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:34:06,926] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 18:34:06,927] {logging_mixin.py:104} INFO - [2021-08-17 18:34:06,927] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:34:07,357] {logging_mixin.py:104} INFO - [2021-08-17 18:34:07,356] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 18:34:07,360] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:34:07,378] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.455 seconds
[2021-08-17 18:34:38,171] {scheduler_job.py:182} INFO - Started process (PID=18776) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:34:38,172] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 18:34:38,173] {logging_mixin.py:104} INFO - [2021-08-17 18:34:38,173] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:34:38,615] {logging_mixin.py:104} INFO - [2021-08-17 18:34:38,613] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 18:34:38,618] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:34:38,636] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.467 seconds
[2021-08-17 18:35:09,418] {scheduler_job.py:182} INFO - Started process (PID=18841) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:35:09,419] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 18:35:09,419] {logging_mixin.py:104} INFO - [2021-08-17 18:35:09,419] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:35:09,848] {logging_mixin.py:104} INFO - [2021-08-17 18:35:09,846] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 18:35:09,851] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:35:09,862] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.446 seconds
[2021-08-17 18:35:40,627] {scheduler_job.py:182} INFO - Started process (PID=18906) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:35:40,628] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 18:35:40,628] {logging_mixin.py:104} INFO - [2021-08-17 18:35:40,628] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:35:41,108] {logging_mixin.py:104} INFO - [2021-08-17 18:35:41,106] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 18:35:41,111] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:35:41,120] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.495 seconds
[2021-08-17 18:36:11,922] {scheduler_job.py:182} INFO - Started process (PID=18972) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:36:11,923] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 18:36:11,924] {logging_mixin.py:104} INFO - [2021-08-17 18:36:11,923] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:36:12,372] {logging_mixin.py:104} INFO - [2021-08-17 18:36:12,370] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 18:36:12,374] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:36:12,385] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.465 seconds
[2021-08-17 18:36:43,275] {scheduler_job.py:182} INFO - Started process (PID=19038) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:36:43,277] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 18:36:43,278] {logging_mixin.py:104} INFO - [2021-08-17 18:36:43,278] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:36:43,717] {logging_mixin.py:104} INFO - [2021-08-17 18:36:43,715] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 18:36:43,719] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:36:43,730] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.457 seconds
[2021-08-17 18:37:14,670] {scheduler_job.py:182} INFO - Started process (PID=19103) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:37:14,671] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 18:37:14,672] {logging_mixin.py:104} INFO - [2021-08-17 18:37:14,672] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:37:15,140] {logging_mixin.py:104} INFO - [2021-08-17 18:37:15,138] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 18:37:15,143] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:37:15,155] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.486 seconds
[2021-08-17 18:37:46,008] {scheduler_job.py:182} INFO - Started process (PID=19168) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:37:46,009] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 18:37:46,010] {logging_mixin.py:104} INFO - [2021-08-17 18:37:46,010] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:37:46,477] {logging_mixin.py:104} INFO - [2021-08-17 18:37:46,475] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 18:37:46,480] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:37:46,492] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.485 seconds
[2021-08-17 18:38:17,361] {scheduler_job.py:182} INFO - Started process (PID=19234) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:38:17,362] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 18:38:17,363] {logging_mixin.py:104} INFO - [2021-08-17 18:38:17,363] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:38:17,779] {logging_mixin.py:104} INFO - [2021-08-17 18:38:17,777] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 18:38:17,781] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:38:17,792] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.432 seconds
[2021-08-17 18:38:48,710] {scheduler_job.py:182} INFO - Started process (PID=19299) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:38:48,710] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 18:38:48,711] {logging_mixin.py:104} INFO - [2021-08-17 18:38:48,711] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:38:49,151] {logging_mixin.py:104} INFO - [2021-08-17 18:38:49,149] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 18:38:49,154] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:38:49,165] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.457 seconds
[2021-08-17 18:39:19,306] {scheduler_job.py:182} INFO - Started process (PID=19364) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:39:19,307] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 18:39:19,308] {logging_mixin.py:104} INFO - [2021-08-17 18:39:19,308] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:39:19,728] {logging_mixin.py:104} INFO - [2021-08-17 18:39:19,726] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 18:39:19,731] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:39:19,742] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.437 seconds
[2021-08-17 18:39:50,099] {scheduler_job.py:182} INFO - Started process (PID=19430) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:39:50,100] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 18:39:50,101] {logging_mixin.py:104} INFO - [2021-08-17 18:39:50,101] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:39:50,540] {logging_mixin.py:104} INFO - [2021-08-17 18:39:50,539] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 18:39:50,542] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:39:50,554] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.456 seconds
[2021-08-17 18:40:21,396] {scheduler_job.py:182} INFO - Started process (PID=19495) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:40:21,396] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 18:40:21,397] {logging_mixin.py:104} INFO - [2021-08-17 18:40:21,397] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:40:21,850] {logging_mixin.py:104} INFO - [2021-08-17 18:40:21,848] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 18:40:21,853] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:40:21,871] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.477 seconds
[2021-08-17 18:40:52,746] {scheduler_job.py:182} INFO - Started process (PID=19562) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:40:52,748] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 18:40:52,749] {logging_mixin.py:104} INFO - [2021-08-17 18:40:52,749] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:40:53,197] {logging_mixin.py:104} INFO - [2021-08-17 18:40:53,196] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 18:40:53,200] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:40:53,211] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.466 seconds
[2021-08-17 18:41:24,168] {scheduler_job.py:182} INFO - Started process (PID=19626) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:41:24,169] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 18:41:24,170] {logging_mixin.py:104} INFO - [2021-08-17 18:41:24,170] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:41:24,651] {logging_mixin.py:104} INFO - [2021-08-17 18:41:24,649] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 18:41:24,654] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:41:24,664] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.502 seconds
[2021-08-17 18:41:54,691] {scheduler_job.py:182} INFO - Started process (PID=19695) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:41:54,692] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 18:41:54,693] {logging_mixin.py:104} INFO - [2021-08-17 18:41:54,693] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:41:55,134] {logging_mixin.py:104} INFO - [2021-08-17 18:41:55,132] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 18:41:55,136] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:41:55,146] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.457 seconds
[2021-08-17 18:42:25,986] {scheduler_job.py:182} INFO - Started process (PID=19760) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:42:25,987] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 18:42:25,988] {logging_mixin.py:104} INFO - [2021-08-17 18:42:25,988] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:42:26,429] {logging_mixin.py:104} INFO - [2021-08-17 18:42:26,427] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 18:42:26,432] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:42:26,442] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.458 seconds
[2021-08-17 18:42:57,435] {scheduler_job.py:182} INFO - Started process (PID=19829) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:42:57,436] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 18:42:57,438] {logging_mixin.py:104} INFO - [2021-08-17 18:42:57,438] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:42:57,893] {logging_mixin.py:104} INFO - [2021-08-17 18:42:57,892] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 18:42:57,896] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:42:57,907] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.474 seconds
[2021-08-17 18:43:29,075] {scheduler_job.py:182} INFO - Started process (PID=19899) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:43:29,083] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 18:43:29,083] {logging_mixin.py:104} INFO - [2021-08-17 18:43:29,083] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:43:29,687] {logging_mixin.py:104} INFO - [2021-08-17 18:43:29,686] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 18:43:29,690] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:43:29,701] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.629 seconds
[2021-08-17 18:44:00,758] {scheduler_job.py:182} INFO - Started process (PID=19965) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:44:00,759] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 18:44:00,760] {logging_mixin.py:104} INFO - [2021-08-17 18:44:00,760] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:44:01,433] {logging_mixin.py:104} INFO - [2021-08-17 18:44:01,432] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 18:44:01,436] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:44:01,451] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.695 seconds
[2021-08-17 18:44:31,646] {scheduler_job.py:182} INFO - Started process (PID=20019) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:44:31,647] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 18:44:31,648] {logging_mixin.py:104} INFO - [2021-08-17 18:44:31,648] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:44:32,205] {logging_mixin.py:104} INFO - [2021-08-17 18:44:32,203] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 18:44:32,208] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:44:32,218] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.574 seconds
[2021-08-17 18:45:02,394] {scheduler_job.py:182} INFO - Started process (PID=20091) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:45:02,394] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 18:45:02,395] {logging_mixin.py:104} INFO - [2021-08-17 18:45:02,395] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:45:02,945] {logging_mixin.py:104} INFO - [2021-08-17 18:45:02,943] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 18:45:02,947] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:45:02,958] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.566 seconds
[2021-08-17 18:45:33,900] {scheduler_job.py:182} INFO - Started process (PID=20157) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:45:33,901] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 18:45:33,902] {logging_mixin.py:104} INFO - [2021-08-17 18:45:33,902] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:45:34,449] {logging_mixin.py:104} INFO - [2021-08-17 18:45:34,448] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 18:45:34,452] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:45:34,461] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.564 seconds
[2021-08-17 18:46:04,517] {scheduler_job.py:182} INFO - Started process (PID=20228) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:46:04,519] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 18:46:04,519] {logging_mixin.py:104} INFO - [2021-08-17 18:46:04,519] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:46:04,953] {logging_mixin.py:104} INFO - [2021-08-17 18:46:04,951] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 18:46:04,956] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:46:04,966] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.452 seconds
[2021-08-17 18:46:35,777] {scheduler_job.py:182} INFO - Started process (PID=20292) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:46:35,778] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 18:46:35,779] {logging_mixin.py:104} INFO - [2021-08-17 18:46:35,779] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:46:36,206] {logging_mixin.py:104} INFO - [2021-08-17 18:46:36,204] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 18:46:36,208] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:46:36,226] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.451 seconds
[2021-08-17 18:47:07,045] {scheduler_job.py:182} INFO - Started process (PID=20356) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:47:07,046] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 18:47:07,046] {logging_mixin.py:104} INFO - [2021-08-17 18:47:07,046] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:47:07,466] {logging_mixin.py:104} INFO - [2021-08-17 18:47:07,465] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 18:47:07,469] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:47:07,479] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.436 seconds
[2021-08-17 18:47:38,356] {scheduler_job.py:182} INFO - Started process (PID=20421) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:47:38,357] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 18:47:38,358] {logging_mixin.py:104} INFO - [2021-08-17 18:47:38,358] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:47:38,800] {logging_mixin.py:104} INFO - [2021-08-17 18:47:38,798] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 18:47:38,802] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:47:38,813] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.458 seconds
[2021-08-17 18:48:09,756] {scheduler_job.py:182} INFO - Started process (PID=20486) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:48:09,757] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 18:48:09,758] {logging_mixin.py:104} INFO - [2021-08-17 18:48:09,758] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:48:10,206] {logging_mixin.py:104} INFO - [2021-08-17 18:48:10,204] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 18:48:10,208] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:48:10,218] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.464 seconds
[2021-08-17 18:48:40,255] {scheduler_job.py:182} INFO - Started process (PID=20552) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:48:40,256] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 18:48:40,257] {logging_mixin.py:104} INFO - [2021-08-17 18:48:40,257] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:48:40,758] {logging_mixin.py:104} INFO - [2021-08-17 18:48:40,756] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 18:48:40,760] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:48:40,771] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.518 seconds
[2021-08-17 18:49:11,629] {scheduler_job.py:182} INFO - Started process (PID=20617) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:49:11,630] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 18:49:11,631] {logging_mixin.py:104} INFO - [2021-08-17 18:49:11,631] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:49:12,067] {logging_mixin.py:104} INFO - [2021-08-17 18:49:12,066] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 18:49:12,070] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:49:12,080] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.453 seconds
[2021-08-17 18:49:42,966] {scheduler_job.py:182} INFO - Started process (PID=20681) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:49:42,967] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 18:49:42,968] {logging_mixin.py:104} INFO - [2021-08-17 18:49:42,968] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:49:43,409] {logging_mixin.py:104} INFO - [2021-08-17 18:49:43,408] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 18:49:43,412] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:49:43,423] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.458 seconds
[2021-08-17 18:50:14,159] {scheduler_job.py:182} INFO - Started process (PID=20746) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:50:14,160] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 18:50:14,161] {logging_mixin.py:104} INFO - [2021-08-17 18:50:14,161] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:50:14,591] {logging_mixin.py:104} INFO - [2021-08-17 18:50:14,589] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 18:50:14,593] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:50:14,604] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.446 seconds
[2021-08-17 18:50:45,316] {scheduler_job.py:182} INFO - Started process (PID=20811) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:50:45,316] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 18:50:45,317] {logging_mixin.py:104} INFO - [2021-08-17 18:50:45,317] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:50:45,749] {logging_mixin.py:104} INFO - [2021-08-17 18:50:45,747] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 18:50:45,752] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:50:45,770] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.456 seconds
[2021-08-17 18:51:15,861] {scheduler_job.py:182} INFO - Started process (PID=20878) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:51:15,861] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 18:51:15,862] {logging_mixin.py:104} INFO - [2021-08-17 18:51:15,862] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:51:16,582] {logging_mixin.py:104} INFO - [2021-08-17 18:51:16,580] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 18:51:16,584] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:51:16,602] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.743 seconds
[2021-08-17 18:51:46,889] {scheduler_job.py:182} INFO - Started process (PID=20944) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:51:46,891] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 18:51:46,892] {logging_mixin.py:104} INFO - [2021-08-17 18:51:46,892] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:51:47,362] {logging_mixin.py:104} INFO - [2021-08-17 18:51:47,360] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 18:51:47,364] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:51:47,378] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.492 seconds
[2021-08-17 18:52:17,479] {scheduler_job.py:182} INFO - Started process (PID=21010) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:52:17,480] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 18:52:17,481] {logging_mixin.py:104} INFO - [2021-08-17 18:52:17,481] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:52:17,910] {logging_mixin.py:104} INFO - [2021-08-17 18:52:17,908] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 18:52:17,913] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:52:17,925] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.447 seconds
[2021-08-17 18:52:48,745] {scheduler_job.py:182} INFO - Started process (PID=21077) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:52:48,746] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 18:52:48,746] {logging_mixin.py:104} INFO - [2021-08-17 18:52:48,746] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:52:49,199] {logging_mixin.py:104} INFO - [2021-08-17 18:52:49,197] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 18:52:49,201] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:52:49,214] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.471 seconds
[2021-08-17 18:53:19,940] {scheduler_job.py:182} INFO - Started process (PID=21144) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:53:19,941] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 18:53:19,942] {logging_mixin.py:104} INFO - [2021-08-17 18:53:19,941] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:53:20,373] {logging_mixin.py:104} INFO - [2021-08-17 18:53:20,372] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 18:53:20,376] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:53:20,387] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.449 seconds
[2021-08-17 18:53:51,127] {scheduler_job.py:182} INFO - Started process (PID=21211) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:53:51,128] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 18:53:51,129] {logging_mixin.py:104} INFO - [2021-08-17 18:53:51,129] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:53:51,580] {logging_mixin.py:104} INFO - [2021-08-17 18:53:51,578] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 18:53:51,582] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:53:51,593] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.468 seconds
[2021-08-17 18:54:22,352] {scheduler_job.py:182} INFO - Started process (PID=21278) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:54:22,353] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 18:54:22,353] {logging_mixin.py:104} INFO - [2021-08-17 18:54:22,353] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:54:44,727] {logging_mixin.py:104} INFO - [2021-08-17 18:54:44,726] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 18:54:44,728] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:54:44,737] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 22.387 seconds
[2021-08-17 18:55:14,805] {scheduler_job.py:182} INFO - Started process (PID=21388) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:55:14,806] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 18:55:14,807] {logging_mixin.py:104} INFO - [2021-08-17 18:55:14,807] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:55:15,257] {logging_mixin.py:104} INFO - [2021-08-17 18:55:15,256] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 18:55:15,260] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:55:15,271] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.468 seconds
[2021-08-17 18:55:45,420] {scheduler_job.py:182} INFO - Started process (PID=21454) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:55:45,422] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 18:55:45,422] {logging_mixin.py:104} INFO - [2021-08-17 18:55:45,422] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:55:45,895] {logging_mixin.py:104} INFO - [2021-08-17 18:55:45,893] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 18:55:45,897] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:55:45,911] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.492 seconds
[2021-08-17 18:56:16,600] {scheduler_job.py:182} INFO - Started process (PID=21514) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:56:16,600] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 18:56:16,601] {logging_mixin.py:104} INFO - [2021-08-17 18:56:16,601] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:56:17,028] {logging_mixin.py:104} INFO - [2021-08-17 18:56:17,026] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 18:56:17,031] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:56:17,041] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.443 seconds
[2021-08-17 18:56:47,086] {scheduler_job.py:182} INFO - Started process (PID=21579) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:56:47,087] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 18:56:47,088] {logging_mixin.py:104} INFO - [2021-08-17 18:56:47,088] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:56:47,812] {logging_mixin.py:104} INFO - [2021-08-17 18:56:47,810] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 18:56:47,816] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:56:47,826] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.741 seconds
[2021-08-17 18:57:17,902] {scheduler_job.py:182} INFO - Started process (PID=21643) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:57:17,903] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 18:57:17,903] {logging_mixin.py:104} INFO - [2021-08-17 18:57:17,903] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:57:18,336] {logging_mixin.py:104} INFO - [2021-08-17 18:57:18,335] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 18:57:18,339] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:57:18,349] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.449 seconds
[2021-08-17 18:57:48,460] {scheduler_job.py:182} INFO - Started process (PID=21711) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:57:48,460] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 18:57:48,461] {logging_mixin.py:104} INFO - [2021-08-17 18:57:48,461] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:57:48,890] {logging_mixin.py:104} INFO - [2021-08-17 18:57:48,888] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 18:57:48,892] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:57:48,902] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.444 seconds
[2021-08-17 18:58:19,152] {scheduler_job.py:182} INFO - Started process (PID=21774) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:58:19,154] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 18:58:19,156] {logging_mixin.py:104} INFO - [2021-08-17 18:58:19,156] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:58:19,641] {logging_mixin.py:104} INFO - [2021-08-17 18:58:19,640] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 18:58:19,644] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:58:19,658] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.508 seconds
[2021-08-17 18:58:50,248] {scheduler_job.py:182} INFO - Started process (PID=21838) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:58:50,249] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 18:58:50,250] {logging_mixin.py:104} INFO - [2021-08-17 18:58:50,249] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:58:50,692] {logging_mixin.py:104} INFO - [2021-08-17 18:58:50,691] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 18:58:50,695] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:58:50,706] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.460 seconds
[2021-08-17 18:59:21,637] {scheduler_job.py:182} INFO - Started process (PID=21907) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:59:21,638] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 18:59:21,639] {logging_mixin.py:104} INFO - [2021-08-17 18:59:21,639] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:59:22,077] {logging_mixin.py:104} INFO - [2021-08-17 18:59:22,075] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 18:59:22,079] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:59:22,097] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.461 seconds
[2021-08-17 18:59:52,306] {scheduler_job.py:182} INFO - Started process (PID=21974) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:59:52,308] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 18:59:52,308] {logging_mixin.py:104} INFO - [2021-08-17 18:59:52,308] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:59:52,729] {logging_mixin.py:104} INFO - [2021-08-17 18:59:52,728] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 18:59:52,732] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 18:59:52,742] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.438 seconds
[2021-08-17 19:00:23,424] {scheduler_job.py:182} INFO - Started process (PID=22039) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:00:23,425] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 19:00:23,426] {logging_mixin.py:104} INFO - [2021-08-17 19:00:23,426] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:00:23,861] {logging_mixin.py:104} INFO - [2021-08-17 19:00:23,859] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 19:00:23,864] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:00:23,874] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.452 seconds
[2021-08-17 19:00:54,054] {scheduler_job.py:182} INFO - Started process (PID=22105) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:00:54,055] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 19:00:54,056] {logging_mixin.py:104} INFO - [2021-08-17 19:00:54,056] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:00:54,502] {logging_mixin.py:104} INFO - [2021-08-17 19:00:54,500] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 19:00:54,504] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:00:54,515] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.462 seconds
[2021-08-17 19:01:25,092] {scheduler_job.py:182} INFO - Started process (PID=22170) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:01:25,093] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 19:01:25,094] {logging_mixin.py:104} INFO - [2021-08-17 19:01:25,094] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:01:25,523] {logging_mixin.py:104} INFO - [2021-08-17 19:01:25,522] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 19:01:25,526] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:01:25,538] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.448 seconds
[2021-08-17 19:01:56,474] {scheduler_job.py:182} INFO - Started process (PID=22235) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:01:56,476] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 19:01:56,476] {logging_mixin.py:104} INFO - [2021-08-17 19:01:56,476] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:01:56,925] {logging_mixin.py:104} INFO - [2021-08-17 19:01:56,924] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 19:01:56,928] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:01:56,939] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.467 seconds
[2021-08-17 19:02:27,748] {scheduler_job.py:182} INFO - Started process (PID=22310) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:02:27,749] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 19:02:27,749] {logging_mixin.py:104} INFO - [2021-08-17 19:02:27,749] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:02:28,195] {logging_mixin.py:104} INFO - [2021-08-17 19:02:28,194] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 19:02:28,198] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:02:28,209] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.463 seconds
[2021-08-17 19:02:58,940] {scheduler_job.py:182} INFO - Started process (PID=22373) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:02:58,940] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 19:02:58,941] {logging_mixin.py:104} INFO - [2021-08-17 19:02:58,941] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:02:59,398] {logging_mixin.py:104} INFO - [2021-08-17 19:02:59,397] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 19:02:59,401] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:02:59,412] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.474 seconds
[2021-08-17 19:03:30,045] {scheduler_job.py:182} INFO - Started process (PID=22438) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:03:30,046] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 19:03:30,047] {logging_mixin.py:104} INFO - [2021-08-17 19:03:30,047] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:03:30,525] {logging_mixin.py:104} INFO - [2021-08-17 19:03:30,524] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 19:03:30,528] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:03:30,546] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.503 seconds
[2021-08-17 19:04:01,232] {scheduler_job.py:182} INFO - Started process (PID=22506) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:04:01,234] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 19:04:01,236] {logging_mixin.py:104} INFO - [2021-08-17 19:04:01,236] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:04:01,670] {logging_mixin.py:104} INFO - [2021-08-17 19:04:01,668] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 19:04:01,672] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:04:01,691] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.461 seconds
[2021-08-17 19:04:32,489] {scheduler_job.py:182} INFO - Started process (PID=22569) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:04:32,490] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 19:04:32,490] {logging_mixin.py:104} INFO - [2021-08-17 19:04:32,490] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:04:32,936] {logging_mixin.py:104} INFO - [2021-08-17 19:04:32,934] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 19:04:32,939] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:04:32,952] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.466 seconds
[2021-08-17 19:05:03,756] {scheduler_job.py:182} INFO - Started process (PID=22629) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:05:03,757] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 19:05:03,758] {logging_mixin.py:104} INFO - [2021-08-17 19:05:03,757] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:05:04,243] {logging_mixin.py:104} INFO - [2021-08-17 19:05:04,241] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 19:05:04,246] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:05:04,258] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.504 seconds
[2021-08-17 19:05:34,890] {scheduler_job.py:182} INFO - Started process (PID=22685) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:05:34,891] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 19:05:34,892] {logging_mixin.py:104} INFO - [2021-08-17 19:05:34,891] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:05:35,336] {logging_mixin.py:104} INFO - [2021-08-17 19:05:35,334] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 19:05:35,338] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:05:35,358] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.471 seconds
[2021-08-17 19:06:06,134] {scheduler_job.py:182} INFO - Started process (PID=22747) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:06:06,135] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 19:06:06,136] {logging_mixin.py:104} INFO - [2021-08-17 19:06:06,136] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:06:06,569] {logging_mixin.py:104} INFO - [2021-08-17 19:06:06,568] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 19:06:06,572] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:06:06,584] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.451 seconds
[2021-08-17 19:06:37,467] {scheduler_job.py:182} INFO - Started process (PID=22810) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:06:37,469] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 19:06:37,469] {logging_mixin.py:104} INFO - [2021-08-17 19:06:37,469] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:06:38,908] {logging_mixin.py:104} INFO - [2021-08-17 19:06:38,906] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 19:06:38,913] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:06:38,925] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 1.459 seconds
[2021-08-17 19:07:09,650] {scheduler_job.py:182} INFO - Started process (PID=22874) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:07:09,651] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 19:07:09,652] {logging_mixin.py:104} INFO - [2021-08-17 19:07:09,652] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:07:10,095] {logging_mixin.py:104} INFO - [2021-08-17 19:07:10,093] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 19:07:10,097] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:07:10,110] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.461 seconds
[2021-08-17 19:07:40,967] {scheduler_job.py:182} INFO - Started process (PID=22939) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:07:40,968] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 19:07:40,969] {logging_mixin.py:104} INFO - [2021-08-17 19:07:40,969] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:07:41,442] {logging_mixin.py:104} INFO - [2021-08-17 19:07:41,441] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 19:07:41,445] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:07:41,458] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.492 seconds
[2021-08-17 19:08:12,132] {scheduler_job.py:182} INFO - Started process (PID=23005) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:08:12,134] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 19:08:12,134] {logging_mixin.py:104} INFO - [2021-08-17 19:08:12,134] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:08:12,577] {logging_mixin.py:104} INFO - [2021-08-17 19:08:12,575] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 19:08:12,580] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:08:12,591] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.460 seconds
[2021-08-17 19:08:43,421] {scheduler_job.py:182} INFO - Started process (PID=23075) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:08:43,422] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 19:08:43,423] {logging_mixin.py:104} INFO - [2021-08-17 19:08:43,423] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:08:43,891] {logging_mixin.py:104} INFO - [2021-08-17 19:08:43,889] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 19:08:43,893] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:08:43,904] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.486 seconds
[2021-08-17 19:09:14,815] {scheduler_job.py:182} INFO - Started process (PID=23146) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:09:14,816] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 19:09:14,817] {logging_mixin.py:104} INFO - [2021-08-17 19:09:14,817] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:09:15,364] {logging_mixin.py:104} INFO - [2021-08-17 19:09:15,362] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 19:09:15,367] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:09:15,378] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.565 seconds
[2021-08-17 19:09:46,052] {scheduler_job.py:182} INFO - Started process (PID=23209) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:09:46,054] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 19:09:46,055] {logging_mixin.py:104} INFO - [2021-08-17 19:09:46,055] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:09:46,532] {logging_mixin.py:104} INFO - [2021-08-17 19:09:46,530] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 19:09:46,535] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:09:46,546] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.496 seconds
[2021-08-17 19:10:17,564] {scheduler_job.py:182} INFO - Started process (PID=23279) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:10:17,565] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 19:10:17,566] {logging_mixin.py:104} INFO - [2021-08-17 19:10:17,566] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:10:18,012] {logging_mixin.py:104} INFO - [2021-08-17 19:10:18,010] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 19:10:18,015] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:10:18,027] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.465 seconds
[2021-08-17 19:10:48,939] {scheduler_job.py:182} INFO - Started process (PID=23355) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:10:48,940] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 19:10:48,941] {logging_mixin.py:104} INFO - [2021-08-17 19:10:48,941] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:10:49,381] {logging_mixin.py:104} INFO - [2021-08-17 19:10:49,380] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 19:10:49,384] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:10:49,396] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.459 seconds
[2021-08-17 19:11:19,448] {scheduler_job.py:182} INFO - Started process (PID=23422) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:11:19,449] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 19:11:19,450] {logging_mixin.py:104} INFO - [2021-08-17 19:11:19,450] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:11:19,922] {logging_mixin.py:104} INFO - [2021-08-17 19:11:19,921] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 19:11:19,925] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:11:19,937] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.491 seconds
[2021-08-17 19:11:50,061] {scheduler_job.py:182} INFO - Started process (PID=23488) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:11:50,062] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 19:11:50,063] {logging_mixin.py:104} INFO - [2021-08-17 19:11:50,063] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:11:50,522] {logging_mixin.py:104} INFO - [2021-08-17 19:11:50,520] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 19:11:50,525] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:11:50,536] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.477 seconds
[2021-08-17 19:12:20,603] {scheduler_job.py:182} INFO - Started process (PID=23562) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:12:20,604] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 19:12:20,605] {logging_mixin.py:104} INFO - [2021-08-17 19:12:20,605] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:12:21,077] {logging_mixin.py:104} INFO - [2021-08-17 19:12:21,076] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 19:12:21,080] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:12:21,090] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.489 seconds
[2021-08-17 19:12:51,628] {scheduler_job.py:182} INFO - Started process (PID=23626) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:12:51,629] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 19:12:51,629] {logging_mixin.py:104} INFO - [2021-08-17 19:12:51,629] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:12:52,121] {logging_mixin.py:104} INFO - [2021-08-17 19:12:52,120] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 19:12:52,124] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:12:52,135] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.509 seconds
[2021-08-17 19:13:22,940] {scheduler_job.py:182} INFO - Started process (PID=23695) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:13:22,941] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 19:13:22,942] {logging_mixin.py:104} INFO - [2021-08-17 19:13:22,942] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:13:23,400] {logging_mixin.py:104} INFO - [2021-08-17 19:13:23,398] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 19:13:23,403] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:13:23,414] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.476 seconds
[2021-08-17 19:13:54,227] {scheduler_job.py:182} INFO - Started process (PID=23759) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:13:54,228] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 19:13:54,229] {logging_mixin.py:104} INFO - [2021-08-17 19:13:54,229] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:13:55,214] {logging_mixin.py:104} INFO - [2021-08-17 19:13:55,212] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 19:13:55,217] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:13:55,232] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 1.006 seconds
[2021-08-17 19:14:25,467] {scheduler_job.py:182} INFO - Started process (PID=23821) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:14:25,467] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 19:14:25,468] {logging_mixin.py:104} INFO - [2021-08-17 19:14:25,468] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:14:25,911] {logging_mixin.py:104} INFO - [2021-08-17 19:14:25,909] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 19:14:25,914] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:14:25,932] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.468 seconds
[2021-08-17 19:14:56,651] {scheduler_job.py:182} INFO - Started process (PID=23886) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:14:56,652] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 19:14:56,653] {logging_mixin.py:104} INFO - [2021-08-17 19:14:56,653] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:14:57,093] {logging_mixin.py:104} INFO - [2021-08-17 19:14:57,092] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 19:14:57,096] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:14:57,107] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.459 seconds
[2021-08-17 19:15:27,913] {scheduler_job.py:182} INFO - Started process (PID=23952) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:15:27,914] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 19:15:27,915] {logging_mixin.py:104} INFO - [2021-08-17 19:15:27,914] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:15:28,381] {logging_mixin.py:104} INFO - [2021-08-17 19:15:28,380] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 19:15:28,384] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:15:28,396] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.484 seconds
[2021-08-17 19:15:59,303] {scheduler_job.py:182} INFO - Started process (PID=24020) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:15:59,304] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 19:15:59,305] {logging_mixin.py:104} INFO - [2021-08-17 19:15:59,304] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:15:59,748] {logging_mixin.py:104} INFO - [2021-08-17 19:15:59,747] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 19:15:59,751] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:15:59,770] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.469 seconds
[2021-08-17 19:16:29,879] {scheduler_job.py:182} INFO - Started process (PID=24086) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:16:29,880] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 19:16:29,881] {logging_mixin.py:104} INFO - [2021-08-17 19:16:29,881] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:16:30,336] {logging_mixin.py:104} INFO - [2021-08-17 19:16:30,334] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 19:16:30,339] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:16:30,351] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.474 seconds
[2021-08-17 19:17:00,479] {scheduler_job.py:182} INFO - Started process (PID=24148) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:17:00,481] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 19:17:00,481] {logging_mixin.py:104} INFO - [2021-08-17 19:17:00,481] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:17:00,954] {logging_mixin.py:104} INFO - [2021-08-17 19:17:00,952] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 19:17:00,957] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:17:00,968] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.491 seconds
[2021-08-17 19:17:31,025] {scheduler_job.py:182} INFO - Started process (PID=24203) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:17:31,026] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 19:17:31,027] {logging_mixin.py:104} INFO - [2021-08-17 19:17:31,026] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:17:31,495] {logging_mixin.py:104} INFO - [2021-08-17 19:17:31,493] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 19:17:31,498] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:17:31,516] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.493 seconds
[2021-08-17 19:18:01,684] {scheduler_job.py:182} INFO - Started process (PID=24265) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:18:01,685] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 19:18:01,685] {logging_mixin.py:104} INFO - [2021-08-17 19:18:01,685] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:18:02,155] {logging_mixin.py:104} INFO - [2021-08-17 19:18:02,153] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 19:18:02,158] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:18:02,168] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.486 seconds
[2021-08-17 19:18:32,868] {scheduler_job.py:182} INFO - Started process (PID=24329) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:18:32,869] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 19:18:32,870] {logging_mixin.py:104} INFO - [2021-08-17 19:18:32,870] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:18:33,300] {logging_mixin.py:104} INFO - [2021-08-17 19:18:33,298] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 19:18:33,302] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:18:33,314] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.447 seconds
[2021-08-17 19:19:04,079] {scheduler_job.py:182} INFO - Started process (PID=24394) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:19:04,079] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 19:19:04,080] {logging_mixin.py:104} INFO - [2021-08-17 19:19:04,080] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:19:04,523] {logging_mixin.py:104} INFO - [2021-08-17 19:19:04,521] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 19:19:04,525] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:19:04,537] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.460 seconds
[2021-08-17 19:19:34,761] {scheduler_job.py:182} INFO - Started process (PID=24456) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:19:34,762] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 19:19:34,763] {logging_mixin.py:104} INFO - [2021-08-17 19:19:34,763] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:19:35,220] {logging_mixin.py:104} INFO - [2021-08-17 19:19:35,219] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 19:19:35,223] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:19:35,233] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.474 seconds
[2021-08-17 19:20:05,353] {scheduler_job.py:182} INFO - Started process (PID=24520) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:20:05,354] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 19:20:05,355] {logging_mixin.py:104} INFO - [2021-08-17 19:20:05,355] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:20:05,824] {logging_mixin.py:104} INFO - [2021-08-17 19:20:05,822] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 19:20:05,826] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:20:05,837] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.486 seconds
[2021-08-17 19:20:36,051] {scheduler_job.py:182} INFO - Started process (PID=24583) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:20:36,052] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 19:20:36,053] {logging_mixin.py:104} INFO - [2021-08-17 19:20:36,052] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:20:36,749] {logging_mixin.py:104} INFO - [2021-08-17 19:20:36,747] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 19:20:36,752] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:20:36,763] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.714 seconds
[2021-08-17 19:21:07,219] {scheduler_job.py:182} INFO - Started process (PID=24646) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:21:07,220] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 19:21:07,221] {logging_mixin.py:104} INFO - [2021-08-17 19:21:07,221] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:21:08,733] {logging_mixin.py:104} INFO - [2021-08-17 19:21:08,732] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 19:21:08,736] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:21:08,746] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 1.528 seconds
[2021-08-17 19:21:38,948] {scheduler_job.py:182} INFO - Started process (PID=24711) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:21:38,950] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 19:21:38,951] {logging_mixin.py:104} INFO - [2021-08-17 19:21:38,951] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:21:39,485] {logging_mixin.py:104} INFO - [2021-08-17 19:21:39,484] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 19:21:39,488] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:21:39,497] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.551 seconds
[2021-08-17 19:22:09,606] {scheduler_job.py:182} INFO - Started process (PID=24774) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:22:09,607] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 19:22:09,607] {logging_mixin.py:104} INFO - [2021-08-17 19:22:09,607] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:22:10,068] {logging_mixin.py:104} INFO - [2021-08-17 19:22:10,067] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 19:22:10,071] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:22:10,081] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.478 seconds
[2021-08-17 19:22:40,241] {scheduler_job.py:182} INFO - Started process (PID=24838) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:22:40,242] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 19:22:40,243] {logging_mixin.py:104} INFO - [2021-08-17 19:22:40,243] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:22:40,713] {logging_mixin.py:104} INFO - [2021-08-17 19:22:40,712] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 19:22:40,716] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:22:40,725] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.488 seconds
[2021-08-17 19:23:10,908] {scheduler_job.py:182} INFO - Started process (PID=24903) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:23:10,909] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 19:23:10,910] {logging_mixin.py:104} INFO - [2021-08-17 19:23:10,910] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:23:11,366] {logging_mixin.py:104} INFO - [2021-08-17 19:23:11,364] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 19:23:11,368] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:23:11,378] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.471 seconds
[2021-08-17 19:23:41,995] {scheduler_job.py:182} INFO - Started process (PID=24967) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:23:41,996] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 19:23:41,997] {logging_mixin.py:104} INFO - [2021-08-17 19:23:41,997] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:23:42,445] {logging_mixin.py:104} INFO - [2021-08-17 19:23:42,444] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 19:23:42,448] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:23:42,459] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.466 seconds
[2021-08-17 19:24:12,623] {scheduler_job.py:182} INFO - Started process (PID=25031) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:24:12,623] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 19:24:12,624] {logging_mixin.py:104} INFO - [2021-08-17 19:24:12,624] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:24:13,059] {logging_mixin.py:104} INFO - [2021-08-17 19:24:13,057] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 19:24:13,061] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:24:13,083] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.463 seconds
[2021-08-17 19:24:43,410] {scheduler_job.py:182} INFO - Started process (PID=25086) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:24:43,411] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 19:24:43,411] {logging_mixin.py:104} INFO - [2021-08-17 19:24:43,411] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:24:43,849] {logging_mixin.py:104} INFO - [2021-08-17 19:24:43,847] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 19:24:43,852] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:24:43,870] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.462 seconds
[2021-08-17 19:25:14,552] {scheduler_job.py:182} INFO - Started process (PID=25149) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:25:14,553] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 19:25:14,554] {logging_mixin.py:104} INFO - [2021-08-17 19:25:14,553] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:25:15,033] {logging_mixin.py:104} INFO - [2021-08-17 19:25:15,032] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 19:25:15,035] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:25:15,053] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.504 seconds
[2021-08-17 19:25:45,949] {scheduler_job.py:182} INFO - Started process (PID=25211) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:25:45,950] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 19:25:45,951] {logging_mixin.py:104} INFO - [2021-08-17 19:25:45,951] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:25:46,538] {logging_mixin.py:104} INFO - [2021-08-17 19:25:46,536] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 19:25:46,542] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:25:46,553] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.610 seconds
[2021-08-17 19:26:16,797] {scheduler_job.py:182} INFO - Started process (PID=25278) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:26:16,800] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 19:26:16,802] {logging_mixin.py:104} INFO - [2021-08-17 19:26:16,802] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:26:17,310] {logging_mixin.py:104} INFO - [2021-08-17 19:26:17,309] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 19:26:17,313] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:26:17,322] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.527 seconds
[2021-08-17 19:26:47,997] {scheduler_job.py:182} INFO - Started process (PID=25345) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:26:47,998] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 19:26:47,999] {logging_mixin.py:104} INFO - [2021-08-17 19:26:47,999] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:26:48,431] {logging_mixin.py:104} INFO - [2021-08-17 19:26:48,429] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 19:26:48,434] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:26:48,445] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.449 seconds
[2021-08-17 19:27:19,220] {scheduler_job.py:182} INFO - Started process (PID=25411) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:27:19,221] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 19:27:19,222] {logging_mixin.py:104} INFO - [2021-08-17 19:27:19,222] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:27:19,661] {logging_mixin.py:104} INFO - [2021-08-17 19:27:19,660] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 19:27:19,663] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:27:19,673] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.455 seconds
[2021-08-17 19:27:50,519] {scheduler_job.py:182} INFO - Started process (PID=25475) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:27:50,520] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 19:27:50,521] {logging_mixin.py:104} INFO - [2021-08-17 19:27:50,521] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:27:50,971] {logging_mixin.py:104} INFO - [2021-08-17 19:27:50,969] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 19:27:50,973] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:27:50,985] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.468 seconds
[2021-08-17 19:28:21,045] {scheduler_job.py:182} INFO - Started process (PID=25540) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:28:21,046] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 19:28:21,047] {logging_mixin.py:104} INFO - [2021-08-17 19:28:21,047] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:28:21,493] {logging_mixin.py:104} INFO - [2021-08-17 19:28:21,492] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 19:28:21,496] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:28:21,507] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.464 seconds
[2021-08-17 19:28:52,427] {scheduler_job.py:182} INFO - Started process (PID=25605) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:28:52,428] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 19:28:52,429] {logging_mixin.py:104} INFO - [2021-08-17 19:28:52,429] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:28:52,851] {logging_mixin.py:104} INFO - [2021-08-17 19:28:52,850] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 19:28:52,854] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:28:52,866] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.441 seconds
[2021-08-17 19:29:22,911] {scheduler_job.py:182} INFO - Started process (PID=25672) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:29:22,911] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 19:29:22,912] {logging_mixin.py:104} INFO - [2021-08-17 19:29:22,912] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:29:44,659] {logging_mixin.py:104} INFO - [2021-08-17 19:29:44,657] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 19:29:44,660] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:29:44,671] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 21.762 seconds
[2021-08-17 19:30:15,170] {scheduler_job.py:182} INFO - Started process (PID=25783) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:30:15,171] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 19:30:15,171] {logging_mixin.py:104} INFO - [2021-08-17 19:30:15,171] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:30:15,890] {logging_mixin.py:104} INFO - [2021-08-17 19:30:15,888] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 19:30:15,892] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:30:15,903] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.735 seconds
[2021-08-17 19:30:46,249] {scheduler_job.py:182} INFO - Started process (PID=25847) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:30:46,250] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 19:30:46,251] {logging_mixin.py:104} INFO - [2021-08-17 19:30:46,251] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:30:46,706] {logging_mixin.py:104} INFO - [2021-08-17 19:30:46,704] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 19:30:46,708] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:30:46,720] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.473 seconds
[2021-08-17 19:31:17,526] {scheduler_job.py:182} INFO - Started process (PID=25909) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:31:17,527] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 19:31:17,527] {logging_mixin.py:104} INFO - [2021-08-17 19:31:17,527] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:31:17,979] {logging_mixin.py:104} INFO - [2021-08-17 19:31:17,977] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 19:31:17,982] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:31:17,992] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.468 seconds
[2021-08-17 19:31:48,736] {scheduler_job.py:182} INFO - Started process (PID=25977) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:31:48,737] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 19:31:48,738] {logging_mixin.py:104} INFO - [2021-08-17 19:31:48,738] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:31:49,170] {logging_mixin.py:104} INFO - [2021-08-17 19:31:49,169] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 19:31:49,173] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:31:49,185] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.451 seconds
[2021-08-17 19:32:19,970] {scheduler_job.py:182} INFO - Started process (PID=26044) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:32:19,971] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 19:32:19,972] {logging_mixin.py:104} INFO - [2021-08-17 19:32:19,972] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:32:20,454] {logging_mixin.py:104} INFO - [2021-08-17 19:32:20,452] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 19:32:20,458] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:32:20,469] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.500 seconds
[2021-08-17 19:32:51,097] {scheduler_job.py:182} INFO - Started process (PID=26111) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:32:51,098] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 19:32:51,098] {logging_mixin.py:104} INFO - [2021-08-17 19:32:51,098] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:32:51,522] {logging_mixin.py:104} INFO - [2021-08-17 19:32:51,521] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 19:32:51,525] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:32:51,544] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.449 seconds
[2021-08-17 19:33:21,664] {scheduler_job.py:182} INFO - Started process (PID=26176) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:33:21,665] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 19:33:21,666] {logging_mixin.py:104} INFO - [2021-08-17 19:33:21,666] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:33:22,094] {logging_mixin.py:104} INFO - [2021-08-17 19:33:22,093] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 19:33:22,097] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:33:22,106] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.444 seconds
[2021-08-17 19:33:52,360] {scheduler_job.py:182} INFO - Started process (PID=26238) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:33:52,361] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 19:33:52,361] {logging_mixin.py:104} INFO - [2021-08-17 19:33:52,361] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:33:52,788] {logging_mixin.py:104} INFO - [2021-08-17 19:33:52,787] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 19:33:52,791] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:33:52,808] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.451 seconds
[2021-08-17 19:34:23,093] {scheduler_job.py:182} INFO - Started process (PID=26292) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:34:23,094] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 19:34:23,095] {logging_mixin.py:104} INFO - [2021-08-17 19:34:23,095] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:34:23,516] {logging_mixin.py:104} INFO - [2021-08-17 19:34:23,515] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 19:34:23,519] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:34:23,529] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.438 seconds
[2021-08-17 19:34:53,817] {scheduler_job.py:182} INFO - Started process (PID=26357) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:34:53,818] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 19:34:53,819] {logging_mixin.py:104} INFO - [2021-08-17 19:34:53,819] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:34:54,249] {logging_mixin.py:104} INFO - [2021-08-17 19:34:54,248] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 19:34:54,252] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:34:54,263] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.448 seconds
[2021-08-17 19:35:24,558] {scheduler_job.py:182} INFO - Started process (PID=26420) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:35:24,559] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 19:35:24,560] {logging_mixin.py:104} INFO - [2021-08-17 19:35:24,560] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:35:25,184] {logging_mixin.py:104} INFO - [2021-08-17 19:35:25,183] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 19:35:25,186] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:35:25,202] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.646 seconds
[2021-08-17 19:35:56,002] {scheduler_job.py:182} INFO - Started process (PID=26488) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:35:56,004] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 19:35:56,004] {logging_mixin.py:104} INFO - [2021-08-17 19:35:56,004] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:35:56,504] {logging_mixin.py:104} INFO - [2021-08-17 19:35:56,494] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 19:35:56,507] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:35:56,516] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.516 seconds
[2021-08-17 19:36:27,253] {scheduler_job.py:182} INFO - Started process (PID=26554) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:36:27,254] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 19:36:27,254] {logging_mixin.py:104} INFO - [2021-08-17 19:36:27,254] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:36:27,683] {logging_mixin.py:104} INFO - [2021-08-17 19:36:27,682] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 19:36:27,686] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:36:27,698] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.446 seconds
[2021-08-17 19:36:58,653] {scheduler_job.py:182} INFO - Started process (PID=26620) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:36:58,655] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 19:36:58,656] {logging_mixin.py:104} INFO - [2021-08-17 19:36:58,656] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:36:59,103] {logging_mixin.py:104} INFO - [2021-08-17 19:36:59,102] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 19:36:59,106] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:36:59,118] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.467 seconds
[2021-08-17 19:37:29,872] {scheduler_job.py:182} INFO - Started process (PID=26683) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:37:29,873] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 19:37:29,873] {logging_mixin.py:104} INFO - [2021-08-17 19:37:29,873] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:37:30,314] {logging_mixin.py:104} INFO - [2021-08-17 19:37:30,312] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 19:37:30,317] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:37:30,328] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.458 seconds
[2021-08-17 19:38:01,239] {scheduler_job.py:182} INFO - Started process (PID=26748) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:38:01,240] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 19:38:01,241] {logging_mixin.py:104} INFO - [2021-08-17 19:38:01,241] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:38:01,684] {logging_mixin.py:104} INFO - [2021-08-17 19:38:01,683] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 19:38:01,687] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:38:01,698] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.461 seconds
[2021-08-17 19:38:32,405] {scheduler_job.py:182} INFO - Started process (PID=26812) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:38:32,406] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 19:38:32,406] {logging_mixin.py:104} INFO - [2021-08-17 19:38:32,406] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:38:32,875] {logging_mixin.py:104} INFO - [2021-08-17 19:38:32,873] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 19:38:32,878] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:38:32,889] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.486 seconds
[2021-08-17 19:39:03,771] {scheduler_job.py:182} INFO - Started process (PID=26877) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:39:03,772] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 19:39:03,773] {logging_mixin.py:104} INFO - [2021-08-17 19:39:03,773] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:39:04,207] {logging_mixin.py:104} INFO - [2021-08-17 19:39:04,205] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 19:39:04,210] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:39:04,220] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.451 seconds
[2021-08-17 19:39:34,705] {scheduler_job.py:182} INFO - Started process (PID=26948) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:39:34,707] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 19:39:34,708] {logging_mixin.py:104} INFO - [2021-08-17 19:39:34,707] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:39:35,156] {logging_mixin.py:104} INFO - [2021-08-17 19:39:35,154] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 19:39:35,159] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:39:35,169] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.467 seconds
[2021-08-17 19:40:05,225] {scheduler_job.py:182} INFO - Started process (PID=27010) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:40:05,226] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 19:40:05,226] {logging_mixin.py:104} INFO - [2021-08-17 19:40:05,226] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:40:05,683] {logging_mixin.py:104} INFO - [2021-08-17 19:40:05,681] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 19:40:05,685] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:40:05,697] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.474 seconds
[2021-08-17 19:40:36,383] {scheduler_job.py:182} INFO - Started process (PID=27076) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:40:36,384] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 19:40:36,385] {logging_mixin.py:104} INFO - [2021-08-17 19:40:36,384] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:40:37,094] {logging_mixin.py:104} INFO - [2021-08-17 19:40:37,093] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 19:40:37,097] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:40:37,108] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.727 seconds
[2021-08-17 19:41:07,714] {scheduler_job.py:182} INFO - Started process (PID=27142) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:41:07,715] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 19:41:07,716] {logging_mixin.py:104} INFO - [2021-08-17 19:41:07,716] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:41:08,145] {logging_mixin.py:104} INFO - [2021-08-17 19:41:08,143] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 19:41:08,148] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:41:08,158] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.446 seconds
[2021-08-17 19:41:38,293] {scheduler_job.py:182} INFO - Started process (PID=27209) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:41:38,294] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 19:41:38,295] {logging_mixin.py:104} INFO - [2021-08-17 19:41:38,295] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:41:38,737] {logging_mixin.py:104} INFO - [2021-08-17 19:41:38,736] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 19:41:38,740] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:41:38,757] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.467 seconds
[2021-08-17 19:42:09,612] {scheduler_job.py:182} INFO - Started process (PID=27274) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:42:09,619] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 19:42:09,620] {logging_mixin.py:104} INFO - [2021-08-17 19:42:09,620] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:42:10,059] {logging_mixin.py:104} INFO - [2021-08-17 19:42:10,058] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 19:42:10,061] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:42:10,072] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.463 seconds
[2021-08-17 19:42:40,849] {scheduler_job.py:182} INFO - Started process (PID=27339) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:42:40,852] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 19:42:40,852] {logging_mixin.py:104} INFO - [2021-08-17 19:42:40,852] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:42:41,298] {logging_mixin.py:104} INFO - [2021-08-17 19:42:41,297] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 19:42:41,300] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:42:41,310] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.463 seconds
[2021-08-17 19:43:12,162] {scheduler_job.py:182} INFO - Started process (PID=27407) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:43:12,162] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 19:43:12,163] {logging_mixin.py:104} INFO - [2021-08-17 19:43:12,163] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:43:12,598] {logging_mixin.py:104} INFO - [2021-08-17 19:43:12,596] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 19:43:12,600] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:43:12,611] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.452 seconds
[2021-08-17 19:43:43,396] {scheduler_job.py:182} INFO - Started process (PID=27472) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:43:43,397] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 19:43:43,398] {logging_mixin.py:104} INFO - [2021-08-17 19:43:43,398] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:43:43,829] {logging_mixin.py:104} INFO - [2021-08-17 19:43:43,827] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 19:43:43,832] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:43:43,844] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.449 seconds
[2021-08-17 19:44:14,653] {scheduler_job.py:182} INFO - Started process (PID=27539) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:44:14,654] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 19:44:14,661] {logging_mixin.py:104} INFO - [2021-08-17 19:44:14,661] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:44:15,110] {logging_mixin.py:104} INFO - [2021-08-17 19:44:15,109] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 19:44:15,114] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:44:15,127] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.477 seconds
[2021-08-17 19:44:45,204] {scheduler_job.py:182} INFO - Started process (PID=27609) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:44:45,205] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 19:44:45,206] {logging_mixin.py:104} INFO - [2021-08-17 19:44:45,206] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:44:45,662] {logging_mixin.py:104} INFO - [2021-08-17 19:44:45,660] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 19:44:45,664] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:44:45,674] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.472 seconds
[2021-08-17 19:45:16,666] {scheduler_job.py:182} INFO - Started process (PID=27676) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:45:16,667] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 19:45:16,668] {logging_mixin.py:104} INFO - [2021-08-17 19:45:16,668] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:45:17,142] {logging_mixin.py:104} INFO - [2021-08-17 19:45:17,140] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 19:45:17,145] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:45:17,157] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.492 seconds
[2021-08-17 19:45:47,958] {scheduler_job.py:182} INFO - Started process (PID=27749) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:45:47,959] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 19:45:47,960] {logging_mixin.py:104} INFO - [2021-08-17 19:45:47,960] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:45:48,402] {logging_mixin.py:104} INFO - [2021-08-17 19:45:48,400] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 19:45:48,405] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:45:48,416] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.460 seconds
[2021-08-17 19:46:19,207] {scheduler_job.py:182} INFO - Started process (PID=27813) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:46:19,208] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 19:46:19,209] {logging_mixin.py:104} INFO - [2021-08-17 19:46:19,209] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:46:19,638] {logging_mixin.py:104} INFO - [2021-08-17 19:46:19,636] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 19:46:19,640] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:46:19,651] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.446 seconds
[2021-08-17 19:46:50,374] {scheduler_job.py:182} INFO - Started process (PID=27867) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:46:50,376] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 19:46:50,376] {logging_mixin.py:104} INFO - [2021-08-17 19:46:50,376] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:46:50,800] {logging_mixin.py:104} INFO - [2021-08-17 19:46:50,798] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 19:46:50,803] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:46:50,813] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.441 seconds
[2021-08-17 19:47:21,609] {scheduler_job.py:182} INFO - Started process (PID=27932) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:47:21,610] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 19:47:21,611] {logging_mixin.py:104} INFO - [2021-08-17 19:47:21,611] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:47:22,036] {logging_mixin.py:104} INFO - [2021-08-17 19:47:22,034] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 19:47:22,038] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:47:22,049] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.442 seconds
[2021-08-17 19:47:52,715] {scheduler_job.py:182} INFO - Started process (PID=27997) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:47:52,715] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 19:47:52,716] {logging_mixin.py:104} INFO - [2021-08-17 19:47:52,716] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:47:53,151] {logging_mixin.py:104} INFO - [2021-08-17 19:47:53,149] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 19:47:53,153] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:47:53,164] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.451 seconds
[2021-08-17 19:48:23,192] {scheduler_job.py:182} INFO - Started process (PID=28063) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:48:23,193] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 19:48:23,194] {logging_mixin.py:104} INFO - [2021-08-17 19:48:23,194] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:48:23,632] {logging_mixin.py:104} INFO - [2021-08-17 19:48:23,631] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 19:48:23,634] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:48:23,645] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.455 seconds
[2021-08-17 19:48:53,695] {scheduler_job.py:182} INFO - Started process (PID=28126) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:48:53,696] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 19:48:53,697] {logging_mixin.py:104} INFO - [2021-08-17 19:48:53,697] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:48:54,131] {logging_mixin.py:104} INFO - [2021-08-17 19:48:54,129] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 19:48:54,133] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:48:54,144] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.450 seconds
[2021-08-17 19:49:24,364] {scheduler_job.py:182} INFO - Started process (PID=28189) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:49:24,365] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 19:49:24,366] {logging_mixin.py:104} INFO - [2021-08-17 19:49:24,366] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:49:25,081] {logging_mixin.py:104} INFO - [2021-08-17 19:49:25,079] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 19:49:25,083] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:49:25,102] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.739 seconds
[2021-08-17 19:49:55,595] {scheduler_job.py:182} INFO - Started process (PID=28252) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:49:55,596] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 19:49:55,597] {logging_mixin.py:104} INFO - [2021-08-17 19:49:55,597] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:49:56,015] {logging_mixin.py:104} INFO - [2021-08-17 19:49:56,013] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 19:49:56,017] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:49:56,029] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.435 seconds
[2021-08-17 19:50:26,089] {scheduler_job.py:182} INFO - Started process (PID=28315) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:50:26,090] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 19:50:26,091] {logging_mixin.py:104} INFO - [2021-08-17 19:50:26,091] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:50:26,530] {logging_mixin.py:104} INFO - [2021-08-17 19:50:26,529] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 19:50:26,533] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:50:26,544] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.457 seconds
[2021-08-17 19:50:56,725] {scheduler_job.py:182} INFO - Started process (PID=28378) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:50:56,726] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 19:50:56,727] {logging_mixin.py:104} INFO - [2021-08-17 19:50:56,727] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:50:57,154] {logging_mixin.py:104} INFO - [2021-08-17 19:50:57,152] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 19:50:57,156] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:50:57,167] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.444 seconds
[2021-08-17 19:51:27,857] {scheduler_job.py:182} INFO - Started process (PID=28446) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:51:27,859] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 19:51:27,860] {logging_mixin.py:104} INFO - [2021-08-17 19:51:27,860] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:51:28,302] {logging_mixin.py:104} INFO - [2021-08-17 19:51:28,300] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 19:51:28,304] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:51:28,315] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.460 seconds
[2021-08-17 19:51:59,121] {scheduler_job.py:182} INFO - Started process (PID=28511) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:51:59,122] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 19:51:59,123] {logging_mixin.py:104} INFO - [2021-08-17 19:51:59,123] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:51:59,572] {logging_mixin.py:104} INFO - [2021-08-17 19:51:59,570] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 19:51:59,574] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:51:59,592] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.473 seconds
[2021-08-17 19:52:30,425] {scheduler_job.py:182} INFO - Started process (PID=28575) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:52:30,426] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 19:52:30,427] {logging_mixin.py:104} INFO - [2021-08-17 19:52:30,427] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:52:30,926] {logging_mixin.py:104} INFO - [2021-08-17 19:52:30,924] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 19:52:30,928] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:52:30,945] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.522 seconds
[2021-08-17 19:53:01,690] {scheduler_job.py:182} INFO - Started process (PID=28638) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:53:01,691] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 19:53:01,692] {logging_mixin.py:104} INFO - [2021-08-17 19:53:01,692] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:53:02,159] {logging_mixin.py:104} INFO - [2021-08-17 19:53:02,158] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 19:53:02,163] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:53:02,174] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.486 seconds
[2021-08-17 19:53:32,226] {scheduler_job.py:182} INFO - Started process (PID=28703) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:53:32,227] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 19:53:32,227] {logging_mixin.py:104} INFO - [2021-08-17 19:53:32,227] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:53:32,660] {logging_mixin.py:104} INFO - [2021-08-17 19:53:32,658] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 19:53:32,662] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:53:32,675] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.451 seconds
[2021-08-17 19:54:03,591] {scheduler_job.py:182} INFO - Started process (PID=28768) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:54:03,592] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 19:54:03,593] {logging_mixin.py:104} INFO - [2021-08-17 19:54:03,593] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:54:04,043] {logging_mixin.py:104} INFO - [2021-08-17 19:54:04,042] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 19:54:04,046] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:54:04,060] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.471 seconds
[2021-08-17 19:54:34,924] {scheduler_job.py:182} INFO - Started process (PID=28831) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:54:34,924] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 19:54:34,925] {logging_mixin.py:104} INFO - [2021-08-17 19:54:34,925] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:54:35,378] {logging_mixin.py:104} INFO - [2021-08-17 19:54:35,377] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 19:54:35,382] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:54:35,393] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.471 seconds
[2021-08-17 19:55:06,063] {scheduler_job.py:182} INFO - Started process (PID=28892) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:55:06,064] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 19:55:06,065] {logging_mixin.py:104} INFO - [2021-08-17 19:55:06,064] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:55:06,588] {logging_mixin.py:104} INFO - [2021-08-17 19:55:06,586] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 19:55:06,590] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:55:06,601] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.541 seconds
[2021-08-17 19:55:37,516] {scheduler_job.py:182} INFO - Started process (PID=28950) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:55:37,517] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 19:55:37,518] {logging_mixin.py:104} INFO - [2021-08-17 19:55:37,518] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:55:37,967] {logging_mixin.py:104} INFO - [2021-08-17 19:55:37,965] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 19:55:37,969] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:55:37,980] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.466 seconds
[2021-08-17 19:56:08,947] {scheduler_job.py:182} INFO - Started process (PID=29019) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:56:08,947] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 19:56:08,948] {logging_mixin.py:104} INFO - [2021-08-17 19:56:08,948] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:56:09,372] {logging_mixin.py:104} INFO - [2021-08-17 19:56:09,371] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 19:56:09,375] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:56:09,388] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.443 seconds
[2021-08-17 19:56:40,256] {scheduler_job.py:182} INFO - Started process (PID=29085) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:56:40,257] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 19:56:40,258] {logging_mixin.py:104} INFO - [2021-08-17 19:56:40,258] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:56:40,704] {logging_mixin.py:104} INFO - [2021-08-17 19:56:40,702] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 19:56:40,706] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:56:40,719] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.464 seconds
[2021-08-17 19:57:11,685] {scheduler_job.py:182} INFO - Started process (PID=29150) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:57:11,686] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 19:57:11,687] {logging_mixin.py:104} INFO - [2021-08-17 19:57:11,686] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:57:12,147] {logging_mixin.py:104} INFO - [2021-08-17 19:57:12,145] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 19:57:12,151] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:57:12,162] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.478 seconds
[2021-08-17 19:57:43,179] {scheduler_job.py:182} INFO - Started process (PID=29214) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:57:43,180] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 19:57:43,181] {logging_mixin.py:104} INFO - [2021-08-17 19:57:43,181] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:57:43,656] {logging_mixin.py:104} INFO - [2021-08-17 19:57:43,654] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 19:57:43,659] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:57:43,670] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.492 seconds
[2021-08-17 19:58:13,747] {scheduler_job.py:182} INFO - Started process (PID=29278) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:58:13,748] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 19:58:13,749] {logging_mixin.py:104} INFO - [2021-08-17 19:58:13,749] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:58:14,178] {logging_mixin.py:104} INFO - [2021-08-17 19:58:14,177] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 19:58:14,181] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:58:14,198] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.453 seconds
[2021-08-17 19:58:44,992] {scheduler_job.py:182} INFO - Started process (PID=29341) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:58:44,993] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 19:58:44,993] {logging_mixin.py:104} INFO - [2021-08-17 19:58:44,993] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:58:45,423] {logging_mixin.py:104} INFO - [2021-08-17 19:58:45,421] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 19:58:45,425] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:58:45,444] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.454 seconds
[2021-08-17 19:59:16,284] {scheduler_job.py:182} INFO - Started process (PID=29408) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:59:16,285] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 19:59:16,285] {logging_mixin.py:104} INFO - [2021-08-17 19:59:16,285] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:59:16,736] {logging_mixin.py:104} INFO - [2021-08-17 19:59:16,734] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 19:59:16,739] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:59:16,750] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.468 seconds
[2021-08-17 19:59:47,652] {scheduler_job.py:182} INFO - Started process (PID=29470) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:59:47,653] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 19:59:47,653] {logging_mixin.py:104} INFO - [2021-08-17 19:59:47,653] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:59:48,104] {logging_mixin.py:104} INFO - [2021-08-17 19:59:48,103] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 19:59:48,107] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 19:59:48,125] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.475 seconds
[2021-08-17 20:00:18,992] {scheduler_job.py:182} INFO - Started process (PID=29534) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:00:18,993] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 20:00:18,994] {logging_mixin.py:104} INFO - [2021-08-17 20:00:18,993] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:00:19,436] {logging_mixin.py:104} INFO - [2021-08-17 20:00:19,435] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 20:00:19,439] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:00:19,450] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.459 seconds
[2021-08-17 20:00:50,526] {scheduler_job.py:182} INFO - Started process (PID=29599) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:00:50,540] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 20:00:50,541] {logging_mixin.py:104} INFO - [2021-08-17 20:00:50,541] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:00:51,205] {logging_mixin.py:104} INFO - [2021-08-17 20:00:51,203] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 20:00:51,208] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:00:51,218] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.695 seconds
[2021-08-17 20:01:22,229] {scheduler_job.py:182} INFO - Started process (PID=29664) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:01:22,231] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 20:01:22,232] {logging_mixin.py:104} INFO - [2021-08-17 20:01:22,231] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:01:22,787] {logging_mixin.py:104} INFO - [2021-08-17 20:01:22,785] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 20:01:22,790] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:01:22,800] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.576 seconds
[2021-08-17 20:01:53,650] {scheduler_job.py:182} INFO - Started process (PID=29728) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:01:53,652] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 20:01:53,654] {logging_mixin.py:104} INFO - [2021-08-17 20:01:53,654] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:01:54,201] {logging_mixin.py:104} INFO - [2021-08-17 20:01:54,200] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 20:01:54,204] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:01:54,214] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.569 seconds
[2021-08-17 20:02:25,166] {scheduler_job.py:182} INFO - Started process (PID=29795) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:02:25,168] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 20:02:25,170] {logging_mixin.py:104} INFO - [2021-08-17 20:02:25,169] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:02:25,692] {logging_mixin.py:104} INFO - [2021-08-17 20:02:25,690] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 20:02:25,694] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:02:25,705] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.544 seconds
[2021-08-17 20:02:56,640] {scheduler_job.py:182} INFO - Started process (PID=29863) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:02:56,641] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 20:02:56,642] {logging_mixin.py:104} INFO - [2021-08-17 20:02:56,642] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:02:57,106] {logging_mixin.py:104} INFO - [2021-08-17 20:02:57,105] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 20:02:57,108] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:02:57,120] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.482 seconds
[2021-08-17 20:03:28,253] {scheduler_job.py:182} INFO - Started process (PID=29936) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:03:28,254] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 20:03:28,255] {logging_mixin.py:104} INFO - [2021-08-17 20:03:28,255] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:03:28,865] {logging_mixin.py:104} INFO - [2021-08-17 20:03:28,863] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 20:03:28,867] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:03:28,878] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.627 seconds
[2021-08-17 20:03:58,980] {scheduler_job.py:182} INFO - Started process (PID=30007) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:03:58,981] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 20:03:58,982] {logging_mixin.py:104} INFO - [2021-08-17 20:03:58,982] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:03:59,479] {logging_mixin.py:104} INFO - [2021-08-17 20:03:59,478] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 20:03:59,482] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:03:59,492] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.514 seconds
[2021-08-17 20:04:30,371] {scheduler_job.py:182} INFO - Started process (PID=30075) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:04:30,371] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 20:04:30,375] {logging_mixin.py:104} INFO - [2021-08-17 20:04:30,375] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:04:30,847] {logging_mixin.py:104} INFO - [2021-08-17 20:04:30,846] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 20:04:30,850] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:04:30,860] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.491 seconds
[2021-08-17 20:05:01,881] {scheduler_job.py:182} INFO - Started process (PID=30147) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:05:01,882] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 20:05:01,883] {logging_mixin.py:104} INFO - [2021-08-17 20:05:01,883] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:05:02,478] {logging_mixin.py:104} INFO - [2021-08-17 20:05:02,477] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 20:05:02,481] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:05:02,491] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.611 seconds
[2021-08-17 20:05:33,155] {scheduler_job.py:182} INFO - Started process (PID=30214) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:05:33,156] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 20:05:33,157] {logging_mixin.py:104} INFO - [2021-08-17 20:05:33,157] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:05:34,128] {logging_mixin.py:104} INFO - [2021-08-17 20:05:34,127] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 20:05:34,131] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:05:34,144] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.990 seconds
[2021-08-17 20:06:04,585] {scheduler_job.py:182} INFO - Started process (PID=30276) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:06:04,586] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 20:06:04,586] {logging_mixin.py:104} INFO - [2021-08-17 20:06:04,586] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:06:05,027] {logging_mixin.py:104} INFO - [2021-08-17 20:06:05,025] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 20:06:05,029] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:06:05,040] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.457 seconds
[2021-08-17 20:06:35,073] {scheduler_job.py:182} INFO - Started process (PID=30346) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:06:35,074] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 20:06:35,075] {logging_mixin.py:104} INFO - [2021-08-17 20:06:35,075] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:06:35,530] {logging_mixin.py:104} INFO - [2021-08-17 20:06:35,529] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 20:06:35,533] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:06:35,544] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.473 seconds
[2021-08-17 20:07:06,358] {scheduler_job.py:182} INFO - Started process (PID=30411) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:07:06,359] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 20:07:06,360] {logging_mixin.py:104} INFO - [2021-08-17 20:07:06,360] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:07:06,804] {logging_mixin.py:104} INFO - [2021-08-17 20:07:06,803] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 20:07:06,807] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:07:06,817] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.461 seconds
[2021-08-17 20:07:37,718] {scheduler_job.py:182} INFO - Started process (PID=30477) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:07:37,719] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 20:07:37,719] {logging_mixin.py:104} INFO - [2021-08-17 20:07:37,719] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:07:38,159] {logging_mixin.py:104} INFO - [2021-08-17 20:07:38,157] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 20:07:38,162] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:07:38,172] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.456 seconds
[2021-08-17 20:08:09,061] {scheduler_job.py:182} INFO - Started process (PID=30543) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:08:09,062] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 20:08:09,063] {logging_mixin.py:104} INFO - [2021-08-17 20:08:09,062] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:08:09,508] {logging_mixin.py:104} INFO - [2021-08-17 20:08:09,506] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 20:08:09,511] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:08:09,527] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.468 seconds
[2021-08-17 20:08:40,283] {scheduler_job.py:182} INFO - Started process (PID=30607) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:08:40,284] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 20:08:40,285] {logging_mixin.py:104} INFO - [2021-08-17 20:08:40,285] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:08:40,731] {logging_mixin.py:104} INFO - [2021-08-17 20:08:40,729] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 20:08:40,733] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:08:40,744] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.463 seconds
[2021-08-17 20:09:11,616] {scheduler_job.py:182} INFO - Started process (PID=30669) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:09:11,617] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 20:09:11,618] {logging_mixin.py:104} INFO - [2021-08-17 20:09:11,617] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:09:12,039] {logging_mixin.py:104} INFO - [2021-08-17 20:09:12,038] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 20:09:12,042] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:09:12,060] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.446 seconds
[2021-08-17 20:09:42,995] {scheduler_job.py:182} INFO - Started process (PID=30735) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:09:42,996] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 20:09:42,996] {logging_mixin.py:104} INFO - [2021-08-17 20:09:42,996] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:09:43,428] {logging_mixin.py:104} INFO - [2021-08-17 20:09:43,427] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 20:09:43,431] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:09:43,442] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.449 seconds
[2021-08-17 20:10:14,296] {scheduler_job.py:182} INFO - Started process (PID=30800) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:10:14,297] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 20:10:14,298] {logging_mixin.py:104} INFO - [2021-08-17 20:10:14,298] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:10:14,726] {logging_mixin.py:104} INFO - [2021-08-17 20:10:14,725] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 20:10:14,729] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:10:14,739] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.445 seconds
[2021-08-17 20:10:44,950] {scheduler_job.py:182} INFO - Started process (PID=30868) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:10:44,951] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 20:10:44,951] {logging_mixin.py:104} INFO - [2021-08-17 20:10:44,951] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:10:45,396] {logging_mixin.py:104} INFO - [2021-08-17 20:10:45,394] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 20:10:45,398] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:10:45,409] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.461 seconds
[2021-08-17 20:11:15,546] {scheduler_job.py:182} INFO - Started process (PID=30920) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:11:15,546] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 20:11:15,547] {logging_mixin.py:104} INFO - [2021-08-17 20:11:15,547] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:11:16,000] {logging_mixin.py:104} INFO - [2021-08-17 20:11:15,998] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 20:11:16,003] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:11:16,014] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.470 seconds
[2021-08-17 20:11:46,094] {scheduler_job.py:182} INFO - Started process (PID=30985) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:11:46,095] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 20:11:46,096] {logging_mixin.py:104} INFO - [2021-08-17 20:11:46,096] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:11:46,539] {logging_mixin.py:104} INFO - [2021-08-17 20:11:46,537] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 20:11:46,541] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:11:46,554] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.462 seconds
[2021-08-17 20:12:16,783] {scheduler_job.py:182} INFO - Started process (PID=31050) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:12:16,784] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 20:12:16,785] {logging_mixin.py:104} INFO - [2021-08-17 20:12:16,785] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:12:17,217] {logging_mixin.py:104} INFO - [2021-08-17 20:12:17,215] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 20:12:17,220] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:12:17,230] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.449 seconds
[2021-08-17 20:12:47,539] {scheduler_job.py:182} INFO - Started process (PID=31118) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:12:47,540] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 20:12:47,541] {logging_mixin.py:104} INFO - [2021-08-17 20:12:47,541] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:12:47,989] {logging_mixin.py:104} INFO - [2021-08-17 20:12:47,987] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 20:12:47,991] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:12:48,002] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.465 seconds
[2021-08-17 20:13:18,065] {scheduler_job.py:182} INFO - Started process (PID=31184) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:13:18,066] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 20:13:18,066] {logging_mixin.py:104} INFO - [2021-08-17 20:13:18,066] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:13:18,514] {logging_mixin.py:104} INFO - [2021-08-17 20:13:18,512] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 20:13:18,516] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:13:18,528] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.465 seconds
[2021-08-17 20:13:48,614] {scheduler_job.py:182} INFO - Started process (PID=31249) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:13:48,616] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 20:13:48,619] {logging_mixin.py:104} INFO - [2021-08-17 20:13:48,618] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:13:49,106] {logging_mixin.py:104} INFO - [2021-08-17 20:13:49,104] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 20:13:49,109] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:13:49,120] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.508 seconds
[2021-08-17 20:14:19,836] {scheduler_job.py:182} INFO - Started process (PID=31313) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:14:19,837] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 20:14:19,838] {logging_mixin.py:104} INFO - [2021-08-17 20:14:19,838] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:14:20,308] {logging_mixin.py:104} INFO - [2021-08-17 20:14:20,306] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 20:14:20,310] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:14:20,329] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.494 seconds
[2021-08-17 20:14:50,388] {scheduler_job.py:182} INFO - Started process (PID=31379) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:14:50,389] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 20:14:50,390] {logging_mixin.py:104} INFO - [2021-08-17 20:14:50,390] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:14:50,824] {logging_mixin.py:104} INFO - [2021-08-17 20:14:50,822] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 20:14:50,826] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:14:50,845] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.458 seconds
[2021-08-17 20:15:20,879] {scheduler_job.py:182} INFO - Started process (PID=31443) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:15:20,880] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 20:15:20,881] {logging_mixin.py:104} INFO - [2021-08-17 20:15:20,881] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:15:21,347] {logging_mixin.py:104} INFO - [2021-08-17 20:15:21,345] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 20:15:21,350] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:15:21,361] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.483 seconds
[2021-08-17 20:15:52,305] {scheduler_job.py:182} INFO - Started process (PID=31509) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:15:52,306] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 20:15:52,307] {logging_mixin.py:104} INFO - [2021-08-17 20:15:52,307] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:15:52,750] {logging_mixin.py:104} INFO - [2021-08-17 20:15:52,749] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 20:15:52,752] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:15:52,763] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.460 seconds
[2021-08-17 20:16:23,728] {scheduler_job.py:182} INFO - Started process (PID=31575) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:16:23,729] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 20:16:23,730] {logging_mixin.py:104} INFO - [2021-08-17 20:16:23,730] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:16:24,209] {logging_mixin.py:104} INFO - [2021-08-17 20:16:24,208] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 20:16:24,212] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:16:24,223] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.497 seconds
[2021-08-17 20:16:55,053] {scheduler_job.py:182} INFO - Started process (PID=31638) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:16:55,054] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 20:16:55,055] {logging_mixin.py:104} INFO - [2021-08-17 20:16:55,055] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:16:55,515] {logging_mixin.py:104} INFO - [2021-08-17 20:16:55,514] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 20:16:55,518] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:16:55,530] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.478 seconds
[2021-08-17 20:17:26,413] {scheduler_job.py:182} INFO - Started process (PID=31706) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:17:26,414] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 20:17:26,414] {logging_mixin.py:104} INFO - [2021-08-17 20:17:26,414] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:17:26,847] {logging_mixin.py:104} INFO - [2021-08-17 20:17:26,845] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 20:17:26,849] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:17:26,859] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.449 seconds
[2021-08-17 20:17:57,842] {scheduler_job.py:182} INFO - Started process (PID=31769) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:17:57,843] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 20:17:57,844] {logging_mixin.py:104} INFO - [2021-08-17 20:17:57,844] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:17:58,291] {logging_mixin.py:104} INFO - [2021-08-17 20:17:58,290] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 20:17:58,294] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:17:58,305] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.464 seconds
[2021-08-17 20:18:29,215] {scheduler_job.py:182} INFO - Started process (PID=31836) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:18:29,215] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 20:18:29,216] {logging_mixin.py:104} INFO - [2021-08-17 20:18:29,216] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:18:29,704] {logging_mixin.py:104} INFO - [2021-08-17 20:18:29,703] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 20:18:29,707] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:18:29,719] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.506 seconds
[2021-08-17 20:18:59,951] {scheduler_job.py:182} INFO - Started process (PID=31902) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:18:59,952] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 20:18:59,953] {logging_mixin.py:104} INFO - [2021-08-17 20:18:59,953] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:19:00,433] {logging_mixin.py:104} INFO - [2021-08-17 20:19:00,431] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 20:19:00,435] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:19:00,446] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.498 seconds
[2021-08-17 20:19:31,318] {scheduler_job.py:182} INFO - Started process (PID=31955) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:19:31,319] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 20:19:31,320] {logging_mixin.py:104} INFO - [2021-08-17 20:19:31,319] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:19:31,820] {logging_mixin.py:104} INFO - [2021-08-17 20:19:31,818] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 20:19:31,823] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:19:31,833] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.516 seconds
[2021-08-17 20:20:02,759] {scheduler_job.py:182} INFO - Started process (PID=32016) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:20:02,760] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 20:20:02,761] {logging_mixin.py:104} INFO - [2021-08-17 20:20:02,761] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:20:03,223] {logging_mixin.py:104} INFO - [2021-08-17 20:20:03,221] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 20:20:03,225] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:20:03,237] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.479 seconds
[2021-08-17 20:20:34,212] {scheduler_job.py:182} INFO - Started process (PID=32079) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:20:34,213] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 20:20:34,214] {logging_mixin.py:104} INFO - [2021-08-17 20:20:34,214] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:20:34,635] {logging_mixin.py:104} INFO - [2021-08-17 20:20:34,633] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 20:20:34,637] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:20:34,649] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.438 seconds
[2021-08-17 20:21:05,521] {scheduler_job.py:182} INFO - Started process (PID=32144) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:21:05,522] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 20:21:05,522] {logging_mixin.py:104} INFO - [2021-08-17 20:21:05,522] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:21:05,994] {logging_mixin.py:104} INFO - [2021-08-17 20:21:05,992] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 20:21:05,996] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:21:06,007] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.488 seconds
[2021-08-17 20:21:36,992] {scheduler_job.py:182} INFO - Started process (PID=32208) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:21:36,993] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 20:21:36,994] {logging_mixin.py:104} INFO - [2021-08-17 20:21:36,994] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:21:37,485] {logging_mixin.py:104} INFO - [2021-08-17 20:21:37,484] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 20:21:37,488] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:21:37,500] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.509 seconds
[2021-08-17 20:22:07,601] {scheduler_job.py:182} INFO - Started process (PID=32275) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:22:07,610] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 20:22:07,611] {logging_mixin.py:104} INFO - [2021-08-17 20:22:07,611] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:22:08,062] {logging_mixin.py:104} INFO - [2021-08-17 20:22:08,061] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 20:22:08,065] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:22:08,084] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.485 seconds
[2021-08-17 20:22:39,023] {scheduler_job.py:182} INFO - Started process (PID=32342) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:22:39,031] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 20:22:39,032] {logging_mixin.py:104} INFO - [2021-08-17 20:22:39,031] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:22:39,502] {logging_mixin.py:104} INFO - [2021-08-17 20:22:39,500] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 20:22:39,504] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:22:39,517] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.497 seconds
[2021-08-17 20:23:09,553] {scheduler_job.py:182} INFO - Started process (PID=32408) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:23:09,554] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 20:23:09,555] {logging_mixin.py:104} INFO - [2021-08-17 20:23:09,555] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:23:09,993] {logging_mixin.py:104} INFO - [2021-08-17 20:23:09,991] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 20:23:09,996] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:23:10,007] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.455 seconds
[2021-08-17 20:23:40,911] {scheduler_job.py:182} INFO - Started process (PID=32471) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:23:40,913] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 20:23:40,913] {logging_mixin.py:104} INFO - [2021-08-17 20:23:40,913] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:23:41,355] {logging_mixin.py:104} INFO - [2021-08-17 20:23:41,353] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 20:23:41,357] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:23:41,368] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.459 seconds
[2021-08-17 20:24:12,354] {scheduler_job.py:182} INFO - Started process (PID=32538) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:24:12,355] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 20:24:12,356] {logging_mixin.py:104} INFO - [2021-08-17 20:24:12,355] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:24:12,836] {logging_mixin.py:104} INFO - [2021-08-17 20:24:12,834] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 20:24:12,839] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:24:12,851] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.499 seconds
[2021-08-17 20:24:42,877] {scheduler_job.py:182} INFO - Started process (PID=32604) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:24:42,878] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 20:24:42,879] {logging_mixin.py:104} INFO - [2021-08-17 20:24:42,878] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:24:43,304] {logging_mixin.py:104} INFO - [2021-08-17 20:24:43,302] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 20:24:43,306] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:24:43,324] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.449 seconds
[2021-08-17 20:25:14,114] {scheduler_job.py:182} INFO - Started process (PID=32667) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:25:14,115] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 20:25:14,116] {logging_mixin.py:104} INFO - [2021-08-17 20:25:14,116] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:25:14,663] {logging_mixin.py:104} INFO - [2021-08-17 20:25:14,661] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 20:25:14,665] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:25:14,683] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.571 seconds
[2021-08-17 20:25:45,381] {scheduler_job.py:182} INFO - Started process (PID=32736) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:25:45,382] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 20:25:45,383] {logging_mixin.py:104} INFO - [2021-08-17 20:25:45,383] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:25:45,824] {logging_mixin.py:104} INFO - [2021-08-17 20:25:45,823] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 20:25:45,827] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:25:45,846] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.466 seconds
[2021-08-17 20:26:16,585] {scheduler_job.py:182} INFO - Started process (PID=32801) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:26:16,586] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 20:26:16,587] {logging_mixin.py:104} INFO - [2021-08-17 20:26:16,587] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:26:17,100] {logging_mixin.py:104} INFO - [2021-08-17 20:26:17,099] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 20:26:17,103] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:26:17,121] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.538 seconds
[2021-08-17 20:26:47,371] {scheduler_job.py:182} INFO - Started process (PID=32873) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:26:47,373] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 20:26:47,374] {logging_mixin.py:104} INFO - [2021-08-17 20:26:47,374] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:26:47,848] {logging_mixin.py:104} INFO - [2021-08-17 20:26:47,847] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 20:26:47,851] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:26:47,864] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.494 seconds
[2021-08-17 20:27:18,770] {scheduler_job.py:182} INFO - Started process (PID=32938) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:27:18,772] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 20:27:18,772] {logging_mixin.py:104} INFO - [2021-08-17 20:27:18,772] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:27:19,388] {logging_mixin.py:104} INFO - [2021-08-17 20:27:19,387] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 20:27:19,390] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:27:19,402] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.637 seconds
[2021-08-17 20:27:50,381] {scheduler_job.py:182} INFO - Started process (PID=33009) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:27:50,389] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 20:27:50,390] {logging_mixin.py:104} INFO - [2021-08-17 20:27:50,390] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:27:50,859] {logging_mixin.py:104} INFO - [2021-08-17 20:27:50,857] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 20:27:50,861] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:27:50,871] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.492 seconds
[2021-08-17 20:28:21,523] {scheduler_job.py:182} INFO - Started process (PID=33077) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:28:21,526] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 20:28:21,527] {logging_mixin.py:104} INFO - [2021-08-17 20:28:21,526] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:28:21,992] {logging_mixin.py:104} INFO - [2021-08-17 20:28:21,990] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 20:28:21,995] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:28:22,006] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.485 seconds
[2021-08-17 20:28:52,689] {scheduler_job.py:182} INFO - Started process (PID=33147) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:28:52,691] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 20:28:52,692] {logging_mixin.py:104} INFO - [2021-08-17 20:28:52,692] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:28:53,175] {logging_mixin.py:104} INFO - [2021-08-17 20:28:53,173] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 20:28:53,177] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:28:53,188] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.503 seconds
[2021-08-17 20:29:23,980] {scheduler_job.py:182} INFO - Started process (PID=33212) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:29:23,981] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 20:29:23,982] {logging_mixin.py:104} INFO - [2021-08-17 20:29:23,982] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:29:24,425] {logging_mixin.py:104} INFO - [2021-08-17 20:29:24,423] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 20:29:24,427] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:29:24,440] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.462 seconds
[2021-08-17 20:29:55,086] {scheduler_job.py:182} INFO - Started process (PID=33275) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:29:55,087] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 20:29:55,088] {logging_mixin.py:104} INFO - [2021-08-17 20:29:55,088] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:29:55,584] {logging_mixin.py:104} INFO - [2021-08-17 20:29:55,583] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 20:29:55,587] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:29:55,599] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.515 seconds
[2021-08-17 20:30:26,281] {scheduler_job.py:182} INFO - Started process (PID=33339) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:30:26,282] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 20:30:26,282] {logging_mixin.py:104} INFO - [2021-08-17 20:30:26,282] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:30:26,722] {logging_mixin.py:104} INFO - [2021-08-17 20:30:26,721] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 20:30:26,725] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:30:26,743] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.464 seconds
[2021-08-17 20:30:57,444] {scheduler_job.py:182} INFO - Started process (PID=33402) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:30:57,445] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 20:30:57,445] {logging_mixin.py:104} INFO - [2021-08-17 20:30:57,445] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:30:57,911] {logging_mixin.py:104} INFO - [2021-08-17 20:30:57,910] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 20:30:57,913] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:30:57,931] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.490 seconds
[2021-08-17 20:31:28,881] {scheduler_job.py:182} INFO - Started process (PID=33466) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:31:28,882] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 20:31:28,883] {logging_mixin.py:104} INFO - [2021-08-17 20:31:28,883] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:31:29,329] {logging_mixin.py:104} INFO - [2021-08-17 20:31:29,328] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 20:31:29,333] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:31:29,351] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.472 seconds
[2021-08-17 20:31:59,474] {scheduler_job.py:182} INFO - Started process (PID=33527) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:31:59,476] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 20:31:59,477] {logging_mixin.py:104} INFO - [2021-08-17 20:31:59,477] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:31:59,915] {logging_mixin.py:104} INFO - [2021-08-17 20:31:59,914] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 20:31:59,918] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:31:59,930] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.458 seconds
[2021-08-17 20:32:30,169] {scheduler_job.py:182} INFO - Started process (PID=33582) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:32:30,170] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 20:32:30,170] {logging_mixin.py:104} INFO - [2021-08-17 20:32:30,170] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:32:30,601] {logging_mixin.py:104} INFO - [2021-08-17 20:32:30,600] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 20:32:30,604] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:32:30,616] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.449 seconds
[2021-08-17 20:33:01,367] {scheduler_job.py:182} INFO - Started process (PID=33646) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:33:01,368] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 20:33:01,369] {logging_mixin.py:104} INFO - [2021-08-17 20:33:01,369] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:33:01,788] {logging_mixin.py:104} INFO - [2021-08-17 20:33:01,787] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 20:33:01,791] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:33:01,803] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.438 seconds
[2021-08-17 20:33:32,535] {scheduler_job.py:182} INFO - Started process (PID=33709) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:33:32,536] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 20:33:32,537] {logging_mixin.py:104} INFO - [2021-08-17 20:33:32,537] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:33:32,964] {logging_mixin.py:104} INFO - [2021-08-17 20:33:32,961] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 20:33:32,966] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:33:32,989] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.456 seconds
[2021-08-17 20:34:03,053] {scheduler_job.py:182} INFO - Started process (PID=33774) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:34:03,054] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 20:34:03,055] {logging_mixin.py:104} INFO - [2021-08-17 20:34:03,055] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:34:03,518] {logging_mixin.py:104} INFO - [2021-08-17 20:34:03,516] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 20:34:03,520] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:34:03,531] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.480 seconds
[2021-08-17 20:34:33,749] {scheduler_job.py:182} INFO - Started process (PID=33838) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:34:33,750] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 20:34:33,751] {logging_mixin.py:104} INFO - [2021-08-17 20:34:33,751] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:34:34,207] {logging_mixin.py:104} INFO - [2021-08-17 20:34:34,206] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 20:34:34,210] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:34:34,221] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.474 seconds
[2021-08-17 20:35:04,980] {scheduler_job.py:182} INFO - Started process (PID=33902) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:35:04,981] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 20:35:04,982] {logging_mixin.py:104} INFO - [2021-08-17 20:35:04,982] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:35:05,429] {logging_mixin.py:104} INFO - [2021-08-17 20:35:05,428] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 20:35:05,432] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:35:05,443] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.465 seconds
[2021-08-17 20:35:36,229] {scheduler_job.py:182} INFO - Started process (PID=33970) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:35:36,229] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 20:35:36,230] {logging_mixin.py:104} INFO - [2021-08-17 20:35:36,230] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:35:36,668] {logging_mixin.py:104} INFO - [2021-08-17 20:35:36,667] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 20:35:36,671] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:35:36,689] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.462 seconds
[2021-08-17 20:36:07,343] {scheduler_job.py:182} INFO - Started process (PID=34033) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:36:07,344] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 20:36:07,344] {logging_mixin.py:104} INFO - [2021-08-17 20:36:07,344] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:36:07,784] {logging_mixin.py:104} INFO - [2021-08-17 20:36:07,782] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 20:36:07,787] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:36:07,804] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.463 seconds
[2021-08-17 20:36:37,839] {scheduler_job.py:182} INFO - Started process (PID=34099) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:36:37,841] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 20:36:37,842] {logging_mixin.py:104} INFO - [2021-08-17 20:36:37,842] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:36:38,321] {logging_mixin.py:104} INFO - [2021-08-17 20:36:38,319] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 20:36:38,324] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:36:38,335] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.497 seconds
[2021-08-17 20:37:08,554] {scheduler_job.py:182} INFO - Started process (PID=34163) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:37:08,555] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 20:37:08,556] {logging_mixin.py:104} INFO - [2021-08-17 20:37:08,556] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:37:09,082] {logging_mixin.py:104} INFO - [2021-08-17 20:37:09,081] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 20:37:09,085] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:37:09,097] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.545 seconds
[2021-08-17 20:37:39,704] {scheduler_job.py:182} INFO - Started process (PID=34227) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:37:39,705] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 20:37:39,706] {logging_mixin.py:104} INFO - [2021-08-17 20:37:39,706] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:37:40,662] {logging_mixin.py:104} INFO - [2021-08-17 20:37:40,661] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 20:37:40,665] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:37:40,682] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.980 seconds
[2021-08-17 20:38:10,864] {scheduler_job.py:182} INFO - Started process (PID=34291) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:38:10,865] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 20:38:10,866] {logging_mixin.py:104} INFO - [2021-08-17 20:38:10,866] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:38:11,286] {logging_mixin.py:104} INFO - [2021-08-17 20:38:11,285] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 20:38:11,289] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:38:11,304] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.442 seconds
[2021-08-17 20:38:41,628] {scheduler_job.py:182} INFO - Started process (PID=34356) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:38:41,628] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 20:38:41,629] {logging_mixin.py:104} INFO - [2021-08-17 20:38:41,629] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:38:42,056] {logging_mixin.py:104} INFO - [2021-08-17 20:38:42,054] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 20:38:42,058] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:38:42,070] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.444 seconds
[2021-08-17 20:39:12,702] {scheduler_job.py:182} INFO - Started process (PID=34422) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:39:12,703] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 20:39:12,703] {logging_mixin.py:104} INFO - [2021-08-17 20:39:12,703] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:39:13,127] {logging_mixin.py:104} INFO - [2021-08-17 20:39:13,125] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 20:39:13,129] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:39:13,141] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.441 seconds
[2021-08-17 20:39:43,311] {scheduler_job.py:182} INFO - Started process (PID=34491) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:39:43,312] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 20:39:43,312] {logging_mixin.py:104} INFO - [2021-08-17 20:39:43,312] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:39:43,743] {logging_mixin.py:104} INFO - [2021-08-17 20:39:43,741] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 20:39:43,746] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:39:43,756] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.447 seconds
[2021-08-17 20:40:14,417] {scheduler_job.py:182} INFO - Started process (PID=34554) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:40:14,418] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 20:40:14,419] {logging_mixin.py:104} INFO - [2021-08-17 20:40:14,419] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:40:14,861] {logging_mixin.py:104} INFO - [2021-08-17 20:40:14,860] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 20:40:14,864] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:40:14,875] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.460 seconds
[2021-08-17 20:40:45,099] {scheduler_job.py:182} INFO - Started process (PID=34610) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:40:45,100] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 20:40:45,101] {logging_mixin.py:104} INFO - [2021-08-17 20:40:45,101] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:40:45,533] {logging_mixin.py:104} INFO - [2021-08-17 20:40:45,531] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 20:40:45,535] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:40:45,546] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.449 seconds
[2021-08-17 20:41:15,639] {scheduler_job.py:182} INFO - Started process (PID=34676) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:41:15,640] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 20:41:15,640] {logging_mixin.py:104} INFO - [2021-08-17 20:41:15,640] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:41:16,081] {logging_mixin.py:104} INFO - [2021-08-17 20:41:16,079] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 20:41:16,083] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:41:16,094] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.457 seconds
[2021-08-17 20:41:46,833] {scheduler_job.py:182} INFO - Started process (PID=34741) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:41:46,834] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 20:41:46,835] {logging_mixin.py:104} INFO - [2021-08-17 20:41:46,835] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:41:47,279] {logging_mixin.py:104} INFO - [2021-08-17 20:41:47,278] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 20:41:47,282] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:41:47,292] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.461 seconds
[2021-08-17 20:42:18,079] {scheduler_job.py:182} INFO - Started process (PID=34805) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:42:18,080] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 20:42:18,080] {logging_mixin.py:104} INFO - [2021-08-17 20:42:18,080] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:42:18,517] {logging_mixin.py:104} INFO - [2021-08-17 20:42:18,514] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 20:42:18,520] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:42:18,533] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.457 seconds
[2021-08-17 20:42:49,545] {scheduler_job.py:182} INFO - Started process (PID=34872) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:42:49,546] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 20:42:49,547] {logging_mixin.py:104} INFO - [2021-08-17 20:42:49,547] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:42:50,028] {logging_mixin.py:104} INFO - [2021-08-17 20:42:50,026] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 20:42:50,031] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:42:50,040] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.497 seconds
[2021-08-17 20:43:20,091] {scheduler_job.py:182} INFO - Started process (PID=34939) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:43:20,092] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 20:43:20,092] {logging_mixin.py:104} INFO - [2021-08-17 20:43:20,092] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:43:20,532] {logging_mixin.py:104} INFO - [2021-08-17 20:43:20,530] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 20:43:20,534] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:43:20,544] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.455 seconds
[2021-08-17 20:43:50,572] {scheduler_job.py:182} INFO - Started process (PID=35010) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:43:50,573] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 20:43:50,574] {logging_mixin.py:104} INFO - [2021-08-17 20:43:50,574] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:43:51,015] {logging_mixin.py:104} INFO - [2021-08-17 20:43:51,014] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 20:43:51,018] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:43:51,036] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.465 seconds
[2021-08-17 20:44:21,172] {scheduler_job.py:182} INFO - Started process (PID=35078) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:44:21,173] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 20:44:21,173] {logging_mixin.py:104} INFO - [2021-08-17 20:44:21,173] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:44:21,595] {logging_mixin.py:104} INFO - [2021-08-17 20:44:21,593] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 20:44:21,597] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:44:21,615] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.445 seconds
[2021-08-17 20:44:52,515] {scheduler_job.py:182} INFO - Started process (PID=35142) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:44:52,516] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 20:44:52,517] {logging_mixin.py:104} INFO - [2021-08-17 20:44:52,517] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:44:53,228] {logging_mixin.py:104} INFO - [2021-08-17 20:44:53,227] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 20:44:53,231] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:44:53,242] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.730 seconds
[2021-08-17 20:45:24,181] {scheduler_job.py:182} INFO - Started process (PID=35208) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:45:24,182] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 20:45:24,183] {logging_mixin.py:104} INFO - [2021-08-17 20:45:24,183] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:45:24,625] {logging_mixin.py:104} INFO - [2021-08-17 20:45:24,623] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 20:45:24,627] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:45:24,637] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.458 seconds
[2021-08-17 20:45:55,648] {scheduler_job.py:182} INFO - Started process (PID=35278) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:45:55,649] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 20:45:55,650] {logging_mixin.py:104} INFO - [2021-08-17 20:45:55,650] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:45:56,091] {logging_mixin.py:104} INFO - [2021-08-17 20:45:56,089] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 20:45:56,094] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:45:56,105] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.458 seconds
[2021-08-17 20:46:26,361] {scheduler_job.py:182} INFO - Started process (PID=35347) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:46:26,362] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 20:46:26,363] {logging_mixin.py:104} INFO - [2021-08-17 20:46:26,362] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:46:26,807] {logging_mixin.py:104} INFO - [2021-08-17 20:46:26,806] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 20:46:26,810] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:46:26,825] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.466 seconds
[2021-08-17 20:46:57,399] {scheduler_job.py:182} INFO - Started process (PID=35421) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:46:57,400] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 20:46:57,401] {logging_mixin.py:104} INFO - [2021-08-17 20:46:57,401] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:46:57,856] {logging_mixin.py:104} INFO - [2021-08-17 20:46:57,855] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 20:46:57,859] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:46:57,869] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.473 seconds
[2021-08-17 20:47:28,034] {scheduler_job.py:182} INFO - Started process (PID=35491) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:47:28,035] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 20:47:28,036] {logging_mixin.py:104} INFO - [2021-08-17 20:47:28,036] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:47:28,541] {logging_mixin.py:104} INFO - [2021-08-17 20:47:28,540] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 20:47:28,544] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:47:28,555] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.522 seconds
[2021-08-17 20:47:59,217] {scheduler_job.py:182} INFO - Started process (PID=35556) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:47:59,218] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 20:47:59,218] {logging_mixin.py:104} INFO - [2021-08-17 20:47:59,218] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:47:59,674] {logging_mixin.py:104} INFO - [2021-08-17 20:47:59,673] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 20:47:59,677] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:47:59,687] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.472 seconds
[2021-08-17 20:48:30,501] {scheduler_job.py:182} INFO - Started process (PID=35628) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:48:30,502] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 20:48:30,503] {logging_mixin.py:104} INFO - [2021-08-17 20:48:30,503] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:48:30,945] {logging_mixin.py:104} INFO - [2021-08-17 20:48:30,942] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 20:48:30,948] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:48:30,963] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.464 seconds
[2021-08-17 20:49:01,629] {scheduler_job.py:182} INFO - Started process (PID=35693) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:49:01,630] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 20:49:01,631] {logging_mixin.py:104} INFO - [2021-08-17 20:49:01,631] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:49:02,075] {logging_mixin.py:104} INFO - [2021-08-17 20:49:02,073] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 20:49:02,077] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:49:02,096] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.468 seconds
[2021-08-17 20:49:32,735] {scheduler_job.py:182} INFO - Started process (PID=35760) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:49:32,736] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 20:49:32,736] {logging_mixin.py:104} INFO - [2021-08-17 20:49:32,736] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:49:33,181] {logging_mixin.py:104} INFO - [2021-08-17 20:49:33,180] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 20:49:33,184] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:49:33,195] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.462 seconds
[2021-08-17 20:50:04,094] {scheduler_job.py:182} INFO - Started process (PID=35829) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:50:04,095] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 20:50:04,096] {logging_mixin.py:104} INFO - [2021-08-17 20:50:04,096] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:50:04,556] {logging_mixin.py:104} INFO - [2021-08-17 20:50:04,555] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 20:50:04,559] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:50:04,569] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.478 seconds
[2021-08-17 20:50:34,617] {scheduler_job.py:182} INFO - Started process (PID=35888) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:50:34,618] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 20:50:34,619] {logging_mixin.py:104} INFO - [2021-08-17 20:50:34,619] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:50:35,060] {logging_mixin.py:104} INFO - [2021-08-17 20:50:35,059] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 20:50:35,064] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:50:35,076] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.461 seconds
[2021-08-17 20:51:05,131] {scheduler_job.py:182} INFO - Started process (PID=35955) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:51:05,132] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 20:51:05,133] {logging_mixin.py:104} INFO - [2021-08-17 20:51:05,132] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:51:05,576] {logging_mixin.py:104} INFO - [2021-08-17 20:51:05,574] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 20:51:05,579] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:51:05,591] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.461 seconds
[2021-08-17 20:51:35,757] {scheduler_job.py:182} INFO - Started process (PID=36021) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:51:35,758] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 20:51:35,759] {logging_mixin.py:104} INFO - [2021-08-17 20:51:35,759] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:51:36,206] {logging_mixin.py:104} INFO - [2021-08-17 20:51:36,205] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 20:51:36,209] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:51:36,219] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.468 seconds
[2021-08-17 20:52:06,991] {scheduler_job.py:182} INFO - Started process (PID=36085) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:52:06,991] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 20:52:06,992] {logging_mixin.py:104} INFO - [2021-08-17 20:52:06,992] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:52:07,422] {logging_mixin.py:104} INFO - [2021-08-17 20:52:07,420] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 20:52:07,424] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:52:07,436] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.447 seconds
[2021-08-17 20:52:38,078] {scheduler_job.py:182} INFO - Started process (PID=36149) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:52:38,078] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 20:52:38,079] {logging_mixin.py:104} INFO - [2021-08-17 20:52:38,079] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:52:38,515] {logging_mixin.py:104} INFO - [2021-08-17 20:52:38,513] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 20:52:38,517] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:52:38,528] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.453 seconds
[2021-08-17 20:53:09,310] {scheduler_job.py:182} INFO - Started process (PID=36214) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:53:09,312] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 20:53:09,313] {logging_mixin.py:104} INFO - [2021-08-17 20:53:09,313] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:53:09,757] {logging_mixin.py:104} INFO - [2021-08-17 20:53:09,755] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 20:53:09,760] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:53:09,771] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.463 seconds
[2021-08-17 20:53:40,407] {scheduler_job.py:182} INFO - Started process (PID=36280) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:53:40,408] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 20:53:40,409] {logging_mixin.py:104} INFO - [2021-08-17 20:53:40,409] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:53:40,844] {logging_mixin.py:104} INFO - [2021-08-17 20:53:40,843] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 20:53:40,847] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:53:40,858] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.453 seconds
[2021-08-17 20:54:10,958] {scheduler_job.py:182} INFO - Started process (PID=36343) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:54:10,959] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 20:54:10,960] {logging_mixin.py:104} INFO - [2021-08-17 20:54:10,960] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:54:11,409] {logging_mixin.py:104} INFO - [2021-08-17 20:54:11,408] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 20:54:11,412] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:54:11,430] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.474 seconds
[2021-08-17 20:54:42,085] {scheduler_job.py:182} INFO - Started process (PID=36407) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:54:42,086] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 20:54:42,087] {logging_mixin.py:104} INFO - [2021-08-17 20:54:42,087] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:54:42,499] {logging_mixin.py:104} INFO - [2021-08-17 20:54:42,498] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 20:54:42,502] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:54:42,513] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.430 seconds
[2021-08-17 20:55:13,216] {scheduler_job.py:182} INFO - Started process (PID=36471) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:55:13,217] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 20:55:13,218] {logging_mixin.py:104} INFO - [2021-08-17 20:55:13,217] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:55:13,718] {logging_mixin.py:104} INFO - [2021-08-17 20:55:13,716] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 20:55:13,721] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:55:13,732] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.518 seconds
[2021-08-17 20:55:44,338] {scheduler_job.py:182} INFO - Started process (PID=36540) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:55:44,339] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 20:55:44,340] {logging_mixin.py:104} INFO - [2021-08-17 20:55:44,339] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:55:44,782] {logging_mixin.py:104} INFO - [2021-08-17 20:55:44,781] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 20:55:44,786] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:55:44,798] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.462 seconds
[2021-08-17 20:56:15,593] {scheduler_job.py:182} INFO - Started process (PID=36607) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:56:15,594] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 20:56:15,594] {logging_mixin.py:104} INFO - [2021-08-17 20:56:15,594] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:56:16,069] {logging_mixin.py:104} INFO - [2021-08-17 20:56:16,067] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 20:56:16,071] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:56:16,083] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.492 seconds
[2021-08-17 20:56:46,849] {scheduler_job.py:182} INFO - Started process (PID=36677) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:56:46,850] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-17 20:56:46,851] {logging_mixin.py:104} INFO - [2021-08-17 20:56:46,851] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:56:47,286] {logging_mixin.py:104} INFO - [2021-08-17 20:56:47,285] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-17 20:56:47,289] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-17 20:56:47,299] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.452 seconds
