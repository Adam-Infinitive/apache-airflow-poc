[2021-08-16 00:00:02,522] {scheduler_job.py:181} INFO - Started process (PID=78866) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:00:02,523] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 00:00:02,524] {logging_mixin.py:104} INFO - [2021-08-16 00:00:02,523] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:00:03,054] {logging_mixin.py:104} INFO - [2021-08-16 00:00:03,053] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 00:00:03,058] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:00:03,070] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.550 seconds
[2021-08-16 00:00:33,211] {scheduler_job.py:181} INFO - Started process (PID=78893) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:00:33,212] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 00:00:33,213] {logging_mixin.py:104} INFO - [2021-08-16 00:00:33,213] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:00:33,656] {logging_mixin.py:104} INFO - [2021-08-16 00:00:33,654] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 00:00:33,659] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:00:33,670] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.461 seconds
[2021-08-16 00:01:04,456] {scheduler_job.py:181} INFO - Started process (PID=78930) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:01:04,457] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 00:01:04,458] {logging_mixin.py:104} INFO - [2021-08-16 00:01:04,458] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:01:05,405] {logging_mixin.py:104} INFO - [2021-08-16 00:01:05,403] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 00:01:05,407] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:01:05,418] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.963 seconds
[2021-08-16 00:01:35,669] {scheduler_job.py:181} INFO - Started process (PID=78971) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:01:35,670] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 00:01:35,671] {logging_mixin.py:104} INFO - [2021-08-16 00:01:35,671] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:01:36,146] {logging_mixin.py:104} INFO - [2021-08-16 00:01:36,145] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 00:01:36,149] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:01:36,160] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.493 seconds
[2021-08-16 00:02:06,914] {scheduler_job.py:181} INFO - Started process (PID=79010) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:02:06,915] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 00:02:06,916] {logging_mixin.py:104} INFO - [2021-08-16 00:02:06,916] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:02:07,386] {logging_mixin.py:104} INFO - [2021-08-16 00:02:07,384] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 00:02:07,389] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:02:07,402] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.490 seconds
[2021-08-16 00:02:37,545] {scheduler_job.py:181} INFO - Started process (PID=79047) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:02:37,546] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 00:02:37,547] {logging_mixin.py:104} INFO - [2021-08-16 00:02:37,547] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:02:38,006] {logging_mixin.py:104} INFO - [2021-08-16 00:02:38,004] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 00:02:38,008] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:02:38,019] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.476 seconds
[2021-08-16 00:03:08,171] {scheduler_job.py:181} INFO - Started process (PID=79076) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:03:08,172] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 00:03:08,173] {logging_mixin.py:104} INFO - [2021-08-16 00:03:08,173] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:03:08,625] {logging_mixin.py:104} INFO - [2021-08-16 00:03:08,624] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 00:03:08,628] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:03:08,639] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.470 seconds
[2021-08-16 00:03:38,781] {scheduler_job.py:181} INFO - Started process (PID=79111) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:03:38,781] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 00:03:38,782] {logging_mixin.py:104} INFO - [2021-08-16 00:03:38,782] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:03:39,227] {logging_mixin.py:104} INFO - [2021-08-16 00:03:39,225] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 00:03:39,229] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:03:39,240] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.461 seconds
[2021-08-16 00:04:09,415] {scheduler_job.py:181} INFO - Started process (PID=79149) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:04:09,416] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 00:04:09,417] {logging_mixin.py:104} INFO - [2021-08-16 00:04:09,417] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:04:09,889] {logging_mixin.py:104} INFO - [2021-08-16 00:04:09,887] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 00:04:09,891] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:04:09,903] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.489 seconds
[2021-08-16 00:04:40,052] {scheduler_job.py:181} INFO - Started process (PID=79196) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:04:40,053] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 00:04:40,054] {logging_mixin.py:104} INFO - [2021-08-16 00:04:40,054] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:04:40,495] {logging_mixin.py:104} INFO - [2021-08-16 00:04:40,494] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 00:04:40,498] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:04:40,509] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.459 seconds
[2021-08-16 00:05:10,657] {scheduler_job.py:181} INFO - Started process (PID=79223) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:05:10,658] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 00:05:10,659] {logging_mixin.py:104} INFO - [2021-08-16 00:05:10,659] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:05:11,094] {logging_mixin.py:104} INFO - [2021-08-16 00:05:11,093] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 00:05:11,097] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:05:11,108] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.452 seconds
[2021-08-16 00:05:41,253] {scheduler_job.py:181} INFO - Started process (PID=79261) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:05:41,254] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 00:05:41,255] {logging_mixin.py:104} INFO - [2021-08-16 00:05:41,255] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:05:41,702] {logging_mixin.py:104} INFO - [2021-08-16 00:05:41,700] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 00:05:41,705] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:05:41,715] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.464 seconds
[2021-08-16 00:06:11,862] {scheduler_job.py:181} INFO - Started process (PID=79304) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:06:11,864] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 00:06:11,864] {logging_mixin.py:104} INFO - [2021-08-16 00:06:11,864] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:06:12,297] {logging_mixin.py:104} INFO - [2021-08-16 00:06:12,295] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 00:06:12,299] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:06:12,310] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.450 seconds
[2021-08-16 00:06:42,458] {scheduler_job.py:181} INFO - Started process (PID=79345) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:06:42,459] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 00:06:42,460] {logging_mixin.py:104} INFO - [2021-08-16 00:06:42,460] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:06:42,901] {logging_mixin.py:104} INFO - [2021-08-16 00:06:42,900] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 00:06:42,904] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:06:42,915] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.458 seconds
[2021-08-16 00:07:13,061] {scheduler_job.py:181} INFO - Started process (PID=79371) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:07:13,062] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 00:07:13,063] {logging_mixin.py:104} INFO - [2021-08-16 00:07:13,063] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:07:13,534] {logging_mixin.py:104} INFO - [2021-08-16 00:07:13,533] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 00:07:13,536] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:07:13,547] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.489 seconds
[2021-08-16 00:07:43,697] {scheduler_job.py:181} INFO - Started process (PID=79411) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:07:43,698] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 00:07:43,699] {logging_mixin.py:104} INFO - [2021-08-16 00:07:43,699] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:07:44,137] {logging_mixin.py:104} INFO - [2021-08-16 00:07:44,135] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 00:07:44,141] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:07:44,152] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.456 seconds
[2021-08-16 00:08:14,322] {scheduler_job.py:181} INFO - Started process (PID=79450) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:08:14,323] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 00:08:14,324] {logging_mixin.py:104} INFO - [2021-08-16 00:08:14,323] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:08:14,881] {logging_mixin.py:104} INFO - [2021-08-16 00:08:14,879] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 00:08:14,886] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:08:14,905] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.585 seconds
[2021-08-16 00:08:45,097] {scheduler_job.py:181} INFO - Started process (PID=79487) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:08:45,098] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 00:08:45,099] {logging_mixin.py:104} INFO - [2021-08-16 00:08:45,099] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:08:45,543] {logging_mixin.py:104} INFO - [2021-08-16 00:08:45,541] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 00:08:45,546] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:08:45,557] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.461 seconds
[2021-08-16 00:09:16,333] {scheduler_job.py:181} INFO - Started process (PID=79526) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:09:16,334] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 00:09:16,335] {logging_mixin.py:104} INFO - [2021-08-16 00:09:16,335] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:09:16,791] {logging_mixin.py:104} INFO - [2021-08-16 00:09:16,789] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 00:09:16,794] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:09:16,805] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.474 seconds
[2021-08-16 00:09:46,946] {scheduler_job.py:181} INFO - Started process (PID=79554) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:09:46,947] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 00:09:46,948] {logging_mixin.py:104} INFO - [2021-08-16 00:09:46,948] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:09:47,383] {logging_mixin.py:104} INFO - [2021-08-16 00:09:47,382] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 00:09:47,386] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:09:47,397] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.452 seconds
[2021-08-16 00:10:17,543] {scheduler_job.py:181} INFO - Started process (PID=79595) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:10:17,544] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 00:10:17,544] {logging_mixin.py:104} INFO - [2021-08-16 00:10:17,544] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:10:17,974] {logging_mixin.py:104} INFO - [2021-08-16 00:10:17,972] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 00:10:17,977] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:10:17,989] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.448 seconds
[2021-08-16 00:10:48,143] {scheduler_job.py:181} INFO - Started process (PID=79634) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:10:48,144] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 00:10:48,145] {logging_mixin.py:104} INFO - [2021-08-16 00:10:48,145] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:10:48,583] {logging_mixin.py:104} INFO - [2021-08-16 00:10:48,581] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 00:10:48,585] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:10:48,598] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.456 seconds
[2021-08-16 00:11:18,740] {scheduler_job.py:181} INFO - Started process (PID=79677) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:11:18,741] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 00:11:18,742] {logging_mixin.py:104} INFO - [2021-08-16 00:11:18,742] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:11:19,185] {logging_mixin.py:104} INFO - [2021-08-16 00:11:19,183] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 00:11:19,187] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:11:19,198] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.460 seconds
[2021-08-16 00:11:49,347] {scheduler_job.py:181} INFO - Started process (PID=79705) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:11:49,349] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 00:11:49,349] {logging_mixin.py:104} INFO - [2021-08-16 00:11:49,349] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:11:49,774] {logging_mixin.py:104} INFO - [2021-08-16 00:11:49,772] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 00:11:49,777] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:11:49,789] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.443 seconds
[2021-08-16 00:12:19,948] {scheduler_job.py:181} INFO - Started process (PID=79745) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:12:19,949] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 00:12:19,950] {logging_mixin.py:104} INFO - [2021-08-16 00:12:19,949] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:12:20,379] {logging_mixin.py:104} INFO - [2021-08-16 00:12:20,377] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 00:12:20,381] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:12:20,391] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.445 seconds
[2021-08-16 00:12:50,558] {scheduler_job.py:181} INFO - Started process (PID=79784) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:12:50,561] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 00:12:50,562] {logging_mixin.py:104} INFO - [2021-08-16 00:12:50,562] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:12:51,001] {logging_mixin.py:104} INFO - [2021-08-16 00:12:50,999] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 00:12:51,004] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:12:51,015] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.462 seconds
[2021-08-16 00:13:21,188] {scheduler_job.py:181} INFO - Started process (PID=79825) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:13:21,189] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 00:13:21,190] {logging_mixin.py:104} INFO - [2021-08-16 00:13:21,190] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:13:21,628] {logging_mixin.py:104} INFO - [2021-08-16 00:13:21,626] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 00:13:21,631] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:13:21,644] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.458 seconds
[2021-08-16 00:13:51,825] {scheduler_job.py:181} INFO - Started process (PID=79852) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:13:51,826] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 00:13:51,827] {logging_mixin.py:104} INFO - [2021-08-16 00:13:51,827] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:13:52,282] {logging_mixin.py:104} INFO - [2021-08-16 00:13:52,281] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 00:13:52,285] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:13:52,296] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.473 seconds
[2021-08-16 00:14:23,060] {scheduler_job.py:181} INFO - Started process (PID=79891) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:14:23,061] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 00:14:23,062] {logging_mixin.py:104} INFO - [2021-08-16 00:14:23,062] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:14:23,519] {logging_mixin.py:104} INFO - [2021-08-16 00:14:23,517] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 00:14:23,521] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:14:23,532] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.474 seconds
[2021-08-16 00:14:53,683] {scheduler_job.py:181} INFO - Started process (PID=79934) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:14:53,684] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 00:14:53,684] {logging_mixin.py:104} INFO - [2021-08-16 00:14:53,684] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:14:54,081] {logging_mixin.py:104} INFO - [2021-08-16 00:14:54,079] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 00:14:54,083] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:14:54,103] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.422 seconds
[2021-08-16 00:15:24,245] {scheduler_job.py:181} INFO - Started process (PID=79975) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:15:24,246] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 00:15:24,247] {logging_mixin.py:104} INFO - [2021-08-16 00:15:24,247] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:15:24,628] {logging_mixin.py:104} INFO - [2021-08-16 00:15:24,626] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 00:15:24,630] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:15:24,649] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.405 seconds
[2021-08-16 00:15:54,790] {scheduler_job.py:181} INFO - Started process (PID=80011) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:15:54,791] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 00:15:54,791] {logging_mixin.py:104} INFO - [2021-08-16 00:15:54,791] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:15:55,182] {logging_mixin.py:104} INFO - [2021-08-16 00:15:55,181] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 00:15:55,184] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:15:55,195] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.408 seconds
[2021-08-16 00:16:25,352] {scheduler_job.py:181} INFO - Started process (PID=80039) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:16:25,353] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 00:16:25,354] {logging_mixin.py:104} INFO - [2021-08-16 00:16:25,354] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:16:25,740] {logging_mixin.py:104} INFO - [2021-08-16 00:16:25,738] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 00:16:25,743] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:16:25,756] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.407 seconds
[2021-08-16 00:16:55,898] {scheduler_job.py:181} INFO - Started process (PID=80078) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:16:55,899] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 00:16:55,900] {logging_mixin.py:104} INFO - [2021-08-16 00:16:55,900] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:16:56,330] {logging_mixin.py:104} INFO - [2021-08-16 00:16:56,328] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 00:16:56,333] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:16:56,344] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.448 seconds
[2021-08-16 00:17:26,491] {scheduler_job.py:181} INFO - Started process (PID=80115) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:17:26,492] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 00:17:26,493] {logging_mixin.py:104} INFO - [2021-08-16 00:17:26,493] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:17:26,885] {logging_mixin.py:104} INFO - [2021-08-16 00:17:26,883] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 00:17:26,887] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:17:26,900] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.410 seconds
[2021-08-16 00:17:57,055] {scheduler_job.py:181} INFO - Started process (PID=80153) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:17:57,057] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 00:17:57,058] {logging_mixin.py:104} INFO - [2021-08-16 00:17:57,058] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:17:57,482] {logging_mixin.py:104} INFO - [2021-08-16 00:17:57,480] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 00:17:57,484] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:17:57,511] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.459 seconds
[2021-08-16 00:18:27,655] {scheduler_job.py:181} INFO - Started process (PID=80181) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:18:27,656] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 00:18:27,657] {logging_mixin.py:104} INFO - [2021-08-16 00:18:27,657] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:18:28,054] {logging_mixin.py:104} INFO - [2021-08-16 00:18:28,052] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 00:18:28,056] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:18:28,068] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.415 seconds
[2021-08-16 00:18:58,247] {scheduler_job.py:181} INFO - Started process (PID=80219) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:18:58,248] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 00:18:58,249] {logging_mixin.py:104} INFO - [2021-08-16 00:18:58,249] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:18:58,657] {logging_mixin.py:104} INFO - [2021-08-16 00:18:58,656] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 00:18:58,660] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:18:58,672] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.427 seconds
[2021-08-16 00:19:28,821] {scheduler_job.py:181} INFO - Started process (PID=80258) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:19:28,822] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 00:19:28,823] {logging_mixin.py:104} INFO - [2021-08-16 00:19:28,823] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:19:29,200] {logging_mixin.py:104} INFO - [2021-08-16 00:19:29,198] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 00:19:29,202] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:19:29,214] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.394 seconds
[2021-08-16 00:19:59,366] {scheduler_job.py:181} INFO - Started process (PID=80296) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:19:59,367] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 00:19:59,368] {logging_mixin.py:104} INFO - [2021-08-16 00:19:59,368] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:19:59,760] {logging_mixin.py:104} INFO - [2021-08-16 00:19:59,759] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 00:19:59,763] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:19:59,775] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.411 seconds
[2021-08-16 00:20:29,916] {scheduler_job.py:181} INFO - Started process (PID=80323) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:20:29,917] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 00:20:29,918] {logging_mixin.py:104} INFO - [2021-08-16 00:20:29,918] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:20:30,319] {logging_mixin.py:104} INFO - [2021-08-16 00:20:30,317] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 00:20:30,321] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:20:30,333] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.419 seconds
[2021-08-16 00:21:00,577] {scheduler_job.py:181} INFO - Started process (PID=80365) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:21:00,578] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 00:21:00,579] {logging_mixin.py:104} INFO - [2021-08-16 00:21:00,579] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:21:00,995] {logging_mixin.py:104} INFO - [2021-08-16 00:21:00,993] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 00:21:00,997] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:21:01,011] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.436 seconds
[2021-08-16 00:21:31,153] {scheduler_job.py:181} INFO - Started process (PID=80406) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:21:31,154] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 00:21:31,155] {logging_mixin.py:104} INFO - [2021-08-16 00:21:31,155] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:21:31,575] {logging_mixin.py:104} INFO - [2021-08-16 00:21:31,573] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 00:21:31,580] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:21:31,592] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.442 seconds
[2021-08-16 00:22:01,735] {scheduler_job.py:181} INFO - Started process (PID=80443) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:22:01,736] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 00:22:01,737] {logging_mixin.py:104} INFO - [2021-08-16 00:22:01,737] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:22:02,148] {logging_mixin.py:104} INFO - [2021-08-16 00:22:02,146] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 00:22:02,151] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:22:02,163] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.430 seconds
[2021-08-16 00:22:32,305] {scheduler_job.py:181} INFO - Started process (PID=80471) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:22:32,306] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 00:22:32,307] {logging_mixin.py:104} INFO - [2021-08-16 00:22:32,307] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:22:32,714] {logging_mixin.py:104} INFO - [2021-08-16 00:22:32,712] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 00:22:32,716] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:22:32,729] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.425 seconds
[2021-08-16 00:23:02,880] {scheduler_job.py:181} INFO - Started process (PID=80511) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:23:02,881] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 00:23:02,882] {logging_mixin.py:104} INFO - [2021-08-16 00:23:02,882] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:23:03,261] {logging_mixin.py:104} INFO - [2021-08-16 00:23:03,259] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 00:23:03,263] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:23:03,275] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.397 seconds
[2021-08-16 00:23:33,421] {scheduler_job.py:181} INFO - Started process (PID=80548) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:23:33,422] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 00:23:33,423] {logging_mixin.py:104} INFO - [2021-08-16 00:23:33,422] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:23:33,805] {logging_mixin.py:104} INFO - [2021-08-16 00:23:33,803] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 00:23:33,807] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:23:33,819] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.400 seconds
[2021-08-16 00:24:03,973] {scheduler_job.py:181} INFO - Started process (PID=80588) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:24:03,974] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 00:24:03,974] {logging_mixin.py:104} INFO - [2021-08-16 00:24:03,974] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:24:04,374] {logging_mixin.py:104} INFO - [2021-08-16 00:24:04,372] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 00:24:04,377] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:24:04,389] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.418 seconds
[2021-08-16 00:24:34,538] {scheduler_job.py:181} INFO - Started process (PID=80616) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:24:34,539] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 00:24:34,540] {logging_mixin.py:104} INFO - [2021-08-16 00:24:34,539] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:24:35,428] {logging_mixin.py:104} INFO - [2021-08-16 00:24:35,427] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 00:24:35,431] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:24:35,443] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.907 seconds
[2021-08-16 00:25:05,753] {scheduler_job.py:181} INFO - Started process (PID=80657) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:25:05,754] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 00:25:05,754] {logging_mixin.py:104} INFO - [2021-08-16 00:25:05,754] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:25:06,200] {logging_mixin.py:104} INFO - [2021-08-16 00:25:06,199] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 00:25:06,203] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:25:06,215] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.464 seconds
[2021-08-16 00:25:36,919] {scheduler_job.py:181} INFO - Started process (PID=80694) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:25:36,920] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 00:25:36,921] {logging_mixin.py:104} INFO - [2021-08-16 00:25:36,921] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:25:37,417] {logging_mixin.py:104} INFO - [2021-08-16 00:25:37,416] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 00:25:37,420] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:25:37,440] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.523 seconds
[2021-08-16 00:26:07,604] {scheduler_job.py:181} INFO - Started process (PID=80733) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:26:07,605] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 00:26:07,605] {logging_mixin.py:104} INFO - [2021-08-16 00:26:07,605] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:26:08,035] {logging_mixin.py:104} INFO - [2021-08-16 00:26:08,032] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 00:26:08,038] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:26:08,053] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.451 seconds
[2021-08-16 00:26:38,199] {scheduler_job.py:181} INFO - Started process (PID=80778) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:26:38,201] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 00:26:38,201] {logging_mixin.py:104} INFO - [2021-08-16 00:26:38,201] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:26:38,656] {logging_mixin.py:104} INFO - [2021-08-16 00:26:38,654] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 00:26:38,660] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:26:38,673] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.475 seconds
[2021-08-16 00:27:08,831] {scheduler_job.py:181} INFO - Started process (PID=80807) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:27:08,833] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 00:27:08,833] {logging_mixin.py:104} INFO - [2021-08-16 00:27:08,833] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:27:09,291] {logging_mixin.py:104} INFO - [2021-08-16 00:27:09,289] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 00:27:09,294] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:27:09,306] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.476 seconds
[2021-08-16 00:27:39,457] {scheduler_job.py:181} INFO - Started process (PID=80846) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:27:39,458] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 00:27:39,459] {logging_mixin.py:104} INFO - [2021-08-16 00:27:39,459] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:27:39,882] {logging_mixin.py:104} INFO - [2021-08-16 00:27:39,880] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 00:27:39,885] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:27:39,897] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.441 seconds
[2021-08-16 00:28:10,064] {scheduler_job.py:181} INFO - Started process (PID=80889) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:28:10,065] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 00:28:10,066] {logging_mixin.py:104} INFO - [2021-08-16 00:28:10,066] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:28:10,519] {logging_mixin.py:104} INFO - [2021-08-16 00:28:10,518] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 00:28:10,522] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:28:10,541] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.479 seconds
[2021-08-16 00:28:40,684] {scheduler_job.py:181} INFO - Started process (PID=80930) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:28:40,685] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 00:28:40,686] {logging_mixin.py:104} INFO - [2021-08-16 00:28:40,686] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:28:41,130] {logging_mixin.py:104} INFO - [2021-08-16 00:28:41,129] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 00:28:41,133] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:28:41,144] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.461 seconds
[2021-08-16 00:29:11,326] {scheduler_job.py:181} INFO - Started process (PID=80959) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:29:11,327] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 00:29:11,327] {logging_mixin.py:104} INFO - [2021-08-16 00:29:11,327] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:29:11,754] {logging_mixin.py:104} INFO - [2021-08-16 00:29:11,752] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 00:29:11,756] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:29:11,768] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.444 seconds
[2021-08-16 00:29:41,914] {scheduler_job.py:181} INFO - Started process (PID=81001) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:29:41,915] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 00:29:41,916] {logging_mixin.py:104} INFO - [2021-08-16 00:29:41,916] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:29:42,396] {logging_mixin.py:104} INFO - [2021-08-16 00:29:42,393] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 00:29:42,399] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:29:42,412] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.499 seconds
[2021-08-16 00:30:12,566] {scheduler_job.py:181} INFO - Started process (PID=81038) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:30:12,567] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 00:30:12,568] {logging_mixin.py:104} INFO - [2021-08-16 00:30:12,568] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:30:13,020] {logging_mixin.py:104} INFO - [2021-08-16 00:30:13,018] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 00:30:13,022] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:30:13,033] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.468 seconds
[2021-08-16 00:30:43,178] {scheduler_job.py:181} INFO - Started process (PID=81075) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:30:43,179] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 00:30:43,179] {logging_mixin.py:104} INFO - [2021-08-16 00:30:43,179] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:30:43,626] {logging_mixin.py:104} INFO - [2021-08-16 00:30:43,624] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 00:30:43,629] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:30:43,641] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.465 seconds
[2021-08-16 00:31:13,789] {scheduler_job.py:181} INFO - Started process (PID=81102) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:31:13,790] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 00:31:13,791] {logging_mixin.py:104} INFO - [2021-08-16 00:31:13,791] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:31:14,774] {logging_mixin.py:104} INFO - [2021-08-16 00:31:14,773] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 00:31:14,778] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:31:14,789] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 1.002 seconds
[2021-08-16 00:31:44,941] {scheduler_job.py:181} INFO - Started process (PID=81137) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:31:44,942] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 00:31:44,942] {logging_mixin.py:104} INFO - [2021-08-16 00:31:44,942] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:31:45,902] {logging_mixin.py:104} INFO - [2021-08-16 00:31:45,901] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 00:31:45,905] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:31:45,917] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.978 seconds
[2021-08-16 00:32:16,103] {scheduler_job.py:181} INFO - Started process (PID=81177) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:32:16,104] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 00:32:16,105] {logging_mixin.py:104} INFO - [2021-08-16 00:32:16,105] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:32:16,559] {logging_mixin.py:104} INFO - [2021-08-16 00:32:16,557] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 00:32:16,562] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:32:16,573] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.472 seconds
[2021-08-16 00:32:46,757] {scheduler_job.py:181} INFO - Started process (PID=81214) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:32:46,758] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 00:32:46,759] {logging_mixin.py:104} INFO - [2021-08-16 00:32:46,759] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:32:47,207] {logging_mixin.py:104} INFO - [2021-08-16 00:32:47,206] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 00:32:47,210] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:32:47,221] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.466 seconds
[2021-08-16 00:33:17,379] {scheduler_job.py:181} INFO - Started process (PID=81251) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:33:17,381] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 00:33:17,382] {logging_mixin.py:104} INFO - [2021-08-16 00:33:17,382] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:33:17,922] {logging_mixin.py:104} INFO - [2021-08-16 00:33:17,920] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 00:33:17,925] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:33:17,937] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.561 seconds
[2021-08-16 00:33:48,123] {scheduler_job.py:181} INFO - Started process (PID=81278) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:33:48,125] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 00:33:48,125] {logging_mixin.py:104} INFO - [2021-08-16 00:33:48,125] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:33:48,613] {logging_mixin.py:104} INFO - [2021-08-16 00:33:48,612] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 00:33:48,616] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:33:48,629] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.507 seconds
[2021-08-16 00:34:18,787] {scheduler_job.py:181} INFO - Started process (PID=81316) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:34:18,788] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 00:34:18,789] {logging_mixin.py:104} INFO - [2021-08-16 00:34:18,789] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:34:19,237] {logging_mixin.py:104} INFO - [2021-08-16 00:34:19,235] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 00:34:19,239] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:34:19,251] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.466 seconds
[2021-08-16 00:34:49,418] {scheduler_job.py:181} INFO - Started process (PID=81355) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:34:49,419] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 00:34:49,420] {logging_mixin.py:104} INFO - [2021-08-16 00:34:49,420] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:34:49,890] {logging_mixin.py:104} INFO - [2021-08-16 00:34:49,888] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 00:34:49,893] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:34:49,906] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.489 seconds
[2021-08-16 00:35:20,061] {scheduler_job.py:181} INFO - Started process (PID=81393) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:35:20,062] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 00:35:20,063] {logging_mixin.py:104} INFO - [2021-08-16 00:35:20,063] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:35:20,578] {logging_mixin.py:104} INFO - [2021-08-16 00:35:20,577] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 00:35:20,581] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:35:20,594] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.535 seconds
[2021-08-16 00:35:50,759] {scheduler_job.py:181} INFO - Started process (PID=81419) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:35:50,760] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 00:35:50,760] {logging_mixin.py:104} INFO - [2021-08-16 00:35:50,760] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:35:51,217] {logging_mixin.py:104} INFO - [2021-08-16 00:35:51,215] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 00:35:51,219] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:35:51,232] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.475 seconds
[2021-08-16 00:36:21,386] {scheduler_job.py:181} INFO - Started process (PID=81458) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:36:21,387] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 00:36:21,388] {logging_mixin.py:104} INFO - [2021-08-16 00:36:21,388] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:36:21,833] {logging_mixin.py:104} INFO - [2021-08-16 00:36:21,831] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 00:36:21,836] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:36:21,846] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.462 seconds
[2021-08-16 00:36:52,003] {scheduler_job.py:181} INFO - Started process (PID=81493) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:36:52,004] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 00:36:52,005] {logging_mixin.py:104} INFO - [2021-08-16 00:36:52,005] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:36:52,449] {logging_mixin.py:104} INFO - [2021-08-16 00:36:52,448] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 00:36:52,452] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:36:52,464] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.463 seconds
[2021-08-16 00:37:22,645] {scheduler_job.py:181} INFO - Started process (PID=81529) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:37:22,646] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 00:37:22,647] {logging_mixin.py:104} INFO - [2021-08-16 00:37:22,647] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:37:23,133] {logging_mixin.py:104} INFO - [2021-08-16 00:37:23,131] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 00:37:23,135] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:37:23,147] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.509 seconds
[2021-08-16 00:37:53,317] {scheduler_job.py:181} INFO - Started process (PID=81560) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:37:53,318] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 00:37:53,318] {logging_mixin.py:104} INFO - [2021-08-16 00:37:53,318] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:37:53,791] {logging_mixin.py:104} INFO - [2021-08-16 00:37:53,788] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 00:37:53,795] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:37:53,817] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.504 seconds
[2021-08-16 00:38:23,987] {scheduler_job.py:181} INFO - Started process (PID=81598) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:38:23,988] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 00:38:23,989] {logging_mixin.py:104} INFO - [2021-08-16 00:38:23,989] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:38:24,447] {logging_mixin.py:104} INFO - [2021-08-16 00:38:24,446] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 00:38:24,451] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:38:24,463] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.478 seconds
[2021-08-16 00:38:54,662] {scheduler_job.py:181} INFO - Started process (PID=81635) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:38:54,663] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 00:38:54,664] {logging_mixin.py:104} INFO - [2021-08-16 00:38:54,664] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:38:55,103] {logging_mixin.py:104} INFO - [2021-08-16 00:38:55,101] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 00:38:55,106] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:38:55,119] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.460 seconds
[2021-08-16 00:39:25,294] {scheduler_job.py:181} INFO - Started process (PID=81663) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:39:25,296] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 00:39:25,296] {logging_mixin.py:104} INFO - [2021-08-16 00:39:25,296] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:39:25,759] {logging_mixin.py:104} INFO - [2021-08-16 00:39:25,757] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 00:39:25,762] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:39:25,774] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.481 seconds
[2021-08-16 00:39:55,930] {scheduler_job.py:181} INFO - Started process (PID=81701) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:39:55,932] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 00:39:55,933] {logging_mixin.py:104} INFO - [2021-08-16 00:39:55,933] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:39:56,389] {logging_mixin.py:104} INFO - [2021-08-16 00:39:56,387] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 00:39:56,392] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:39:56,404] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.475 seconds
[2021-08-16 00:40:26,560] {scheduler_job.py:181} INFO - Started process (PID=81739) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:40:26,561] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 00:40:26,562] {logging_mixin.py:104} INFO - [2021-08-16 00:40:26,562] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:40:27,019] {logging_mixin.py:104} INFO - [2021-08-16 00:40:27,017] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 00:40:27,022] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:40:27,033] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.475 seconds
[2021-08-16 00:40:57,205] {scheduler_job.py:181} INFO - Started process (PID=81778) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:40:57,206] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 00:40:57,207] {logging_mixin.py:104} INFO - [2021-08-16 00:40:57,207] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:40:57,681] {logging_mixin.py:104} INFO - [2021-08-16 00:40:57,679] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 00:40:57,684] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:40:57,698] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.495 seconds
[2021-08-16 00:41:27,868] {scheduler_job.py:181} INFO - Started process (PID=81805) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:41:27,870] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 00:41:27,871] {logging_mixin.py:104} INFO - [2021-08-16 00:41:27,871] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:41:28,318] {logging_mixin.py:104} INFO - [2021-08-16 00:41:28,316] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 00:41:28,321] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:41:28,333] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.466 seconds
[2021-08-16 00:41:58,487] {scheduler_job.py:181} INFO - Started process (PID=81843) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:41:58,488] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 00:41:58,489] {logging_mixin.py:104} INFO - [2021-08-16 00:41:58,489] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:41:59,212] {logging_mixin.py:104} INFO - [2021-08-16 00:41:59,210] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 00:41:59,215] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:41:59,226] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.741 seconds
[2021-08-16 00:42:29,655] {scheduler_job.py:181} INFO - Started process (PID=81879) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:42:29,656] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 00:42:29,657] {logging_mixin.py:104} INFO - [2021-08-16 00:42:29,657] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:42:30,115] {logging_mixin.py:104} INFO - [2021-08-16 00:42:30,113] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 00:42:30,118] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:42:30,131] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.478 seconds
[2021-08-16 00:43:00,837] {scheduler_job.py:181} INFO - Started process (PID=81918) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:43:00,838] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 00:43:00,839] {logging_mixin.py:104} INFO - [2021-08-16 00:43:00,839] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:43:01,282] {logging_mixin.py:104} INFO - [2021-08-16 00:43:01,281] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 00:43:01,286] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:43:01,297] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.462 seconds
[2021-08-16 00:43:31,467] {scheduler_job.py:181} INFO - Started process (PID=81950) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:43:31,469] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 00:43:31,469] {logging_mixin.py:104} INFO - [2021-08-16 00:43:31,469] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:43:31,905] {logging_mixin.py:104} INFO - [2021-08-16 00:43:31,903] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 00:43:31,909] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:43:31,920] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.454 seconds
[2021-08-16 00:44:02,109] {scheduler_job.py:181} INFO - Started process (PID=81990) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:44:02,110] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 00:44:02,111] {logging_mixin.py:104} INFO - [2021-08-16 00:44:02,111] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:44:03,067] {logging_mixin.py:104} INFO - [2021-08-16 00:44:03,065] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 00:44:03,069] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:44:03,081] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.974 seconds
[2021-08-16 00:44:33,286] {scheduler_job.py:181} INFO - Started process (PID=82027) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:44:33,287] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 00:44:33,288] {logging_mixin.py:104} INFO - [2021-08-16 00:44:33,288] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:44:33,746] {logging_mixin.py:104} INFO - [2021-08-16 00:44:33,744] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 00:44:33,750] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:44:33,764] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.480 seconds
[2021-08-16 00:45:03,971] {scheduler_job.py:181} INFO - Started process (PID=82070) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:45:03,972] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 00:45:03,973] {logging_mixin.py:104} INFO - [2021-08-16 00:45:03,973] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:45:04,427] {logging_mixin.py:104} INFO - [2021-08-16 00:45:04,425] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 00:45:04,429] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:45:04,441] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.472 seconds
[2021-08-16 00:45:34,594] {scheduler_job.py:181} INFO - Started process (PID=82097) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:45:34,595] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 00:45:34,596] {logging_mixin.py:104} INFO - [2021-08-16 00:45:34,596] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:45:35,069] {logging_mixin.py:104} INFO - [2021-08-16 00:45:35,068] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 00:45:35,072] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:45:35,083] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.491 seconds
[2021-08-16 00:46:05,249] {scheduler_job.py:181} INFO - Started process (PID=82136) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:46:05,250] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 00:46:05,251] {logging_mixin.py:104} INFO - [2021-08-16 00:46:05,251] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:46:05,691] {logging_mixin.py:104} INFO - [2021-08-16 00:46:05,689] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 00:46:05,694] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:46:05,713] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.465 seconds
[2021-08-16 00:46:35,888] {scheduler_job.py:181} INFO - Started process (PID=82172) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:46:35,889] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 00:46:35,890] {logging_mixin.py:104} INFO - [2021-08-16 00:46:35,890] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:46:36,342] {logging_mixin.py:104} INFO - [2021-08-16 00:46:36,341] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 00:46:36,346] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:46:36,358] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.472 seconds
[2021-08-16 00:47:06,522] {scheduler_job.py:181} INFO - Started process (PID=82211) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:47:06,525] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 00:47:06,526] {logging_mixin.py:104} INFO - [2021-08-16 00:47:06,526] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:47:07,432] {logging_mixin.py:104} INFO - [2021-08-16 00:47:07,431] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 00:47:07,435] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:47:07,447] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.927 seconds
[2021-08-16 00:47:37,703] {scheduler_job.py:181} INFO - Started process (PID=82239) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:47:37,704] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 00:47:37,705] {logging_mixin.py:104} INFO - [2021-08-16 00:47:37,705] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:47:38,116] {logging_mixin.py:104} INFO - [2021-08-16 00:47:38,114] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 00:47:38,119] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:47:38,130] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.429 seconds
[2021-08-16 00:48:08,290] {scheduler_job.py:181} INFO - Started process (PID=82278) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:48:08,291] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 00:48:08,293] {logging_mixin.py:104} INFO - [2021-08-16 00:48:08,292] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:48:08,723] {logging_mixin.py:104} INFO - [2021-08-16 00:48:08,721] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 00:48:08,726] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:48:08,749] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.461 seconds
[2021-08-16 00:48:38,915] {scheduler_job.py:181} INFO - Started process (PID=82320) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:48:38,916] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 00:48:38,917] {logging_mixin.py:104} INFO - [2021-08-16 00:48:38,917] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:48:39,334] {logging_mixin.py:104} INFO - [2021-08-16 00:48:39,332] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 00:48:39,337] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:48:39,350] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.437 seconds
[2021-08-16 00:49:09,535] {scheduler_job.py:181} INFO - Started process (PID=82358) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:49:09,536] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 00:49:09,537] {logging_mixin.py:104} INFO - [2021-08-16 00:49:09,537] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:49:09,946] {logging_mixin.py:104} INFO - [2021-08-16 00:49:09,945] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 00:49:09,949] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:49:09,968] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.435 seconds
[2021-08-16 00:49:40,120] {scheduler_job.py:181} INFO - Started process (PID=82385) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:49:40,121] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 00:49:40,122] {logging_mixin.py:104} INFO - [2021-08-16 00:49:40,121] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:49:40,526] {logging_mixin.py:104} INFO - [2021-08-16 00:49:40,524] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 00:49:40,529] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:49:40,542] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.424 seconds
[2021-08-16 00:50:10,697] {scheduler_job.py:181} INFO - Started process (PID=82427) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:50:10,698] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 00:50:10,699] {logging_mixin.py:104} INFO - [2021-08-16 00:50:10,699] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:50:11,083] {logging_mixin.py:104} INFO - [2021-08-16 00:50:11,081] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 00:50:11,086] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:50:11,106] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.411 seconds
[2021-08-16 00:50:41,264] {scheduler_job.py:181} INFO - Started process (PID=82469) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:50:41,265] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 00:50:41,266] {logging_mixin.py:104} INFO - [2021-08-16 00:50:41,266] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:50:41,685] {logging_mixin.py:104} INFO - [2021-08-16 00:50:41,683] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 00:50:41,688] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:50:41,708] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.446 seconds
[2021-08-16 00:51:11,863] {scheduler_job.py:181} INFO - Started process (PID=82508) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:51:11,865] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 00:51:11,866] {logging_mixin.py:104} INFO - [2021-08-16 00:51:11,865] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:51:12,311] {logging_mixin.py:104} INFO - [2021-08-16 00:51:12,309] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 00:51:12,314] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:51:12,333] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.472 seconds
[2021-08-16 00:51:42,482] {scheduler_job.py:181} INFO - Started process (PID=82533) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:51:42,483] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 00:51:42,484] {logging_mixin.py:104} INFO - [2021-08-16 00:51:42,484] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:51:42,886] {logging_mixin.py:104} INFO - [2021-08-16 00:51:42,884] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 00:51:42,889] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:51:42,902] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.421 seconds
[2021-08-16 00:52:13,054] {scheduler_job.py:181} INFO - Started process (PID=82569) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:52:13,055] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 00:52:13,056] {logging_mixin.py:104} INFO - [2021-08-16 00:52:13,055] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:52:13,439] {logging_mixin.py:104} INFO - [2021-08-16 00:52:13,437] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 00:52:13,442] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:52:13,456] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.404 seconds
[2021-08-16 00:52:43,615] {scheduler_job.py:181} INFO - Started process (PID=82610) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:52:43,616] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 00:52:43,617] {logging_mixin.py:104} INFO - [2021-08-16 00:52:43,617] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:52:44,525] {logging_mixin.py:104} INFO - [2021-08-16 00:52:44,523] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 00:52:44,528] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:52:44,541] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.928 seconds
[2021-08-16 00:53:14,834] {scheduler_job.py:181} INFO - Started process (PID=82649) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:53:14,836] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 00:53:14,836] {logging_mixin.py:104} INFO - [2021-08-16 00:53:14,836] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:53:15,262] {logging_mixin.py:104} INFO - [2021-08-16 00:53:15,260] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 00:53:15,265] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:53:15,278] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.446 seconds
[2021-08-16 00:53:46,008] {scheduler_job.py:181} INFO - Started process (PID=82676) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:53:46,009] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 00:53:46,010] {logging_mixin.py:104} INFO - [2021-08-16 00:53:46,010] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:53:46,406] {logging_mixin.py:104} INFO - [2021-08-16 00:53:46,404] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 00:53:46,409] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:53:46,423] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.417 seconds
[2021-08-16 00:54:16,625] {scheduler_job.py:181} INFO - Started process (PID=82712) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:54:16,626] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 00:54:16,626] {logging_mixin.py:104} INFO - [2021-08-16 00:54:16,626] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:54:17,047] {logging_mixin.py:104} INFO - [2021-08-16 00:54:17,045] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 00:54:17,050] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:54:17,063] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.440 seconds
[2021-08-16 00:54:47,224] {scheduler_job.py:181} INFO - Started process (PID=82751) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:54:47,225] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 00:54:47,226] {logging_mixin.py:104} INFO - [2021-08-16 00:54:47,226] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:54:47,620] {logging_mixin.py:104} INFO - [2021-08-16 00:54:47,618] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 00:54:47,623] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:54:47,636] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.414 seconds
[2021-08-16 00:55:18,516] {scheduler_job.py:181} INFO - Started process (PID=82789) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:55:18,517] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 00:55:18,518] {logging_mixin.py:104} INFO - [2021-08-16 00:55:18,518] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:55:18,986] {logging_mixin.py:104} INFO - [2021-08-16 00:55:18,984] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 00:55:18,988] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:55:19,001] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.486 seconds
[2021-08-16 00:55:49,169] {scheduler_job.py:181} INFO - Started process (PID=82818) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:55:49,171] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 00:55:49,171] {logging_mixin.py:104} INFO - [2021-08-16 00:55:49,171] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:55:49,631] {logging_mixin.py:104} INFO - [2021-08-16 00:55:49,629] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 00:55:49,633] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:55:49,646] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.479 seconds
[2021-08-16 00:56:19,845] {scheduler_job.py:181} INFO - Started process (PID=82857) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:56:19,846] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 00:56:19,847] {logging_mixin.py:104} INFO - [2021-08-16 00:56:19,847] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:56:20,297] {logging_mixin.py:104} INFO - [2021-08-16 00:56:20,295] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 00:56:20,300] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:56:20,312] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.469 seconds
[2021-08-16 00:56:50,491] {scheduler_job.py:181} INFO - Started process (PID=82894) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:56:50,492] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 00:56:50,493] {logging_mixin.py:104} INFO - [2021-08-16 00:56:50,493] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:56:50,950] {logging_mixin.py:104} INFO - [2021-08-16 00:56:50,948] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 00:56:50,953] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:56:50,965] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.475 seconds
[2021-08-16 00:57:21,122] {scheduler_job.py:181} INFO - Started process (PID=82934) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:57:21,123] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 00:57:21,124] {logging_mixin.py:104} INFO - [2021-08-16 00:57:21,124] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:57:21,590] {logging_mixin.py:104} INFO - [2021-08-16 00:57:21,588] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 00:57:21,593] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:57:21,608] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.488 seconds
[2021-08-16 00:57:51,772] {scheduler_job.py:181} INFO - Started process (PID=82961) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:57:51,773] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 00:57:51,774] {logging_mixin.py:104} INFO - [2021-08-16 00:57:51,774] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:57:52,221] {logging_mixin.py:104} INFO - [2021-08-16 00:57:52,219] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 00:57:52,224] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:57:52,238] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.467 seconds
[2021-08-16 00:58:22,406] {scheduler_job.py:181} INFO - Started process (PID=82997) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:58:22,407] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 00:58:22,407] {logging_mixin.py:104} INFO - [2021-08-16 00:58:22,407] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:58:22,854] {logging_mixin.py:104} INFO - [2021-08-16 00:58:22,852] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 00:58:22,857] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:58:22,869] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.465 seconds
[2021-08-16 00:58:53,076] {scheduler_job.py:181} INFO - Started process (PID=83036) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:58:53,077] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 00:58:53,078] {logging_mixin.py:104} INFO - [2021-08-16 00:58:53,077] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:58:53,527] {logging_mixin.py:104} INFO - [2021-08-16 00:58:53,526] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 00:58:53,530] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:58:53,544] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.470 seconds
[2021-08-16 00:59:23,706] {scheduler_job.py:181} INFO - Started process (PID=83073) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:59:23,707] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 00:59:23,708] {logging_mixin.py:104} INFO - [2021-08-16 00:59:23,708] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:59:24,171] {logging_mixin.py:104} INFO - [2021-08-16 00:59:24,168] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 00:59:24,176] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:59:24,194] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.490 seconds
[2021-08-16 00:59:54,381] {scheduler_job.py:181} INFO - Started process (PID=83104) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:59:54,383] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 00:59:54,385] {logging_mixin.py:104} INFO - [2021-08-16 00:59:54,385] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:59:54,835] {logging_mixin.py:104} INFO - [2021-08-16 00:59:54,833] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 00:59:54,838] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 00:59:54,850] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.471 seconds
[2021-08-16 01:00:25,012] {scheduler_job.py:181} INFO - Started process (PID=83144) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:00:25,013] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 01:00:25,014] {logging_mixin.py:104} INFO - [2021-08-16 01:00:25,014] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:00:25,493] {logging_mixin.py:104} INFO - [2021-08-16 01:00:25,492] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 01:00:25,497] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:00:25,510] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.499 seconds
[2021-08-16 01:00:55,668] {scheduler_job.py:181} INFO - Started process (PID=83185) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:00:55,669] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 01:00:55,670] {logging_mixin.py:104} INFO - [2021-08-16 01:00:55,670] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:00:56,113] {logging_mixin.py:104} INFO - [2021-08-16 01:00:56,111] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 01:00:56,116] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:00:56,128] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.462 seconds
[2021-08-16 01:01:26,288] {scheduler_job.py:181} INFO - Started process (PID=83213) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:01:26,289] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 01:01:26,290] {logging_mixin.py:104} INFO - [2021-08-16 01:01:26,290] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:01:26,727] {logging_mixin.py:104} INFO - [2021-08-16 01:01:26,725] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 01:01:26,730] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:01:26,741] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.455 seconds
[2021-08-16 01:01:56,908] {scheduler_job.py:181} INFO - Started process (PID=83251) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:01:56,909] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 01:01:56,909] {logging_mixin.py:104} INFO - [2021-08-16 01:01:56,909] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:01:57,878] {logging_mixin.py:104} INFO - [2021-08-16 01:01:57,876] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 01:01:57,881] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:01:57,894] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.988 seconds
[2021-08-16 01:02:28,055] {scheduler_job.py:181} INFO - Started process (PID=83291) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:02:28,056] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 01:02:28,057] {logging_mixin.py:104} INFO - [2021-08-16 01:02:28,057] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:02:28,508] {logging_mixin.py:104} INFO - [2021-08-16 01:02:28,507] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 01:02:28,512] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:02:28,524] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.470 seconds
[2021-08-16 01:02:58,680] {scheduler_job.py:181} INFO - Started process (PID=83338) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:02:58,682] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 01:02:58,682] {logging_mixin.py:104} INFO - [2021-08-16 01:02:58,682] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:02:59,167] {logging_mixin.py:104} INFO - [2021-08-16 01:02:59,165] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 01:02:59,170] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:02:59,189] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.510 seconds
[2021-08-16 01:03:29,353] {scheduler_job.py:181} INFO - Started process (PID=83368) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:03:29,354] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 01:03:29,355] {logging_mixin.py:104} INFO - [2021-08-16 01:03:29,355] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:03:29,810] {logging_mixin.py:104} INFO - [2021-08-16 01:03:29,808] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 01:03:29,812] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:03:29,824] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.473 seconds
[2021-08-16 01:04:00,020] {scheduler_job.py:181} INFO - Started process (PID=83408) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:04:00,021] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 01:04:00,022] {logging_mixin.py:104} INFO - [2021-08-16 01:04:00,022] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:04:00,489] {logging_mixin.py:104} INFO - [2021-08-16 01:04:00,487] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 01:04:00,493] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:04:00,505] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.486 seconds
[2021-08-16 01:04:30,672] {scheduler_job.py:181} INFO - Started process (PID=83447) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:04:30,673] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 01:04:30,674] {logging_mixin.py:104} INFO - [2021-08-16 01:04:30,674] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:04:31,168] {logging_mixin.py:104} INFO - [2021-08-16 01:04:31,166] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 01:04:31,172] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:04:31,203] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.533 seconds
[2021-08-16 01:05:01,370] {scheduler_job.py:181} INFO - Started process (PID=83488) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:05:01,371] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 01:05:01,372] {logging_mixin.py:104} INFO - [2021-08-16 01:05:01,372] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:05:01,831] {logging_mixin.py:104} INFO - [2021-08-16 01:05:01,828] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 01:05:01,837] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:05:01,855] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.487 seconds
[2021-08-16 01:05:32,030] {scheduler_job.py:181} INFO - Started process (PID=83517) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:05:32,031] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 01:05:32,032] {logging_mixin.py:104} INFO - [2021-08-16 01:05:32,032] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:05:32,469] {logging_mixin.py:104} INFO - [2021-08-16 01:05:32,467] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 01:05:32,471] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:05:32,501] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.473 seconds
[2021-08-16 01:06:02,674] {scheduler_job.py:181} INFO - Started process (PID=83554) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:06:02,675] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 01:06:02,676] {logging_mixin.py:104} INFO - [2021-08-16 01:06:02,676] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:06:03,159] {logging_mixin.py:104} INFO - [2021-08-16 01:06:03,157] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 01:06:03,162] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:06:03,174] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.502 seconds
[2021-08-16 01:06:33,336] {scheduler_job.py:181} INFO - Started process (PID=83591) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:06:33,338] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 01:06:33,338] {logging_mixin.py:104} INFO - [2021-08-16 01:06:33,338] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:06:33,774] {logging_mixin.py:104} INFO - [2021-08-16 01:06:33,772] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 01:06:33,776] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:06:33,789] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.455 seconds
[2021-08-16 01:07:03,947] {scheduler_job.py:181} INFO - Started process (PID=83628) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:07:03,948] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 01:07:03,949] {logging_mixin.py:104} INFO - [2021-08-16 01:07:03,948] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:07:04,434] {logging_mixin.py:104} INFO - [2021-08-16 01:07:04,432] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 01:07:04,437] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:07:04,449] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.505 seconds
[2021-08-16 01:07:34,617] {scheduler_job.py:181} INFO - Started process (PID=83654) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:07:34,618] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 01:07:34,619] {logging_mixin.py:104} INFO - [2021-08-16 01:07:34,619] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:07:35,637] {logging_mixin.py:104} INFO - [2021-08-16 01:07:35,635] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 01:07:35,639] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:07:35,660] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 1.044 seconds
[2021-08-16 01:08:05,817] {scheduler_job.py:181} INFO - Started process (PID=83693) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:08:05,818] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 01:08:05,819] {logging_mixin.py:104} INFO - [2021-08-16 01:08:05,819] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:08:06,262] {logging_mixin.py:104} INFO - [2021-08-16 01:08:06,260] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 01:08:06,264] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:08:06,276] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.461 seconds
[2021-08-16 01:08:36,434] {scheduler_job.py:181} INFO - Started process (PID=83732) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:08:36,435] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 01:08:36,436] {logging_mixin.py:104} INFO - [2021-08-16 01:08:36,436] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:08:36,875] {logging_mixin.py:104} INFO - [2021-08-16 01:08:36,874] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 01:08:36,878] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:08:36,897] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.466 seconds
[2021-08-16 01:09:07,118] {scheduler_job.py:181} INFO - Started process (PID=83771) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:09:07,119] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 01:09:07,120] {logging_mixin.py:104} INFO - [2021-08-16 01:09:07,120] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:09:07,570] {logging_mixin.py:104} INFO - [2021-08-16 01:09:07,568] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 01:09:07,573] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:09:07,588] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.471 seconds
[2021-08-16 01:09:38,354] {scheduler_job.py:181} INFO - Started process (PID=83801) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:09:38,355] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 01:09:38,356] {logging_mixin.py:104} INFO - [2021-08-16 01:09:38,356] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:09:38,813] {logging_mixin.py:104} INFO - [2021-08-16 01:09:38,809] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 01:09:38,817] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:09:38,835] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.483 seconds
[2021-08-16 01:10:09,000] {scheduler_job.py:181} INFO - Started process (PID=83838) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:10:09,001] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 01:10:09,002] {logging_mixin.py:104} INFO - [2021-08-16 01:10:09,002] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:10:09,457] {logging_mixin.py:104} INFO - [2021-08-16 01:10:09,455] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 01:10:09,460] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:10:09,473] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.475 seconds
[2021-08-16 01:10:39,631] {scheduler_job.py:181} INFO - Started process (PID=83876) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:10:39,632] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 01:10:39,633] {logging_mixin.py:104} INFO - [2021-08-16 01:10:39,633] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:10:40,106] {logging_mixin.py:104} INFO - [2021-08-16 01:10:40,105] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 01:10:40,109] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:10:40,122] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.492 seconds
[2021-08-16 01:11:10,284] {scheduler_job.py:181} INFO - Started process (PID=83914) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:11:10,285] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 01:11:10,286] {logging_mixin.py:104} INFO - [2021-08-16 01:11:10,286] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:11:10,749] {logging_mixin.py:104} INFO - [2021-08-16 01:11:10,747] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 01:11:10,752] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:11:10,771] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.490 seconds
[2021-08-16 01:11:40,937] {scheduler_job.py:181} INFO - Started process (PID=83944) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:11:40,938] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 01:11:40,938] {logging_mixin.py:104} INFO - [2021-08-16 01:11:40,938] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:11:41,400] {logging_mixin.py:104} INFO - [2021-08-16 01:11:41,399] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 01:11:41,403] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:11:41,415] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.480 seconds
[2021-08-16 01:12:11,590] {scheduler_job.py:181} INFO - Started process (PID=83987) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:12:11,591] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 01:12:11,592] {logging_mixin.py:104} INFO - [2021-08-16 01:12:11,592] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:12:12,038] {logging_mixin.py:104} INFO - [2021-08-16 01:12:12,037] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 01:12:12,041] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:12:12,053] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.465 seconds
[2021-08-16 01:12:42,208] {scheduler_job.py:181} INFO - Started process (PID=84024) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:12:42,209] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 01:12:42,210] {logging_mixin.py:104} INFO - [2021-08-16 01:12:42,210] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:12:42,641] {logging_mixin.py:104} INFO - [2021-08-16 01:12:42,639] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 01:12:42,643] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:12:42,655] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.449 seconds
[2021-08-16 01:13:12,810] {scheduler_job.py:181} INFO - Started process (PID=84063) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:13:12,811] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 01:13:12,811] {logging_mixin.py:104} INFO - [2021-08-16 01:13:12,811] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:13:13,240] {logging_mixin.py:104} INFO - [2021-08-16 01:13:13,239] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 01:13:13,243] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:13:13,255] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.447 seconds
[2021-08-16 01:13:43,399] {scheduler_job.py:181} INFO - Started process (PID=84090) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:13:43,400] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 01:13:43,400] {logging_mixin.py:104} INFO - [2021-08-16 01:13:43,400] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:13:43,843] {logging_mixin.py:104} INFO - [2021-08-16 01:13:43,842] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 01:13:43,846] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:13:43,857] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.461 seconds
[2021-08-16 01:14:14,005] {scheduler_job.py:181} INFO - Started process (PID=84128) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:14:14,006] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 01:14:14,007] {logging_mixin.py:104} INFO - [2021-08-16 01:14:14,006] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:14:14,441] {logging_mixin.py:104} INFO - [2021-08-16 01:14:14,439] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 01:14:14,443] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:14:14,454] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.451 seconds
[2021-08-16 01:14:44,610] {scheduler_job.py:181} INFO - Started process (PID=84165) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:14:44,611] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 01:14:44,612] {logging_mixin.py:104} INFO - [2021-08-16 01:14:44,612] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:14:45,035] {logging_mixin.py:104} INFO - [2021-08-16 01:14:45,034] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 01:14:45,038] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:14:45,048] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.440 seconds
[2021-08-16 01:15:15,204] {scheduler_job.py:181} INFO - Started process (PID=84202) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:15:15,205] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 01:15:15,206] {logging_mixin.py:104} INFO - [2021-08-16 01:15:15,206] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:15:15,648] {logging_mixin.py:104} INFO - [2021-08-16 01:15:15,646] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 01:15:15,651] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:15:15,663] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.461 seconds
[2021-08-16 01:15:45,811] {scheduler_job.py:181} INFO - Started process (PID=84237) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:15:45,812] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 01:15:45,813] {logging_mixin.py:104} INFO - [2021-08-16 01:15:45,812] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:15:46,276] {logging_mixin.py:104} INFO - [2021-08-16 01:15:46,275] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 01:15:46,278] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:15:46,289] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.480 seconds
[2021-08-16 01:16:16,434] {scheduler_job.py:181} INFO - Started process (PID=84269) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:16:16,435] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 01:16:16,436] {logging_mixin.py:104} INFO - [2021-08-16 01:16:16,435] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:16:16,860] {logging_mixin.py:104} INFO - [2021-08-16 01:16:16,859] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 01:16:16,863] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:16:16,873] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.441 seconds
[2021-08-16 01:16:47,028] {scheduler_job.py:181} INFO - Started process (PID=84308) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:16:47,029] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 01:16:47,030] {logging_mixin.py:104} INFO - [2021-08-16 01:16:47,030] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:16:47,461] {logging_mixin.py:104} INFO - [2021-08-16 01:16:47,459] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 01:16:47,463] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:16:47,474] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.447 seconds
[2021-08-16 01:17:17,622] {scheduler_job.py:181} INFO - Started process (PID=84346) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:17:17,624] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 01:17:17,625] {logging_mixin.py:104} INFO - [2021-08-16 01:17:17,624] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:17:18,086] {logging_mixin.py:104} INFO - [2021-08-16 01:17:18,084] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 01:17:18,089] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:17:18,100] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.480 seconds
[2021-08-16 01:17:48,260] {scheduler_job.py:181} INFO - Started process (PID=84388) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:17:48,261] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 01:17:48,262] {logging_mixin.py:104} INFO - [2021-08-16 01:17:48,262] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:17:48,730] {logging_mixin.py:104} INFO - [2021-08-16 01:17:48,729] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 01:17:48,734] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:17:48,745] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.487 seconds
[2021-08-16 01:18:18,908] {scheduler_job.py:181} INFO - Started process (PID=84418) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:18:18,909] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 01:18:18,910] {logging_mixin.py:104} INFO - [2021-08-16 01:18:18,910] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:18:19,349] {logging_mixin.py:104} INFO - [2021-08-16 01:18:19,348] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 01:18:19,353] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:18:19,364] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.458 seconds
[2021-08-16 01:18:49,531] {scheduler_job.py:181} INFO - Started process (PID=84457) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:18:49,532] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 01:18:49,533] {logging_mixin.py:104} INFO - [2021-08-16 01:18:49,533] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:18:49,969] {logging_mixin.py:104} INFO - [2021-08-16 01:18:49,968] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 01:18:49,972] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:18:49,983] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.454 seconds
[2021-08-16 01:19:20,140] {scheduler_job.py:181} INFO - Started process (PID=84500) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:19:20,141] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 01:19:20,142] {logging_mixin.py:104} INFO - [2021-08-16 01:19:20,142] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:19:20,607] {logging_mixin.py:104} INFO - [2021-08-16 01:19:20,605] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 01:19:20,610] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:19:20,622] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.483 seconds
[2021-08-16 01:19:50,774] {scheduler_job.py:181} INFO - Started process (PID=84539) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:19:50,775] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 01:19:50,776] {logging_mixin.py:104} INFO - [2021-08-16 01:19:50,776] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:19:51,246] {logging_mixin.py:104} INFO - [2021-08-16 01:19:51,245] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 01:19:51,249] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:19:51,261] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.490 seconds
[2021-08-16 01:20:21,435] {scheduler_job.py:181} INFO - Started process (PID=84566) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:20:21,436] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 01:20:21,436] {logging_mixin.py:104} INFO - [2021-08-16 01:20:21,436] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:20:21,881] {logging_mixin.py:104} INFO - [2021-08-16 01:20:21,879] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 01:20:21,884] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:20:21,896] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.463 seconds
[2021-08-16 01:20:52,047] {scheduler_job.py:181} INFO - Started process (PID=84603) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:20:52,048] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 01:20:52,049] {logging_mixin.py:104} INFO - [2021-08-16 01:20:52,049] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:20:52,493] {logging_mixin.py:104} INFO - [2021-08-16 01:20:52,491] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 01:20:52,496] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:20:52,506] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.461 seconds
[2021-08-16 01:21:22,655] {scheduler_job.py:181} INFO - Started process (PID=84643) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:21:22,657] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 01:21:22,657] {logging_mixin.py:104} INFO - [2021-08-16 01:21:22,657] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:21:23,101] {logging_mixin.py:104} INFO - [2021-08-16 01:21:23,099] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 01:21:23,103] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:21:23,114] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.460 seconds
[2021-08-16 01:21:53,268] {scheduler_job.py:181} INFO - Started process (PID=84679) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:21:53,269] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 01:21:53,270] {logging_mixin.py:104} INFO - [2021-08-16 01:21:53,270] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:21:53,659] {logging_mixin.py:104} INFO - [2021-08-16 01:21:53,658] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 01:21:53,662] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:21:53,675] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.408 seconds
[2021-08-16 01:22:23,825] {scheduler_job.py:181} INFO - Started process (PID=84707) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:22:23,826] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 01:22:23,827] {logging_mixin.py:104} INFO - [2021-08-16 01:22:23,827] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:22:24,233] {logging_mixin.py:104} INFO - [2021-08-16 01:22:24,231] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 01:22:24,235] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:22:24,247] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.424 seconds
[2021-08-16 01:22:54,388] {scheduler_job.py:181} INFO - Started process (PID=84746) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:22:54,389] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 01:22:54,390] {logging_mixin.py:104} INFO - [2021-08-16 01:22:54,390] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:22:54,791] {logging_mixin.py:104} INFO - [2021-08-16 01:22:54,789] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 01:22:54,794] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:22:54,807] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.421 seconds
[2021-08-16 01:23:24,959] {scheduler_job.py:181} INFO - Started process (PID=84784) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:23:24,961] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 01:23:24,961] {logging_mixin.py:104} INFO - [2021-08-16 01:23:24,961] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:23:25,355] {logging_mixin.py:104} INFO - [2021-08-16 01:23:25,353] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 01:23:25,358] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:23:25,371] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.414 seconds
[2021-08-16 01:23:55,540] {scheduler_job.py:181} INFO - Started process (PID=84824) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:23:55,541] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 01:23:55,542] {logging_mixin.py:104} INFO - [2021-08-16 01:23:55,542] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:23:55,939] {logging_mixin.py:104} INFO - [2021-08-16 01:23:55,938] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 01:23:55,942] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:23:55,955] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.416 seconds
[2021-08-16 01:24:26,103] {scheduler_job.py:181} INFO - Started process (PID=84851) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:24:26,104] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 01:24:26,105] {logging_mixin.py:104} INFO - [2021-08-16 01:24:26,105] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:24:26,498] {logging_mixin.py:104} INFO - [2021-08-16 01:24:26,497] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 01:24:26,501] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:24:26,513] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.412 seconds
[2021-08-16 01:24:56,660] {scheduler_job.py:181} INFO - Started process (PID=84888) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:24:56,661] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 01:24:56,662] {logging_mixin.py:104} INFO - [2021-08-16 01:24:56,662] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:24:57,066] {logging_mixin.py:104} INFO - [2021-08-16 01:24:57,063] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 01:24:57,070] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:24:57,083] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.424 seconds
[2021-08-16 01:25:27,276] {scheduler_job.py:181} INFO - Started process (PID=84928) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:25:27,278] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 01:25:27,278] {logging_mixin.py:104} INFO - [2021-08-16 01:25:27,278] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:25:27,734] {logging_mixin.py:104} INFO - [2021-08-16 01:25:27,733] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 01:25:27,736] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:25:27,748] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.475 seconds
[2021-08-16 01:25:57,898] {scheduler_job.py:181} INFO - Started process (PID=84968) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:25:57,899] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 01:25:57,900] {logging_mixin.py:104} INFO - [2021-08-16 01:25:57,900] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:25:58,332] {logging_mixin.py:104} INFO - [2021-08-16 01:25:58,330] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 01:25:58,334] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:25:58,346] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.450 seconds
[2021-08-16 01:26:28,494] {scheduler_job.py:181} INFO - Started process (PID=84994) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:26:28,495] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 01:26:28,496] {logging_mixin.py:104} INFO - [2021-08-16 01:26:28,496] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:26:28,923] {logging_mixin.py:104} INFO - [2021-08-16 01:26:28,921] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 01:26:28,925] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:26:28,936] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.443 seconds
[2021-08-16 01:26:59,081] {scheduler_job.py:181} INFO - Started process (PID=85036) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:26:59,082] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 01:26:59,083] {logging_mixin.py:104} INFO - [2021-08-16 01:26:59,083] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:26:59,540] {logging_mixin.py:104} INFO - [2021-08-16 01:26:59,538] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 01:26:59,542] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:26:59,561] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.481 seconds
[2021-08-16 01:27:29,705] {scheduler_job.py:181} INFO - Started process (PID=85079) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:27:29,707] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 01:27:29,707] {logging_mixin.py:104} INFO - [2021-08-16 01:27:29,707] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:27:30,127] {logging_mixin.py:104} INFO - [2021-08-16 01:27:30,125] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 01:27:30,129] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:27:30,141] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.438 seconds
[2021-08-16 01:28:00,298] {scheduler_job.py:181} INFO - Started process (PID=85117) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:28:00,298] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 01:28:00,299] {logging_mixin.py:104} INFO - [2021-08-16 01:28:00,299] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:28:00,737] {logging_mixin.py:104} INFO - [2021-08-16 01:28:00,736] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 01:28:00,740] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:28:00,751] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.455 seconds
[2021-08-16 01:28:30,903] {scheduler_job.py:181} INFO - Started process (PID=85143) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:28:30,905] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 01:28:30,905] {logging_mixin.py:104} INFO - [2021-08-16 01:28:30,905] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:28:31,337] {logging_mixin.py:104} INFO - [2021-08-16 01:28:31,335] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 01:28:31,341] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:28:31,363] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.461 seconds
[2021-08-16 01:29:01,523] {scheduler_job.py:181} INFO - Started process (PID=85181) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:29:01,524] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 01:29:01,525] {logging_mixin.py:104} INFO - [2021-08-16 01:29:01,525] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:29:01,947] {logging_mixin.py:104} INFO - [2021-08-16 01:29:01,945] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 01:29:01,949] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:29:01,960] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.439 seconds
[2021-08-16 01:29:32,132] {scheduler_job.py:181} INFO - Started process (PID=85221) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:29:32,133] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 01:29:32,134] {logging_mixin.py:104} INFO - [2021-08-16 01:29:32,134] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:29:32,558] {logging_mixin.py:104} INFO - [2021-08-16 01:29:32,557] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 01:29:32,561] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:29:32,572] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.442 seconds
[2021-08-16 01:30:02,731] {scheduler_job.py:181} INFO - Started process (PID=85261) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:30:02,732] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 01:30:02,733] {logging_mixin.py:104} INFO - [2021-08-16 01:30:02,733] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:30:03,169] {logging_mixin.py:104} INFO - [2021-08-16 01:30:03,167] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 01:30:03,172] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:30:03,183] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.454 seconds
[2021-08-16 01:30:33,330] {scheduler_job.py:181} INFO - Started process (PID=85303) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:30:33,331] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 01:30:33,332] {logging_mixin.py:104} INFO - [2021-08-16 01:30:33,332] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:30:33,774] {logging_mixin.py:104} INFO - [2021-08-16 01:30:33,773] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 01:30:33,778] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:30:33,791] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.463 seconds
[2021-08-16 01:31:03,942] {scheduler_job.py:181} INFO - Started process (PID=85331) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:31:03,943] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 01:31:03,944] {logging_mixin.py:104} INFO - [2021-08-16 01:31:03,944] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:31:04,435] {logging_mixin.py:104} INFO - [2021-08-16 01:31:04,434] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 01:31:04,438] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:31:04,448] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.508 seconds
[2021-08-16 01:31:34,600] {scheduler_job.py:181} INFO - Started process (PID=85372) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:31:34,603] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 01:31:34,604] {logging_mixin.py:104} INFO - [2021-08-16 01:31:34,604] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:31:35,026] {logging_mixin.py:104} INFO - [2021-08-16 01:31:35,025] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 01:31:35,029] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:31:35,040] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.442 seconds
[2021-08-16 01:32:05,185] {scheduler_job.py:181} INFO - Started process (PID=85410) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:32:05,187] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 01:32:05,187] {logging_mixin.py:104} INFO - [2021-08-16 01:32:05,187] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:32:05,616] {logging_mixin.py:104} INFO - [2021-08-16 01:32:05,614] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 01:32:05,618] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:32:05,629] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.446 seconds
[2021-08-16 01:32:35,774] {scheduler_job.py:181} INFO - Started process (PID=85446) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:32:35,775] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 01:32:35,776] {logging_mixin.py:104} INFO - [2021-08-16 01:32:35,776] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:32:36,214] {logging_mixin.py:104} INFO - [2021-08-16 01:32:36,212] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 01:32:36,216] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:32:36,228] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.456 seconds
[2021-08-16 01:33:06,393] {scheduler_job.py:181} INFO - Started process (PID=85471) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:33:06,394] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 01:33:06,395] {logging_mixin.py:104} INFO - [2021-08-16 01:33:06,395] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:33:06,906] {logging_mixin.py:104} INFO - [2021-08-16 01:33:06,904] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 01:33:06,908] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:33:06,920] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.530 seconds
[2021-08-16 01:33:37,071] {scheduler_job.py:181} INFO - Started process (PID=85518) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:33:37,072] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 01:33:37,072] {logging_mixin.py:104} INFO - [2021-08-16 01:33:37,072] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:33:37,504] {logging_mixin.py:104} INFO - [2021-08-16 01:33:37,502] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 01:33:37,506] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:33:37,517] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.448 seconds
[2021-08-16 01:34:07,691] {scheduler_job.py:181} INFO - Started process (PID=85561) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:34:07,692] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 01:34:07,692] {logging_mixin.py:104} INFO - [2021-08-16 01:34:07,692] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:34:08,135] {logging_mixin.py:104} INFO - [2021-08-16 01:34:08,133] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 01:34:08,137] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:34:08,148] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.459 seconds
[2021-08-16 01:34:38,296] {scheduler_job.py:181} INFO - Started process (PID=85600) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:34:38,297] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 01:34:38,297] {logging_mixin.py:104} INFO - [2021-08-16 01:34:38,297] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:34:38,729] {logging_mixin.py:104} INFO - [2021-08-16 01:34:38,728] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 01:34:38,732] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:34:38,744] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.450 seconds
[2021-08-16 01:35:08,892] {scheduler_job.py:181} INFO - Started process (PID=85627) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:35:08,893] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 01:35:08,894] {logging_mixin.py:104} INFO - [2021-08-16 01:35:08,894] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:35:09,340] {logging_mixin.py:104} INFO - [2021-08-16 01:35:09,338] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 01:35:09,343] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:35:09,354] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.463 seconds
[2021-08-16 01:35:39,501] {scheduler_job.py:181} INFO - Started process (PID=85666) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:35:39,502] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 01:35:39,503] {logging_mixin.py:104} INFO - [2021-08-16 01:35:39,503] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:35:39,944] {logging_mixin.py:104} INFO - [2021-08-16 01:35:39,942] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 01:35:39,946] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:35:39,957] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.458 seconds
[2021-08-16 01:36:10,115] {scheduler_job.py:181} INFO - Started process (PID=85705) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:36:10,116] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 01:36:10,117] {logging_mixin.py:104} INFO - [2021-08-16 01:36:10,117] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:36:10,656] {logging_mixin.py:104} INFO - [2021-08-16 01:36:10,655] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 01:36:10,659] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:36:10,670] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.557 seconds
[2021-08-16 01:36:40,820] {scheduler_job.py:181} INFO - Started process (PID=85748) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:36:40,821] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 01:36:40,822] {logging_mixin.py:104} INFO - [2021-08-16 01:36:40,822] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:36:41,271] {logging_mixin.py:104} INFO - [2021-08-16 01:36:41,270] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 01:36:41,274] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:36:41,286] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.468 seconds
[2021-08-16 01:37:11,439] {scheduler_job.py:181} INFO - Started process (PID=85775) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:37:11,441] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 01:37:11,442] {logging_mixin.py:104} INFO - [2021-08-16 01:37:11,442] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:37:11,874] {logging_mixin.py:104} INFO - [2021-08-16 01:37:11,873] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 01:37:11,876] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:37:11,887] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.449 seconds
[2021-08-16 01:37:42,043] {scheduler_job.py:181} INFO - Started process (PID=85813) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:37:42,044] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 01:37:42,045] {logging_mixin.py:104} INFO - [2021-08-16 01:37:42,045] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:37:42,481] {logging_mixin.py:104} INFO - [2021-08-16 01:37:42,479] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 01:37:42,483] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:37:42,495] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.453 seconds
[2021-08-16 01:38:12,646] {scheduler_job.py:181} INFO - Started process (PID=85854) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:38:12,647] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 01:38:12,647] {logging_mixin.py:104} INFO - [2021-08-16 01:38:12,647] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:38:13,092] {logging_mixin.py:104} INFO - [2021-08-16 01:38:13,091] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 01:38:13,094] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:38:13,105] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.462 seconds
[2021-08-16 01:38:43,252] {scheduler_job.py:181} INFO - Started process (PID=85893) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:38:43,253] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 01:38:43,254] {logging_mixin.py:104} INFO - [2021-08-16 01:38:43,254] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:38:43,679] {logging_mixin.py:104} INFO - [2021-08-16 01:38:43,677] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 01:38:43,681] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:38:43,692] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.442 seconds
[2021-08-16 01:39:13,871] {scheduler_job.py:181} INFO - Started process (PID=85931) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:39:13,872] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 01:39:13,873] {logging_mixin.py:104} INFO - [2021-08-16 01:39:13,873] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:39:14,312] {logging_mixin.py:104} INFO - [2021-08-16 01:39:14,310] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 01:39:14,314] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:39:14,327] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.458 seconds
[2021-08-16 01:39:44,485] {scheduler_job.py:181} INFO - Started process (PID=85960) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:39:44,487] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 01:39:44,487] {logging_mixin.py:104} INFO - [2021-08-16 01:39:44,487] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:39:44,933] {logging_mixin.py:104} INFO - [2021-08-16 01:39:44,931] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 01:39:44,935] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:39:44,946] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.462 seconds
[2021-08-16 01:40:15,092] {scheduler_job.py:181} INFO - Started process (PID=85999) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:40:15,093] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 01:40:15,094] {logging_mixin.py:104} INFO - [2021-08-16 01:40:15,094] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:40:15,549] {logging_mixin.py:104} INFO - [2021-08-16 01:40:15,547] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 01:40:15,552] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:40:15,562] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.472 seconds
[2021-08-16 01:40:45,711] {scheduler_job.py:181} INFO - Started process (PID=86036) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:40:45,712] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 01:40:45,713] {logging_mixin.py:104} INFO - [2021-08-16 01:40:45,713] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:40:46,152] {logging_mixin.py:104} INFO - [2021-08-16 01:40:46,150] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 01:40:46,154] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:40:46,166] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.457 seconds
[2021-08-16 01:41:16,323] {scheduler_job.py:181} INFO - Started process (PID=86077) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:41:16,323] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 01:41:16,324] {logging_mixin.py:104} INFO - [2021-08-16 01:41:16,324] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:41:16,746] {logging_mixin.py:104} INFO - [2021-08-16 01:41:16,744] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 01:41:16,748] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:41:16,759] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.439 seconds
[2021-08-16 01:41:46,916] {scheduler_job.py:181} INFO - Started process (PID=86105) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:41:46,917] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 01:41:46,918] {logging_mixin.py:104} INFO - [2021-08-16 01:41:46,918] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:41:47,348] {logging_mixin.py:104} INFO - [2021-08-16 01:41:47,347] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 01:41:47,351] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:41:47,362] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.448 seconds
[2021-08-16 01:42:17,509] {scheduler_job.py:181} INFO - Started process (PID=86145) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:42:17,510] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 01:42:17,510] {logging_mixin.py:104} INFO - [2021-08-16 01:42:17,510] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:42:17,966] {logging_mixin.py:104} INFO - [2021-08-16 01:42:17,964] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 01:42:17,969] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:42:17,979] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.472 seconds
[2021-08-16 01:42:48,127] {scheduler_job.py:181} INFO - Started process (PID=86184) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:42:48,128] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 01:42:48,128] {logging_mixin.py:104} INFO - [2021-08-16 01:42:48,128] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:42:48,561] {logging_mixin.py:104} INFO - [2021-08-16 01:42:48,559] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 01:42:48,563] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:42:48,574] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.449 seconds
[2021-08-16 01:43:18,721] {scheduler_job.py:181} INFO - Started process (PID=86222) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:43:18,723] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 01:43:18,723] {logging_mixin.py:104} INFO - [2021-08-16 01:43:18,723] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:43:19,155] {logging_mixin.py:104} INFO - [2021-08-16 01:43:19,153] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 01:43:19,157] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:43:19,169] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.449 seconds
[2021-08-16 01:43:49,319] {scheduler_job.py:181} INFO - Started process (PID=86251) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:43:49,320] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 01:43:49,321] {logging_mixin.py:104} INFO - [2021-08-16 01:43:49,321] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:43:49,761] {logging_mixin.py:104} INFO - [2021-08-16 01:43:49,759] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 01:43:49,763] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:43:49,774] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.457 seconds
[2021-08-16 01:44:19,966] {scheduler_job.py:181} INFO - Started process (PID=86290) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:44:19,968] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 01:44:19,968] {logging_mixin.py:104} INFO - [2021-08-16 01:44:19,968] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:44:20,405] {logging_mixin.py:104} INFO - [2021-08-16 01:44:20,403] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 01:44:20,407] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:44:20,419] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.454 seconds
[2021-08-16 01:44:50,578] {scheduler_job.py:181} INFO - Started process (PID=86330) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:44:50,579] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 01:44:50,580] {logging_mixin.py:104} INFO - [2021-08-16 01:44:50,580] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:44:50,997] {logging_mixin.py:104} INFO - [2021-08-16 01:44:50,996] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 01:44:51,000] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:44:51,013] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.436 seconds
[2021-08-16 01:45:21,162] {scheduler_job.py:181} INFO - Started process (PID=86367) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:45:21,163] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 01:45:21,164] {logging_mixin.py:104} INFO - [2021-08-16 01:45:21,163] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:45:21,582] {logging_mixin.py:104} INFO - [2021-08-16 01:45:21,580] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 01:45:21,585] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:45:21,596] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.435 seconds
[2021-08-16 01:45:51,748] {scheduler_job.py:181} INFO - Started process (PID=86396) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:45:51,749] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 01:45:51,751] {logging_mixin.py:104} INFO - [2021-08-16 01:45:51,751] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:45:52,179] {logging_mixin.py:104} INFO - [2021-08-16 01:45:52,177] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 01:45:52,182] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:45:52,202] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.455 seconds
[2021-08-16 01:46:22,350] {scheduler_job.py:181} INFO - Started process (PID=86437) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:46:22,352] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 01:46:22,352] {logging_mixin.py:104} INFO - [2021-08-16 01:46:22,352] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:46:22,800] {logging_mixin.py:104} INFO - [2021-08-16 01:46:22,798] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 01:46:22,802] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:46:22,813] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.464 seconds
[2021-08-16 01:46:52,959] {scheduler_job.py:181} INFO - Started process (PID=86478) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:46:52,960] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 01:46:52,961] {logging_mixin.py:104} INFO - [2021-08-16 01:46:52,961] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:46:53,377] {logging_mixin.py:104} INFO - [2021-08-16 01:46:53,375] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 01:46:53,379] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:46:53,391] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.433 seconds
[2021-08-16 01:47:23,536] {scheduler_job.py:181} INFO - Started process (PID=86518) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:47:23,537] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 01:47:23,538] {logging_mixin.py:104} INFO - [2021-08-16 01:47:23,538] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:47:23,948] {logging_mixin.py:104} INFO - [2021-08-16 01:47:23,946] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 01:47:23,951] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:47:23,969] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.435 seconds
[2021-08-16 01:47:54,115] {scheduler_job.py:181} INFO - Started process (PID=86556) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:47:54,116] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 01:47:54,116] {logging_mixin.py:104} INFO - [2021-08-16 01:47:54,116] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:47:54,576] {logging_mixin.py:104} INFO - [2021-08-16 01:47:54,575] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 01:47:54,579] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:47:54,588] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.476 seconds
[2021-08-16 01:48:24,747] {scheduler_job.py:181} INFO - Started process (PID=86586) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:48:24,748] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 01:48:24,749] {logging_mixin.py:104} INFO - [2021-08-16 01:48:24,749] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:48:25,216] {logging_mixin.py:104} INFO - [2021-08-16 01:48:25,214] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 01:48:25,218] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:48:25,229] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.483 seconds
[2021-08-16 01:48:55,398] {scheduler_job.py:181} INFO - Started process (PID=86625) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:48:55,399] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 01:48:55,400] {logging_mixin.py:104} INFO - [2021-08-16 01:48:55,400] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:48:55,826] {logging_mixin.py:104} INFO - [2021-08-16 01:48:55,824] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 01:48:55,828] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:48:55,841] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.444 seconds
[2021-08-16 01:49:25,985] {scheduler_job.py:181} INFO - Started process (PID=86662) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:49:25,986] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 01:49:25,987] {logging_mixin.py:104} INFO - [2021-08-16 01:49:25,987] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:49:26,416] {logging_mixin.py:104} INFO - [2021-08-16 01:49:26,414] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 01:49:26,418] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:49:26,437] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.453 seconds
[2021-08-16 01:49:56,583] {scheduler_job.py:181} INFO - Started process (PID=86702) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:49:56,584] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 01:49:56,584] {logging_mixin.py:104} INFO - [2021-08-16 01:49:56,584] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:49:57,019] {logging_mixin.py:104} INFO - [2021-08-16 01:49:57,018] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 01:49:57,022] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:49:57,033] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.452 seconds
[2021-08-16 01:50:27,186] {scheduler_job.py:181} INFO - Started process (PID=86729) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:50:27,187] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 01:50:27,187] {logging_mixin.py:104} INFO - [2021-08-16 01:50:27,187] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:50:27,658] {logging_mixin.py:104} INFO - [2021-08-16 01:50:27,656] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 01:50:27,661] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:50:27,671] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.487 seconds
[2021-08-16 01:50:57,839] {scheduler_job.py:181} INFO - Started process (PID=86769) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:50:57,840] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 01:50:57,841] {logging_mixin.py:104} INFO - [2021-08-16 01:50:57,840] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:50:58,285] {logging_mixin.py:104} INFO - [2021-08-16 01:50:58,283] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 01:50:58,287] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:50:58,298] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.461 seconds
[2021-08-16 01:51:28,444] {scheduler_job.py:181} INFO - Started process (PID=86808) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:51:28,445] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 01:51:28,446] {logging_mixin.py:104} INFO - [2021-08-16 01:51:28,446] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:51:28,881] {logging_mixin.py:104} INFO - [2021-08-16 01:51:28,879] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 01:51:28,884] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:51:28,896] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.454 seconds
[2021-08-16 01:51:59,052] {scheduler_job.py:181} INFO - Started process (PID=86846) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:51:59,053] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 01:51:59,054] {logging_mixin.py:104} INFO - [2021-08-16 01:51:59,054] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:51:59,487] {logging_mixin.py:104} INFO - [2021-08-16 01:51:59,485] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 01:51:59,490] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:51:59,508] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.458 seconds
[2021-08-16 01:52:29,656] {scheduler_job.py:181} INFO - Started process (PID=86873) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:52:29,657] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 01:52:29,658] {logging_mixin.py:104} INFO - [2021-08-16 01:52:29,658] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:52:30,102] {logging_mixin.py:104} INFO - [2021-08-16 01:52:30,100] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 01:52:30,104] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:52:30,123] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.468 seconds
[2021-08-16 01:53:00,280] {scheduler_job.py:181} INFO - Started process (PID=86916) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:53:00,281] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 01:53:00,282] {logging_mixin.py:104} INFO - [2021-08-16 01:53:00,281] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:53:00,703] {logging_mixin.py:104} INFO - [2021-08-16 01:53:00,701] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 01:53:00,706] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:53:00,719] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.440 seconds
[2021-08-16 01:53:30,879] {scheduler_job.py:181} INFO - Started process (PID=86953) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:53:30,880] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 01:53:30,881] {logging_mixin.py:104} INFO - [2021-08-16 01:53:30,881] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:53:31,294] {logging_mixin.py:104} INFO - [2021-08-16 01:53:31,290] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 01:53:31,297] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:53:31,326] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.449 seconds
[2021-08-16 01:54:01,602] {scheduler_job.py:181} INFO - Started process (PID=86991) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:54:01,603] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 01:54:01,604] {logging_mixin.py:104} INFO - [2021-08-16 01:54:01,604] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:54:02,040] {logging_mixin.py:104} INFO - [2021-08-16 01:54:02,039] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 01:54:02,043] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:54:02,054] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.454 seconds
[2021-08-16 01:54:32,199] {scheduler_job.py:181} INFO - Started process (PID=87025) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:54:32,200] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 01:54:32,201] {logging_mixin.py:104} INFO - [2021-08-16 01:54:32,201] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:54:32,676] {logging_mixin.py:104} INFO - [2021-08-16 01:54:32,674] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 01:54:32,678] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:54:32,690] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.494 seconds
[2021-08-16 01:55:02,838] {scheduler_job.py:181} INFO - Started process (PID=87054) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:55:02,839] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 01:55:02,839] {logging_mixin.py:104} INFO - [2021-08-16 01:55:02,839] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:55:03,264] {logging_mixin.py:104} INFO - [2021-08-16 01:55:03,214] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 01:55:03,266] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:55:03,277] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.441 seconds
[2021-08-16 01:55:33,434] {scheduler_job.py:181} INFO - Started process (PID=87092) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:55:33,435] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 01:55:33,436] {logging_mixin.py:104} INFO - [2021-08-16 01:55:33,436] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:55:33,832] {logging_mixin.py:104} INFO - [2021-08-16 01:55:33,830] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 01:55:33,834] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:55:33,846] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.414 seconds
[2021-08-16 01:56:03,993] {scheduler_job.py:181} INFO - Started process (PID=87135) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:56:03,994] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 01:56:03,995] {logging_mixin.py:104} INFO - [2021-08-16 01:56:03,995] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:56:04,444] {logging_mixin.py:104} INFO - [2021-08-16 01:56:04,442] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 01:56:04,446] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:56:04,458] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.467 seconds
[2021-08-16 01:56:34,609] {scheduler_job.py:181} INFO - Started process (PID=87173) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:56:34,610] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 01:56:34,611] {logging_mixin.py:104} INFO - [2021-08-16 01:56:34,611] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:56:35,038] {logging_mixin.py:104} INFO - [2021-08-16 01:56:35,036] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 01:56:35,041] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:56:35,052] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.446 seconds
[2021-08-16 01:57:05,203] {scheduler_job.py:181} INFO - Started process (PID=87201) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:57:05,204] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 01:57:05,205] {logging_mixin.py:104} INFO - [2021-08-16 01:57:05,205] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:57:05,633] {logging_mixin.py:104} INFO - [2021-08-16 01:57:05,631] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 01:57:05,636] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:57:05,647] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.446 seconds
[2021-08-16 01:57:35,795] {scheduler_job.py:181} INFO - Started process (PID=87239) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:57:35,796] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 01:57:35,796] {logging_mixin.py:104} INFO - [2021-08-16 01:57:35,796] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:57:36,234] {logging_mixin.py:104} INFO - [2021-08-16 01:57:36,232] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 01:57:36,236] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:57:36,247] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.454 seconds
[2021-08-16 01:58:06,396] {scheduler_job.py:181} INFO - Started process (PID=87277) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:58:06,397] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 01:58:06,397] {logging_mixin.py:104} INFO - [2021-08-16 01:58:06,397] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:58:06,824] {logging_mixin.py:104} INFO - [2021-08-16 01:58:06,823] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 01:58:06,827] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:58:06,845] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.451 seconds
[2021-08-16 01:58:37,002] {scheduler_job.py:181} INFO - Started process (PID=87316) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:58:37,003] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 01:58:37,004] {logging_mixin.py:104} INFO - [2021-08-16 01:58:37,004] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:58:37,433] {logging_mixin.py:104} INFO - [2021-08-16 01:58:37,432] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 01:58:37,436] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:58:37,448] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.448 seconds
[2021-08-16 01:59:07,619] {scheduler_job.py:181} INFO - Started process (PID=87344) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:59:07,620] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 01:59:07,621] {logging_mixin.py:104} INFO - [2021-08-16 01:59:07,621] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:59:08,058] {logging_mixin.py:104} INFO - [2021-08-16 01:59:08,056] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 01:59:08,060] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:59:08,071] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.454 seconds
[2021-08-16 01:59:38,218] {scheduler_job.py:181} INFO - Started process (PID=87381) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:59:38,219] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 01:59:38,220] {logging_mixin.py:104} INFO - [2021-08-16 01:59:38,220] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:59:38,656] {logging_mixin.py:104} INFO - [2021-08-16 01:59:38,654] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 01:59:38,658] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 01:59:38,669] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.452 seconds
[2021-08-16 02:00:08,816] {scheduler_job.py:181} INFO - Started process (PID=87422) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:00:08,817] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 02:00:08,818] {logging_mixin.py:104} INFO - [2021-08-16 02:00:08,817] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:00:09,259] {logging_mixin.py:104} INFO - [2021-08-16 02:00:09,257] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 02:00:09,261] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:00:09,273] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.459 seconds
[2021-08-16 02:00:39,415] {scheduler_job.py:181} INFO - Started process (PID=87462) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:00:39,416] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 02:00:39,417] {logging_mixin.py:104} INFO - [2021-08-16 02:00:39,417] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:00:39,849] {logging_mixin.py:104} INFO - [2021-08-16 02:00:39,848] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 02:00:39,852] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:00:39,869] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.456 seconds
[2021-08-16 02:01:10,020] {scheduler_job.py:181} INFO - Started process (PID=87498) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:01:10,021] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 02:01:10,021] {logging_mixin.py:104} INFO - [2021-08-16 02:01:10,021] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:01:10,469] {logging_mixin.py:104} INFO - [2021-08-16 02:01:10,468] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 02:01:10,471] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:01:10,482] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.465 seconds
[2021-08-16 02:01:40,640] {scheduler_job.py:181} INFO - Started process (PID=87529) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:01:40,642] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 02:01:40,642] {logging_mixin.py:104} INFO - [2021-08-16 02:01:40,642] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:01:41,071] {logging_mixin.py:104} INFO - [2021-08-16 02:01:41,070] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 02:01:41,074] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:01:41,085] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.446 seconds
[2021-08-16 02:02:11,232] {scheduler_job.py:181} INFO - Started process (PID=87565) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:02:11,233] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 02:02:11,234] {logging_mixin.py:104} INFO - [2021-08-16 02:02:11,234] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:02:11,674] {logging_mixin.py:104} INFO - [2021-08-16 02:02:11,672] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 02:02:11,677] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:02:11,688] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.458 seconds
[2021-08-16 02:02:41,835] {scheduler_job.py:181} INFO - Started process (PID=87602) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:02:41,836] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 02:02:41,837] {logging_mixin.py:104} INFO - [2021-08-16 02:02:41,837] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:02:42,263] {logging_mixin.py:104} INFO - [2021-08-16 02:02:42,262] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 02:02:42,266] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:02:42,276] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.443 seconds
[2021-08-16 02:03:12,422] {scheduler_job.py:181} INFO - Started process (PID=87639) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:03:12,423] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 02:03:12,423] {logging_mixin.py:104} INFO - [2021-08-16 02:03:12,423] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:03:12,884] {logging_mixin.py:104} INFO - [2021-08-16 02:03:12,882] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 02:03:12,887] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:03:12,898] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.478 seconds
[2021-08-16 02:03:43,052] {scheduler_job.py:181} INFO - Started process (PID=87669) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:03:43,053] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 02:03:43,054] {logging_mixin.py:104} INFO - [2021-08-16 02:03:43,054] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:03:43,480] {logging_mixin.py:104} INFO - [2021-08-16 02:03:43,478] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 02:03:43,482] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:03:43,493] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.443 seconds
[2021-08-16 02:04:13,639] {scheduler_job.py:181} INFO - Started process (PID=87707) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:04:13,640] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 02:04:13,641] {logging_mixin.py:104} INFO - [2021-08-16 02:04:13,641] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:04:14,059] {logging_mixin.py:104} INFO - [2021-08-16 02:04:14,057] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 02:04:14,061] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:04:14,076] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.438 seconds
[2021-08-16 02:04:44,248] {scheduler_job.py:181} INFO - Started process (PID=87748) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:04:44,249] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 02:04:44,250] {logging_mixin.py:104} INFO - [2021-08-16 02:04:44,250] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:04:44,685] {logging_mixin.py:104} INFO - [2021-08-16 02:04:44,684] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 02:04:44,688] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:04:44,698] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.452 seconds
[2021-08-16 02:05:14,848] {scheduler_job.py:181} INFO - Started process (PID=87788) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:05:14,849] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 02:05:14,849] {logging_mixin.py:104} INFO - [2021-08-16 02:05:14,849] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:05:15,319] {logging_mixin.py:104} INFO - [2021-08-16 02:05:15,317] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 02:05:15,322] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:05:15,334] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.488 seconds
[2021-08-16 02:05:45,485] {scheduler_job.py:181} INFO - Started process (PID=87815) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:05:45,486] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 02:05:45,487] {logging_mixin.py:104} INFO - [2021-08-16 02:05:45,487] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:05:45,933] {logging_mixin.py:104} INFO - [2021-08-16 02:05:45,932] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 02:05:45,936] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:05:45,948] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.465 seconds
[2021-08-16 02:06:16,108] {scheduler_job.py:181} INFO - Started process (PID=87854) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:06:16,109] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 02:06:16,110] {logging_mixin.py:104} INFO - [2021-08-16 02:06:16,110] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:06:16,567] {logging_mixin.py:104} INFO - [2021-08-16 02:06:16,566] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 02:06:16,570] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:06:16,584] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.477 seconds
[2021-08-16 02:06:46,742] {scheduler_job.py:181} INFO - Started process (PID=87893) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:06:46,743] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 02:06:46,743] {logging_mixin.py:104} INFO - [2021-08-16 02:06:46,743] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:06:47,174] {logging_mixin.py:104} INFO - [2021-08-16 02:06:47,173] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 02:06:47,177] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:06:47,187] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.447 seconds
[2021-08-16 02:07:17,343] {scheduler_job.py:181} INFO - Started process (PID=87934) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:07:17,344] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 02:07:17,345] {logging_mixin.py:104} INFO - [2021-08-16 02:07:17,345] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:07:17,820] {logging_mixin.py:104} INFO - [2021-08-16 02:07:17,819] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 02:07:17,823] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:07:17,834] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.493 seconds
[2021-08-16 02:07:47,985] {scheduler_job.py:181} INFO - Started process (PID=87964) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:07:47,987] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 02:07:47,987] {logging_mixin.py:104} INFO - [2021-08-16 02:07:47,987] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:07:48,431] {logging_mixin.py:104} INFO - [2021-08-16 02:07:48,430] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 02:07:48,433] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:07:48,443] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.460 seconds
[2021-08-16 02:08:18,617] {scheduler_job.py:181} INFO - Started process (PID=88004) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:08:18,618] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 02:08:18,619] {logging_mixin.py:104} INFO - [2021-08-16 02:08:18,619] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:08:19,069] {logging_mixin.py:104} INFO - [2021-08-16 02:08:19,067] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 02:08:19,071] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:08:19,083] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.467 seconds
[2021-08-16 02:08:49,228] {scheduler_job.py:181} INFO - Started process (PID=88042) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:08:49,229] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 02:08:49,230] {logging_mixin.py:104} INFO - [2021-08-16 02:08:49,230] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:08:49,643] {logging_mixin.py:104} INFO - [2021-08-16 02:08:49,642] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 02:08:49,646] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:08:49,664] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.438 seconds
[2021-08-16 02:09:19,845] {scheduler_job.py:181} INFO - Started process (PID=88082) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:09:19,846] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 02:09:19,847] {logging_mixin.py:104} INFO - [2021-08-16 02:09:19,847] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:09:20,270] {logging_mixin.py:104} INFO - [2021-08-16 02:09:20,268] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 02:09:20,272] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:09:20,284] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.440 seconds
[2021-08-16 02:09:50,436] {scheduler_job.py:181} INFO - Started process (PID=88121) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:09:50,438] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 02:09:50,438] {logging_mixin.py:104} INFO - [2021-08-16 02:09:50,438] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:09:50,940] {logging_mixin.py:104} INFO - [2021-08-16 02:09:50,939] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 02:09:50,943] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:09:50,954] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.519 seconds
[2021-08-16 02:10:21,104] {scheduler_job.py:181} INFO - Started process (PID=88151) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:10:21,105] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 02:10:21,106] {logging_mixin.py:104} INFO - [2021-08-16 02:10:21,106] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:10:21,543] {logging_mixin.py:104} INFO - [2021-08-16 02:10:21,542] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 02:10:21,546] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:10:21,557] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.454 seconds
[2021-08-16 02:10:51,708] {scheduler_job.py:181} INFO - Started process (PID=88192) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:10:51,709] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 02:10:51,710] {logging_mixin.py:104} INFO - [2021-08-16 02:10:51,710] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:10:52,131] {logging_mixin.py:104} INFO - [2021-08-16 02:10:52,129] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 02:10:52,134] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:10:52,144] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.438 seconds
[2021-08-16 02:11:22,295] {scheduler_job.py:181} INFO - Started process (PID=88229) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:11:22,297] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 02:11:22,297] {logging_mixin.py:104} INFO - [2021-08-16 02:11:22,297] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:11:22,741] {logging_mixin.py:104} INFO - [2021-08-16 02:11:22,739] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 02:11:22,744] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:11:22,755] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.461 seconds
[2021-08-16 02:11:52,899] {scheduler_job.py:181} INFO - Started process (PID=88268) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:11:52,900] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 02:11:52,901] {logging_mixin.py:104} INFO - [2021-08-16 02:11:52,900] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:11:53,340] {logging_mixin.py:104} INFO - [2021-08-16 02:11:53,338] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 02:11:53,343] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:11:53,360] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.463 seconds
[2021-08-16 02:12:23,514] {scheduler_job.py:181} INFO - Started process (PID=88295) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:12:23,515] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 02:12:23,516] {logging_mixin.py:104} INFO - [2021-08-16 02:12:23,516] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:12:23,937] {logging_mixin.py:104} INFO - [2021-08-16 02:12:23,936] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 02:12:23,940] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:12:23,952] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.439 seconds
[2021-08-16 02:12:54,102] {scheduler_job.py:181} INFO - Started process (PID=88336) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:12:54,103] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 02:12:54,104] {logging_mixin.py:104} INFO - [2021-08-16 02:12:54,104] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:12:54,533] {logging_mixin.py:104} INFO - [2021-08-16 02:12:54,531] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 02:12:54,535] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:12:54,554] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.453 seconds
[2021-08-16 02:13:24,703] {scheduler_job.py:181} INFO - Started process (PID=88377) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:13:24,704] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 02:13:24,704] {logging_mixin.py:104} INFO - [2021-08-16 02:13:24,704] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:13:25,129] {logging_mixin.py:104} INFO - [2021-08-16 02:13:25,128] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 02:13:25,132] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:13:25,143] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.442 seconds
[2021-08-16 02:13:55,320] {scheduler_job.py:181} INFO - Started process (PID=88417) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:13:55,321] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 02:13:55,322] {logging_mixin.py:104} INFO - [2021-08-16 02:13:55,322] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:13:55,791] {logging_mixin.py:104} INFO - [2021-08-16 02:13:55,790] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 02:13:55,794] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:13:55,806] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.488 seconds
[2021-08-16 02:14:25,954] {scheduler_job.py:181} INFO - Started process (PID=88446) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:14:25,955] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 02:14:25,955] {logging_mixin.py:104} INFO - [2021-08-16 02:14:25,955] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:14:26,384] {logging_mixin.py:104} INFO - [2021-08-16 02:14:26,383] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 02:14:26,387] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:14:26,398] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.446 seconds
[2021-08-16 02:14:56,547] {scheduler_job.py:181} INFO - Started process (PID=88487) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:14:56,548] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 02:14:56,548] {logging_mixin.py:104} INFO - [2021-08-16 02:14:56,548] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:14:56,990] {logging_mixin.py:104} INFO - [2021-08-16 02:14:56,988] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 02:14:56,992] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:14:57,003] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.458 seconds
[2021-08-16 02:15:27,150] {scheduler_job.py:181} INFO - Started process (PID=88524) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:15:27,151] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 02:15:27,152] {logging_mixin.py:104} INFO - [2021-08-16 02:15:27,152] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:15:27,571] {logging_mixin.py:104} INFO - [2021-08-16 02:15:27,569] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 02:15:27,574] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:15:27,585] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.437 seconds
[2021-08-16 02:15:57,743] {scheduler_job.py:181} INFO - Started process (PID=88563) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:15:57,744] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 02:15:57,744] {logging_mixin.py:104} INFO - [2021-08-16 02:15:57,744] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:15:58,175] {logging_mixin.py:104} INFO - [2021-08-16 02:15:58,174] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 02:15:58,179] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:15:58,190] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.449 seconds
[2021-08-16 02:16:28,337] {scheduler_job.py:181} INFO - Started process (PID=88604) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:16:28,339] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 02:16:28,339] {logging_mixin.py:104} INFO - [2021-08-16 02:16:28,339] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:16:28,790] {logging_mixin.py:104} INFO - [2021-08-16 02:16:28,789] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 02:16:28,793] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:16:28,803] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.468 seconds
[2021-08-16 02:16:58,957] {scheduler_job.py:181} INFO - Started process (PID=88632) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:16:58,957] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 02:16:58,958] {logging_mixin.py:104} INFO - [2021-08-16 02:16:58,958] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:16:59,389] {logging_mixin.py:104} INFO - [2021-08-16 02:16:59,383] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 02:16:59,392] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:16:59,406] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.451 seconds
[2021-08-16 02:17:29,562] {scheduler_job.py:181} INFO - Started process (PID=88670) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:17:29,563] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 02:17:29,563] {logging_mixin.py:104} INFO - [2021-08-16 02:17:29,563] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:17:29,990] {logging_mixin.py:104} INFO - [2021-08-16 02:17:29,989] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 02:17:29,993] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:17:30,004] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.444 seconds
[2021-08-16 02:18:00,154] {scheduler_job.py:181} INFO - Started process (PID=88709) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:18:00,155] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 02:18:00,156] {logging_mixin.py:104} INFO - [2021-08-16 02:18:00,156] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:18:00,582] {logging_mixin.py:104} INFO - [2021-08-16 02:18:00,580] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 02:18:00,584] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:18:00,595] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.443 seconds
[2021-08-16 02:18:30,743] {scheduler_job.py:181} INFO - Started process (PID=88746) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:18:30,744] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 02:18:30,745] {logging_mixin.py:104} INFO - [2021-08-16 02:18:30,745] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:18:31,198] {logging_mixin.py:104} INFO - [2021-08-16 02:18:31,197] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 02:18:31,201] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:18:31,212] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.472 seconds
[2021-08-16 02:19:01,390] {scheduler_job.py:181} INFO - Started process (PID=88773) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:19:01,392] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 02:19:01,393] {logging_mixin.py:104} INFO - [2021-08-16 02:19:01,393] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:19:01,827] {logging_mixin.py:104} INFO - [2021-08-16 02:19:01,826] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 02:19:01,830] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:19:01,841] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.453 seconds
[2021-08-16 02:19:31,994] {scheduler_job.py:181} INFO - Started process (PID=88813) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:19:31,995] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 02:19:31,996] {logging_mixin.py:104} INFO - [2021-08-16 02:19:31,996] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:19:32,697] {logging_mixin.py:104} INFO - [2021-08-16 02:19:32,696] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 02:19:32,700] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:19:32,711] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.719 seconds
[2021-08-16 02:20:03,118] {scheduler_job.py:181} INFO - Started process (PID=88850) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:20:03,120] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 02:20:03,120] {logging_mixin.py:104} INFO - [2021-08-16 02:20:03,120] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:20:03,553] {logging_mixin.py:104} INFO - [2021-08-16 02:20:03,551] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 02:20:03,555] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:20:03,566] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.449 seconds
[2021-08-16 02:20:34,325] {scheduler_job.py:181} INFO - Started process (PID=88888) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:20:34,326] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 02:20:34,327] {logging_mixin.py:104} INFO - [2021-08-16 02:20:34,327] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:20:34,767] {logging_mixin.py:104} INFO - [2021-08-16 02:20:34,765] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 02:20:34,769] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:20:34,782] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.458 seconds
[2021-08-16 02:21:04,942] {scheduler_job.py:181} INFO - Started process (PID=88918) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:21:04,944] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 02:21:04,944] {logging_mixin.py:104} INFO - [2021-08-16 02:21:04,944] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:21:05,427] {logging_mixin.py:104} INFO - [2021-08-16 02:21:05,425] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 02:21:05,429] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:21:05,439] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.500 seconds
[2021-08-16 02:21:35,596] {scheduler_job.py:181} INFO - Started process (PID=88956) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:21:35,598] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 02:21:35,598] {logging_mixin.py:104} INFO - [2021-08-16 02:21:35,598] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:21:36,047] {logging_mixin.py:104} INFO - [2021-08-16 02:21:36,046] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 02:21:36,051] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:21:36,064] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.469 seconds
[2021-08-16 02:22:06,230] {scheduler_job.py:181} INFO - Started process (PID=88994) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:22:06,231] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 02:22:06,232] {logging_mixin.py:104} INFO - [2021-08-16 02:22:06,232] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:22:06,658] {logging_mixin.py:104} INFO - [2021-08-16 02:22:06,656] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 02:22:06,660] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:22:06,672] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.443 seconds
[2021-08-16 02:22:36,823] {scheduler_job.py:181} INFO - Started process (PID=89032) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:22:36,824] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 02:22:36,824] {logging_mixin.py:104} INFO - [2021-08-16 02:22:36,824] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:22:37,276] {logging_mixin.py:104} INFO - [2021-08-16 02:22:37,274] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 02:22:37,278] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:22:37,289] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.468 seconds
[2021-08-16 02:23:07,442] {scheduler_job.py:181} INFO - Started process (PID=89073) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:23:07,443] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 02:23:07,444] {logging_mixin.py:104} INFO - [2021-08-16 02:23:07,444] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:23:07,906] {logging_mixin.py:104} INFO - [2021-08-16 02:23:07,904] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 02:23:07,909] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:23:07,921] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.481 seconds
[2021-08-16 02:23:38,100] {scheduler_job.py:181} INFO - Started process (PID=89103) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:23:38,101] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 02:23:38,102] {logging_mixin.py:104} INFO - [2021-08-16 02:23:38,102] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:23:38,545] {logging_mixin.py:104} INFO - [2021-08-16 02:23:38,543] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 02:23:38,547] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:23:38,558] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.460 seconds
[2021-08-16 02:24:08,740] {scheduler_job.py:181} INFO - Started process (PID=89140) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:24:08,741] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 02:24:08,742] {logging_mixin.py:104} INFO - [2021-08-16 02:24:08,742] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:24:09,182] {logging_mixin.py:104} INFO - [2021-08-16 02:24:09,181] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 02:24:09,186] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:24:09,196] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.457 seconds
[2021-08-16 02:24:39,356] {scheduler_job.py:181} INFO - Started process (PID=89179) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:24:39,357] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 02:24:39,358] {logging_mixin.py:104} INFO - [2021-08-16 02:24:39,358] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:24:39,803] {logging_mixin.py:104} INFO - [2021-08-16 02:24:39,801] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 02:24:39,807] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:24:39,819] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.465 seconds
[2021-08-16 02:25:09,988] {scheduler_job.py:181} INFO - Started process (PID=89222) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:25:09,989] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 02:25:09,990] {logging_mixin.py:104} INFO - [2021-08-16 02:25:09,990] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:25:10,416] {logging_mixin.py:104} INFO - [2021-08-16 02:25:10,415] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 02:25:10,419] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:25:10,430] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.444 seconds
[2021-08-16 02:25:40,576] {scheduler_job.py:181} INFO - Started process (PID=89253) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:25:40,577] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 02:25:40,577] {logging_mixin.py:104} INFO - [2021-08-16 02:25:40,577] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:25:40,999] {logging_mixin.py:104} INFO - [2021-08-16 02:25:40,997] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 02:25:41,002] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:25:41,013] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.439 seconds
[2021-08-16 02:26:11,166] {scheduler_job.py:181} INFO - Started process (PID=89293) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:26:11,167] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 02:26:11,168] {logging_mixin.py:104} INFO - [2021-08-16 02:26:11,168] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:26:11,602] {logging_mixin.py:104} INFO - [2021-08-16 02:26:11,601] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 02:26:11,605] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:26:11,616] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.452 seconds
[2021-08-16 02:26:41,772] {scheduler_job.py:181} INFO - Started process (PID=89330) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:26:41,773] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 02:26:41,774] {logging_mixin.py:104} INFO - [2021-08-16 02:26:41,774] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:26:42,197] {logging_mixin.py:104} INFO - [2021-08-16 02:26:42,195] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 02:26:42,200] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:26:42,212] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.442 seconds
[2021-08-16 02:27:12,359] {scheduler_job.py:181} INFO - Started process (PID=89372) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:27:12,360] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 02:27:12,361] {logging_mixin.py:104} INFO - [2021-08-16 02:27:12,360] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:27:12,791] {logging_mixin.py:104} INFO - [2021-08-16 02:27:12,789] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 02:27:12,793] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:27:12,804] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.447 seconds
[2021-08-16 02:27:42,951] {scheduler_job.py:181} INFO - Started process (PID=89399) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:27:42,952] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 02:27:42,953] {logging_mixin.py:104} INFO - [2021-08-16 02:27:42,953] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:27:43,888] {logging_mixin.py:104} INFO - [2021-08-16 02:27:43,886] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 02:27:43,891] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:27:43,906] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.957 seconds
[2021-08-16 02:28:14,143] {scheduler_job.py:181} INFO - Started process (PID=89437) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:28:14,144] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 02:28:14,145] {logging_mixin.py:104} INFO - [2021-08-16 02:28:14,145] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:28:14,864] {logging_mixin.py:104} INFO - [2021-08-16 02:28:14,862] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 02:28:14,866] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:28:14,879] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.738 seconds
[2021-08-16 02:28:45,353] {scheduler_job.py:181} INFO - Started process (PID=89473) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:28:45,354] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 02:28:45,354] {logging_mixin.py:104} INFO - [2021-08-16 02:28:45,354] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:28:45,778] {logging_mixin.py:104} INFO - [2021-08-16 02:28:45,776] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 02:28:45,780] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:28:45,799] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.447 seconds
[2021-08-16 02:29:16,612] {scheduler_job.py:181} INFO - Started process (PID=89513) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:29:16,613] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 02:29:16,613] {logging_mixin.py:104} INFO - [2021-08-16 02:29:16,613] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:29:17,042] {logging_mixin.py:104} INFO - [2021-08-16 02:29:17,040] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 02:29:17,044] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:29:17,055] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.445 seconds
[2021-08-16 02:29:47,915] {scheduler_job.py:181} INFO - Started process (PID=89550) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:29:47,916] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 02:29:47,916] {logging_mixin.py:104} INFO - [2021-08-16 02:29:47,916] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:29:48,364] {logging_mixin.py:104} INFO - [2021-08-16 02:29:48,362] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 02:29:48,366] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:29:48,378] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.465 seconds
[2021-08-16 02:30:18,456] {scheduler_job.py:181} INFO - Started process (PID=89579) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:30:18,457] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 02:30:18,458] {logging_mixin.py:104} INFO - [2021-08-16 02:30:18,458] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:30:18,910] {logging_mixin.py:104} INFO - [2021-08-16 02:30:18,909] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 02:30:18,913] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:30:18,924] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.470 seconds
[2021-08-16 02:30:49,650] {scheduler_job.py:181} INFO - Started process (PID=89619) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:30:49,651] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 02:30:49,651] {logging_mixin.py:104} INFO - [2021-08-16 02:30:49,651] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:30:50,093] {logging_mixin.py:104} INFO - [2021-08-16 02:30:50,091] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 02:30:50,096] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:30:50,107] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.459 seconds
[2021-08-16 02:31:20,140] {scheduler_job.py:181} INFO - Started process (PID=89658) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:31:20,142] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 02:31:20,143] {logging_mixin.py:104} INFO - [2021-08-16 02:31:20,143] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:31:20,572] {logging_mixin.py:104} INFO - [2021-08-16 02:31:20,570] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 02:31:20,574] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:31:20,586] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.447 seconds
[2021-08-16 02:31:51,387] {scheduler_job.py:181} INFO - Started process (PID=89697) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:31:51,388] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 02:31:51,389] {logging_mixin.py:104} INFO - [2021-08-16 02:31:51,389] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:31:51,843] {logging_mixin.py:104} INFO - [2021-08-16 02:31:51,841] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 02:31:51,845] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:31:51,857] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.472 seconds
[2021-08-16 02:32:22,727] {scheduler_job.py:181} INFO - Started process (PID=89736) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:32:22,728] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 02:32:22,729] {logging_mixin.py:104} INFO - [2021-08-16 02:32:22,729] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:32:23,171] {logging_mixin.py:104} INFO - [2021-08-16 02:32:23,169] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 02:32:23,173] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:32:23,184] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.459 seconds
[2021-08-16 02:32:53,995] {scheduler_job.py:181} INFO - Started process (PID=89771) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:32:53,996] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 02:32:53,996] {logging_mixin.py:104} INFO - [2021-08-16 02:32:53,996] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:32:54,443] {logging_mixin.py:104} INFO - [2021-08-16 02:32:54,441] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 02:32:54,445] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:32:54,455] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.462 seconds
[2021-08-16 02:33:25,335] {scheduler_job.py:181} INFO - Started process (PID=89802) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:33:25,336] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 02:33:25,337] {logging_mixin.py:104} INFO - [2021-08-16 02:33:25,337] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:33:25,768] {logging_mixin.py:104} INFO - [2021-08-16 02:33:25,766] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 02:33:25,770] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:33:25,781] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.448 seconds
[2021-08-16 02:33:55,942] {scheduler_job.py:181} INFO - Started process (PID=89842) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:33:55,943] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 02:33:55,944] {logging_mixin.py:104} INFO - [2021-08-16 02:33:55,944] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:33:56,442] {logging_mixin.py:104} INFO - [2021-08-16 02:33:56,441] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 02:33:56,444] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:33:56,459] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.519 seconds
[2021-08-16 02:34:26,581] {scheduler_job.py:181} INFO - Started process (PID=89883) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:34:26,582] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 02:34:26,585] {logging_mixin.py:104} INFO - [2021-08-16 02:34:26,585] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:34:27,057] {logging_mixin.py:104} INFO - [2021-08-16 02:34:27,056] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 02:34:27,060] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:34:27,072] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.493 seconds
[2021-08-16 02:34:57,234] {scheduler_job.py:181} INFO - Started process (PID=89923) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:34:57,235] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 02:34:57,236] {logging_mixin.py:104} INFO - [2021-08-16 02:34:57,236] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:34:57,745] {logging_mixin.py:104} INFO - [2021-08-16 02:34:57,743] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 02:34:57,748] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:34:57,759] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.527 seconds
[2021-08-16 02:35:27,920] {scheduler_job.py:181} INFO - Started process (PID=89952) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:35:27,921] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 02:35:27,922] {logging_mixin.py:104} INFO - [2021-08-16 02:35:27,922] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:35:28,382] {logging_mixin.py:104} INFO - [2021-08-16 02:35:28,380] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 02:35:28,384] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:35:28,396] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.478 seconds
[2021-08-16 02:35:59,237] {scheduler_job.py:181} INFO - Started process (PID=89992) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:35:59,238] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 02:35:59,239] {logging_mixin.py:104} INFO - [2021-08-16 02:35:59,238] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:35:59,686] {logging_mixin.py:104} INFO - [2021-08-16 02:35:59,683] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 02:35:59,689] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:35:59,700] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.465 seconds
[2021-08-16 02:36:29,774] {scheduler_job.py:181} INFO - Started process (PID=90033) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:36:29,775] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 02:36:29,776] {logging_mixin.py:104} INFO - [2021-08-16 02:36:29,776] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:36:30,200] {logging_mixin.py:104} INFO - [2021-08-16 02:36:30,199] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 02:36:30,203] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:36:30,214] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.442 seconds
[2021-08-16 02:37:01,085] {scheduler_job.py:181} INFO - Started process (PID=90070) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:37:01,086] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 02:37:01,087] {logging_mixin.py:104} INFO - [2021-08-16 02:37:01,087] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:37:01,553] {logging_mixin.py:104} INFO - [2021-08-16 02:37:01,551] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 02:37:01,555] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:37:01,567] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.483 seconds
[2021-08-16 02:37:32,428] {scheduler_job.py:181} INFO - Started process (PID=90110) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:37:32,429] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 02:37:32,429] {logging_mixin.py:104} INFO - [2021-08-16 02:37:32,429] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:37:32,856] {logging_mixin.py:104} INFO - [2021-08-16 02:37:32,855] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 02:37:32,859] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:37:32,871] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.445 seconds
[2021-08-16 02:38:02,922] {scheduler_job.py:181} INFO - Started process (PID=90136) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:38:02,923] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 02:38:02,924] {logging_mixin.py:104} INFO - [2021-08-16 02:38:02,924] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:38:03,376] {logging_mixin.py:104} INFO - [2021-08-16 02:38:03,375] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 02:38:03,379] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:38:03,389] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.469 seconds
[2021-08-16 02:38:34,103] {scheduler_job.py:181} INFO - Started process (PID=90176) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:38:34,104] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 02:38:34,105] {logging_mixin.py:104} INFO - [2021-08-16 02:38:34,105] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:38:34,541] {logging_mixin.py:104} INFO - [2021-08-16 02:38:34,539] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 02:38:34,543] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:38:34,555] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.454 seconds
[2021-08-16 02:39:04,718] {scheduler_job.py:181} INFO - Started process (PID=90213) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:39:04,719] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 02:39:04,720] {logging_mixin.py:104} INFO - [2021-08-16 02:39:04,720] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:39:05,159] {logging_mixin.py:104} INFO - [2021-08-16 02:39:05,157] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 02:39:05,161] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:39:05,174] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.457 seconds
[2021-08-16 02:39:35,903] {scheduler_job.py:181} INFO - Started process (PID=90253) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:39:35,904] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 02:39:35,905] {logging_mixin.py:104} INFO - [2021-08-16 02:39:35,905] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:39:36,366] {logging_mixin.py:104} INFO - [2021-08-16 02:39:36,365] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 02:39:36,369] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:39:36,380] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.479 seconds
[2021-08-16 02:40:07,257] {scheduler_job.py:181} INFO - Started process (PID=90292) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:40:07,258] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 02:40:07,259] {logging_mixin.py:104} INFO - [2021-08-16 02:40:07,259] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:40:07,676] {logging_mixin.py:104} INFO - [2021-08-16 02:40:07,674] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 02:40:07,679] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:40:07,689] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.434 seconds
[2021-08-16 02:40:37,796] {scheduler_job.py:181} INFO - Started process (PID=90317) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:40:37,797] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 02:40:37,798] {logging_mixin.py:104} INFO - [2021-08-16 02:40:37,798] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:40:38,229] {logging_mixin.py:104} INFO - [2021-08-16 02:40:38,228] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 02:40:38,232] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:40:38,243] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.449 seconds
[2021-08-16 02:41:09,036] {scheduler_job.py:181} INFO - Started process (PID=90353) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:41:09,037] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 02:41:09,038] {logging_mixin.py:104} INFO - [2021-08-16 02:41:09,038] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:41:09,469] {logging_mixin.py:104} INFO - [2021-08-16 02:41:09,467] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 02:41:09,471] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:41:09,482] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.448 seconds
[2021-08-16 02:41:39,545] {scheduler_job.py:181} INFO - Started process (PID=90394) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:41:39,547] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 02:41:39,548] {logging_mixin.py:104} INFO - [2021-08-16 02:41:39,548] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:41:39,997] {logging_mixin.py:104} INFO - [2021-08-16 02:41:39,996] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 02:41:40,000] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:41:40,012] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.468 seconds
[2021-08-16 02:42:10,734] {scheduler_job.py:181} INFO - Started process (PID=90432) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:42:10,735] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 02:42:10,735] {logging_mixin.py:104} INFO - [2021-08-16 02:42:10,735] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:42:11,172] {logging_mixin.py:104} INFO - [2021-08-16 02:42:11,171] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 02:42:11,175] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:42:11,187] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.455 seconds
[2021-08-16 02:42:41,210] {scheduler_job.py:181} INFO - Started process (PID=90476) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:42:41,212] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 02:42:41,212] {logging_mixin.py:104} INFO - [2021-08-16 02:42:41,212] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:42:41,667] {logging_mixin.py:104} INFO - [2021-08-16 02:42:41,664] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 02:42:41,670] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:42:41,682] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.473 seconds
[2021-08-16 02:43:12,417] {scheduler_job.py:181} INFO - Started process (PID=90501) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:43:12,418] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 02:43:12,419] {logging_mixin.py:104} INFO - [2021-08-16 02:43:12,418] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:43:12,853] {logging_mixin.py:104} INFO - [2021-08-16 02:43:12,851] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 02:43:12,856] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:43:12,867] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.452 seconds
[2021-08-16 02:43:42,918] {scheduler_job.py:181} INFO - Started process (PID=90539) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:43:42,919] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 02:43:42,919] {logging_mixin.py:104} INFO - [2021-08-16 02:43:42,919] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:43:43,359] {logging_mixin.py:104} INFO - [2021-08-16 02:43:43,358] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 02:43:43,362] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:43:43,374] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.458 seconds
[2021-08-16 02:44:14,116] {scheduler_job.py:181} INFO - Started process (PID=90583) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:44:14,118] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 02:44:14,119] {logging_mixin.py:104} INFO - [2021-08-16 02:44:14,119] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:44:14,559] {logging_mixin.py:104} INFO - [2021-08-16 02:44:14,557] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 02:44:14,562] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:44:14,575] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.461 seconds
[2021-08-16 02:44:44,679] {scheduler_job.py:181} INFO - Started process (PID=90621) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:44:44,680] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 02:44:44,681] {logging_mixin.py:104} INFO - [2021-08-16 02:44:44,681] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:44:45,118] {logging_mixin.py:104} INFO - [2021-08-16 02:44:45,116] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 02:44:45,121] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:44:45,131] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.453 seconds
[2021-08-16 02:45:16,003] {scheduler_job.py:181} INFO - Started process (PID=90651) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:45:16,004] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 02:45:16,005] {logging_mixin.py:104} INFO - [2021-08-16 02:45:16,005] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:45:16,486] {logging_mixin.py:104} INFO - [2021-08-16 02:45:16,485] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 02:45:16,489] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:45:16,501] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.499 seconds
[2021-08-16 02:45:46,534] {scheduler_job.py:181} INFO - Started process (PID=90689) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:45:46,535] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 02:45:46,536] {logging_mixin.py:104} INFO - [2021-08-16 02:45:46,535] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:45:46,958] {logging_mixin.py:104} INFO - [2021-08-16 02:45:46,957] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 02:45:46,961] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:45:46,974] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.442 seconds
[2021-08-16 02:46:17,732] {scheduler_job.py:181} INFO - Started process (PID=90731) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:46:17,733] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 02:46:17,734] {logging_mixin.py:104} INFO - [2021-08-16 02:46:17,733] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:46:18,668] {logging_mixin.py:104} INFO - [2021-08-16 02:46:18,667] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 02:46:18,671] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:46:18,682] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.952 seconds
[2021-08-16 02:46:48,943] {scheduler_job.py:181} INFO - Started process (PID=90769) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:46:48,944] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 02:46:48,945] {logging_mixin.py:104} INFO - [2021-08-16 02:46:48,945] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:46:49,423] {logging_mixin.py:104} INFO - [2021-08-16 02:46:49,421] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 02:46:49,426] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:46:49,437] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.495 seconds
[2021-08-16 02:47:19,489] {scheduler_job.py:181} INFO - Started process (PID=90808) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:47:19,490] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 02:47:19,491] {logging_mixin.py:104} INFO - [2021-08-16 02:47:19,491] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:47:19,924] {logging_mixin.py:104} INFO - [2021-08-16 02:47:19,922] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 02:47:19,927] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:47:19,938] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.451 seconds
[2021-08-16 02:47:50,687] {scheduler_job.py:181} INFO - Started process (PID=90836) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:47:50,688] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 02:47:50,689] {logging_mixin.py:104} INFO - [2021-08-16 02:47:50,689] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:47:51,120] {logging_mixin.py:104} INFO - [2021-08-16 02:47:51,118] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 02:47:51,122] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:47:51,139] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.453 seconds
[2021-08-16 02:48:22,038] {scheduler_job.py:181} INFO - Started process (PID=90874) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:48:22,039] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 02:48:22,039] {logging_mixin.py:104} INFO - [2021-08-16 02:48:22,039] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:48:22,478] {logging_mixin.py:104} INFO - [2021-08-16 02:48:22,476] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 02:48:22,480] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:48:22,492] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.456 seconds
[2021-08-16 02:48:53,370] {scheduler_job.py:181} INFO - Started process (PID=90915) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:48:53,371] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 02:48:53,371] {logging_mixin.py:104} INFO - [2021-08-16 02:48:53,371] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:48:53,805] {logging_mixin.py:104} INFO - [2021-08-16 02:48:53,803] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 02:48:53,808] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:48:53,820] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.452 seconds
[2021-08-16 02:49:23,896] {scheduler_job.py:181} INFO - Started process (PID=90953) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:49:23,897] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 02:49:23,897] {logging_mixin.py:104} INFO - [2021-08-16 02:49:23,897] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:49:24,329] {logging_mixin.py:104} INFO - [2021-08-16 02:49:24,327] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 02:49:24,331] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:49:24,344] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.450 seconds
[2021-08-16 02:49:55,138] {scheduler_job.py:181} INFO - Started process (PID=90995) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:49:55,139] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 02:49:55,139] {logging_mixin.py:104} INFO - [2021-08-16 02:49:55,139] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:49:55,575] {logging_mixin.py:104} INFO - [2021-08-16 02:49:55,573] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 02:49:55,577] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:49:55,588] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.452 seconds
[2021-08-16 02:50:26,437] {scheduler_job.py:181} INFO - Started process (PID=91035) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:50:26,438] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 02:50:26,439] {logging_mixin.py:104} INFO - [2021-08-16 02:50:26,438] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:50:27,410] {logging_mixin.py:104} INFO - [2021-08-16 02:50:27,408] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 02:50:27,412] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:50:27,430] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.996 seconds
[2021-08-16 02:50:57,692] {scheduler_job.py:181} INFO - Started process (PID=91066) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:50:57,693] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 02:50:57,693] {logging_mixin.py:104} INFO - [2021-08-16 02:50:57,693] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:50:58,115] {logging_mixin.py:104} INFO - [2021-08-16 02:50:58,113] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 02:50:58,118] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:50:58,128] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.439 seconds
[2021-08-16 02:51:28,243] {scheduler_job.py:181} INFO - Started process (PID=91106) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:51:28,245] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 02:51:28,245] {logging_mixin.py:104} INFO - [2021-08-16 02:51:28,245] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:51:28,712] {logging_mixin.py:104} INFO - [2021-08-16 02:51:28,710] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 02:51:28,716] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:51:28,735] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.493 seconds
[2021-08-16 02:51:59,442] {scheduler_job.py:181} INFO - Started process (PID=91144) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:51:59,443] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 02:51:59,444] {logging_mixin.py:104} INFO - [2021-08-16 02:51:59,444] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:51:59,887] {logging_mixin.py:104} INFO - [2021-08-16 02:51:59,885] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 02:51:59,890] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:51:59,900] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.460 seconds
[2021-08-16 02:52:30,809] {scheduler_job.py:181} INFO - Started process (PID=91182) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:52:30,810] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 02:52:30,811] {logging_mixin.py:104} INFO - [2021-08-16 02:52:30,811] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:52:31,244] {logging_mixin.py:104} INFO - [2021-08-16 02:52:31,242] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 02:52:31,246] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:52:31,257] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.450 seconds
[2021-08-16 02:53:01,405] {scheduler_job.py:181} INFO - Started process (PID=91210) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:53:01,406] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 02:53:01,406] {logging_mixin.py:104} INFO - [2021-08-16 02:53:01,406] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:53:02,337] {logging_mixin.py:104} INFO - [2021-08-16 02:53:02,336] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 02:53:02,341] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:53:02,359] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.956 seconds
[2021-08-16 02:53:32,543] {scheduler_job.py:181} INFO - Started process (PID=91248) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:53:32,544] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 02:53:32,545] {logging_mixin.py:104} INFO - [2021-08-16 02:53:32,545] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:53:32,975] {logging_mixin.py:104} INFO - [2021-08-16 02:53:32,973] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 02:53:32,977] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:53:32,989] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.448 seconds
[2021-08-16 02:54:03,761] {scheduler_job.py:181} INFO - Started process (PID=91285) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:54:03,762] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 02:54:03,763] {logging_mixin.py:104} INFO - [2021-08-16 02:54:03,763] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:54:04,196] {logging_mixin.py:104} INFO - [2021-08-16 02:54:04,194] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 02:54:04,199] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:54:04,210] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.450 seconds
[2021-08-16 02:54:34,245] {scheduler_job.py:181} INFO - Started process (PID=91326) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:54:34,246] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 02:54:34,246] {logging_mixin.py:104} INFO - [2021-08-16 02:54:34,246] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:54:34,681] {logging_mixin.py:104} INFO - [2021-08-16 02:54:34,679] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 02:54:34,683] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:54:34,696] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.453 seconds
[2021-08-16 02:55:05,515] {scheduler_job.py:181} INFO - Started process (PID=91365) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:55:05,516] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 02:55:05,517] {logging_mixin.py:104} INFO - [2021-08-16 02:55:05,517] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:55:05,958] {logging_mixin.py:104} INFO - [2021-08-16 02:55:05,957] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 02:55:05,961] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:55:05,972] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.458 seconds
[2021-08-16 02:55:36,777] {scheduler_job.py:181} INFO - Started process (PID=91403) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:55:36,778] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 02:55:36,779] {logging_mixin.py:104} INFO - [2021-08-16 02:55:36,779] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:55:37,253] {logging_mixin.py:104} INFO - [2021-08-16 02:55:37,252] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 02:55:37,255] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:55:37,265] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.490 seconds
[2021-08-16 02:56:07,358] {scheduler_job.py:181} INFO - Started process (PID=91433) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:56:07,359] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 02:56:07,359] {logging_mixin.py:104} INFO - [2021-08-16 02:56:07,359] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:56:07,780] {logging_mixin.py:104} INFO - [2021-08-16 02:56:07,778] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 02:56:07,782] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:56:07,793] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.437 seconds
[2021-08-16 02:56:38,540] {scheduler_job.py:181} INFO - Started process (PID=91471) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:56:38,541] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 02:56:38,542] {logging_mixin.py:104} INFO - [2021-08-16 02:56:38,542] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:56:38,976] {logging_mixin.py:104} INFO - [2021-08-16 02:56:38,974] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 02:56:38,978] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:56:38,989] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.451 seconds
[2021-08-16 02:57:09,064] {scheduler_job.py:181} INFO - Started process (PID=91510) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:57:09,065] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 02:57:09,066] {logging_mixin.py:104} INFO - [2021-08-16 02:57:09,065] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:57:09,512] {logging_mixin.py:104} INFO - [2021-08-16 02:57:09,510] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 02:57:09,514] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:57:09,525] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.463 seconds
[2021-08-16 02:57:40,241] {scheduler_job.py:181} INFO - Started process (PID=91548) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:57:40,242] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 02:57:40,243] {logging_mixin.py:104} INFO - [2021-08-16 02:57:40,243] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:57:40,667] {logging_mixin.py:104} INFO - [2021-08-16 02:57:40,666] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 02:57:40,670] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:57:40,680] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.441 seconds
[2021-08-16 02:58:10,758] {scheduler_job.py:181} INFO - Started process (PID=91575) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:58:10,759] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 02:58:10,759] {logging_mixin.py:104} INFO - [2021-08-16 02:58:10,759] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:58:11,197] {logging_mixin.py:104} INFO - [2021-08-16 02:58:11,196] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 02:58:11,200] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:58:11,213] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.457 seconds
[2021-08-16 02:58:41,943] {scheduler_job.py:181} INFO - Started process (PID=91615) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:58:41,944] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 02:58:41,945] {logging_mixin.py:104} INFO - [2021-08-16 02:58:41,945] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:58:42,402] {logging_mixin.py:104} INFO - [2021-08-16 02:58:42,401] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 02:58:42,404] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:58:42,415] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.474 seconds
[2021-08-16 02:59:13,245] {scheduler_job.py:181} INFO - Started process (PID=91655) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:59:13,246] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 02:59:13,247] {logging_mixin.py:104} INFO - [2021-08-16 02:59:13,247] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:59:13,725] {logging_mixin.py:104} INFO - [2021-08-16 02:59:13,724] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 02:59:13,728] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:59:13,738] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.495 seconds
[2021-08-16 02:59:44,553] {scheduler_job.py:181} INFO - Started process (PID=91697) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:59:44,554] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 02:59:44,554] {logging_mixin.py:104} INFO - [2021-08-16 02:59:44,554] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:59:44,994] {logging_mixin.py:104} INFO - [2021-08-16 02:59:44,992] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 02:59:44,996] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 02:59:45,007] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.457 seconds
[2021-08-16 03:00:15,120] {scheduler_job.py:181} INFO - Started process (PID=91736) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:00:15,121] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 03:00:15,122] {logging_mixin.py:104} INFO - [2021-08-16 03:00:15,122] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:00:15,583] {logging_mixin.py:104} INFO - [2021-08-16 03:00:15,581] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 03:00:15,586] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:00:15,596] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.481 seconds
[2021-08-16 03:00:45,755] {scheduler_job.py:181} INFO - Started process (PID=91764) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:00:45,755] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 03:00:45,756] {logging_mixin.py:104} INFO - [2021-08-16 03:00:45,756] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:00:46,194] {logging_mixin.py:104} INFO - [2021-08-16 03:00:46,192] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 03:00:46,197] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:00:46,207] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.455 seconds
[2021-08-16 03:01:16,322] {scheduler_job.py:181} INFO - Started process (PID=91802) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:01:16,323] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 03:01:16,324] {logging_mixin.py:104} INFO - [2021-08-16 03:01:16,324] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:01:16,755] {logging_mixin.py:104} INFO - [2021-08-16 03:01:16,754] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 03:01:16,757] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:01:16,769] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.450 seconds
[2021-08-16 03:01:46,872] {scheduler_job.py:181} INFO - Started process (PID=91840) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:01:46,874] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 03:01:46,874] {logging_mixin.py:104} INFO - [2021-08-16 03:01:46,874] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:01:47,318] {logging_mixin.py:104} INFO - [2021-08-16 03:01:47,316] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 03:01:47,320] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:01:47,332] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.462 seconds
[2021-08-16 03:02:17,438] {scheduler_job.py:181} INFO - Started process (PID=91879) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:02:17,439] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 03:02:17,440] {logging_mixin.py:104} INFO - [2021-08-16 03:02:17,440] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:02:17,886] {logging_mixin.py:104} INFO - [2021-08-16 03:02:17,884] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 03:02:17,888] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:02:17,899] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.463 seconds
[2021-08-16 03:02:48,060] {scheduler_job.py:181} INFO - Started process (PID=91919) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:02:48,061] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 03:02:48,061] {logging_mixin.py:104} INFO - [2021-08-16 03:02:48,061] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:02:48,532] {logging_mixin.py:104} INFO - [2021-08-16 03:02:48,528] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 03:02:48,535] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:02:48,547] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.489 seconds
[2021-08-16 03:03:19,366] {scheduler_job.py:181} INFO - Started process (PID=91947) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:03:19,367] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 03:03:19,368] {logging_mixin.py:104} INFO - [2021-08-16 03:03:19,368] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:03:19,804] {logging_mixin.py:104} INFO - [2021-08-16 03:03:19,802] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 03:03:19,806] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:03:19,817] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.452 seconds
[2021-08-16 03:03:49,974] {scheduler_job.py:181} INFO - Started process (PID=91989) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:03:49,975] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 03:03:49,976] {logging_mixin.py:104} INFO - [2021-08-16 03:03:49,976] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:03:50,408] {logging_mixin.py:104} INFO - [2021-08-16 03:03:50,407] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 03:03:50,411] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:03:50,421] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.449 seconds
[2021-08-16 03:04:20,605] {scheduler_job.py:181} INFO - Started process (PID=92033) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:04:20,606] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 03:04:20,606] {logging_mixin.py:104} INFO - [2021-08-16 03:04:20,606] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:04:21,044] {logging_mixin.py:104} INFO - [2021-08-16 03:04:21,043] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 03:04:21,047] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:04:21,058] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.455 seconds
[2021-08-16 03:04:51,217] {scheduler_job.py:181} INFO - Started process (PID=92073) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:04:51,218] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 03:04:51,219] {logging_mixin.py:104} INFO - [2021-08-16 03:04:51,219] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:04:51,655] {logging_mixin.py:104} INFO - [2021-08-16 03:04:51,653] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 03:04:51,657] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:04:51,668] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.452 seconds
[2021-08-16 03:05:21,826] {scheduler_job.py:181} INFO - Started process (PID=92101) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:05:21,827] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 03:05:21,828] {logging_mixin.py:104} INFO - [2021-08-16 03:05:21,828] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:05:22,264] {logging_mixin.py:104} INFO - [2021-08-16 03:05:22,262] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 03:05:22,267] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:05:22,278] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.454 seconds
[2021-08-16 03:05:52,439] {scheduler_job.py:181} INFO - Started process (PID=92139) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:05:52,440] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 03:05:52,441] {logging_mixin.py:104} INFO - [2021-08-16 03:05:52,441] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:05:52,872] {logging_mixin.py:104} INFO - [2021-08-16 03:05:52,871] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 03:05:52,875] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:05:52,886] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.448 seconds
[2021-08-16 03:06:23,046] {scheduler_job.py:181} INFO - Started process (PID=92180) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:06:23,047] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 03:06:23,047] {logging_mixin.py:104} INFO - [2021-08-16 03:06:23,047] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:06:23,479] {logging_mixin.py:104} INFO - [2021-08-16 03:06:23,477] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 03:06:23,481] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:06:23,492] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.448 seconds
[2021-08-16 03:06:53,660] {scheduler_job.py:181} INFO - Started process (PID=92217) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:06:53,661] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 03:06:53,661] {logging_mixin.py:104} INFO - [2021-08-16 03:06:53,661] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:06:54,116] {logging_mixin.py:104} INFO - [2021-08-16 03:06:54,114] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 03:06:54,119] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:06:54,129] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.471 seconds
[2021-08-16 03:07:24,293] {scheduler_job.py:181} INFO - Started process (PID=92258) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:07:24,294] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 03:07:24,295] {logging_mixin.py:104} INFO - [2021-08-16 03:07:24,295] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:07:24,721] {logging_mixin.py:104} INFO - [2021-08-16 03:07:24,719] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 03:07:24,723] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:07:24,734] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.443 seconds
[2021-08-16 03:07:54,892] {scheduler_job.py:181} INFO - Started process (PID=92289) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:07:54,893] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 03:07:54,894] {logging_mixin.py:104} INFO - [2021-08-16 03:07:54,894] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:07:55,326] {logging_mixin.py:104} INFO - [2021-08-16 03:07:55,324] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 03:07:55,329] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:07:55,340] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.450 seconds
[2021-08-16 03:08:25,509] {scheduler_job.py:181} INFO - Started process (PID=92329) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:08:25,511] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 03:08:25,511] {logging_mixin.py:104} INFO - [2021-08-16 03:08:25,511] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:08:25,937] {logging_mixin.py:104} INFO - [2021-08-16 03:08:25,935] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 03:08:25,939] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:08:25,950] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.442 seconds
[2021-08-16 03:08:56,115] {scheduler_job.py:181} INFO - Started process (PID=92370) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:08:56,116] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 03:08:56,117] {logging_mixin.py:104} INFO - [2021-08-16 03:08:56,117] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:08:56,538] {logging_mixin.py:104} INFO - [2021-08-16 03:08:56,536] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 03:08:56,541] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:08:56,552] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.438 seconds
[2021-08-16 03:09:26,749] {scheduler_job.py:181} INFO - Started process (PID=92408) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:09:26,750] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 03:09:26,751] {logging_mixin.py:104} INFO - [2021-08-16 03:09:26,751] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:09:27,183] {logging_mixin.py:104} INFO - [2021-08-16 03:09:27,181] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 03:09:27,185] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:09:27,196] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.449 seconds
[2021-08-16 03:09:57,354] {scheduler_job.py:181} INFO - Started process (PID=92435) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:09:57,355] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 03:09:57,356] {logging_mixin.py:104} INFO - [2021-08-16 03:09:57,355] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:09:58,328] {logging_mixin.py:104} INFO - [2021-08-16 03:09:58,326] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 03:09:58,330] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:09:58,341] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.989 seconds
[2021-08-16 03:10:28,497] {scheduler_job.py:181} INFO - Started process (PID=92474) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:10:28,498] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 03:10:28,499] {logging_mixin.py:104} INFO - [2021-08-16 03:10:28,499] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:10:29,465] {logging_mixin.py:104} INFO - [2021-08-16 03:10:29,464] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 03:10:29,468] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:10:29,478] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.983 seconds
[2021-08-16 03:10:59,679] {scheduler_job.py:181} INFO - Started process (PID=92515) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:10:59,680] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 03:10:59,681] {logging_mixin.py:104} INFO - [2021-08-16 03:10:59,681] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:11:00,112] {logging_mixin.py:104} INFO - [2021-08-16 03:11:00,111] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 03:11:00,115] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:11:00,133] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.456 seconds
[2021-08-16 03:11:30,290] {scheduler_job.py:181} INFO - Started process (PID=92555) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:11:30,291] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 03:11:30,292] {logging_mixin.py:104} INFO - [2021-08-16 03:11:30,292] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:11:30,724] {logging_mixin.py:104} INFO - [2021-08-16 03:11:30,722] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 03:11:30,726] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:11:30,737] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.449 seconds
[2021-08-16 03:12:00,896] {scheduler_job.py:181} INFO - Started process (PID=92592) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:12:00,897] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 03:12:00,897] {logging_mixin.py:104} INFO - [2021-08-16 03:12:00,897] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:12:01,345] {logging_mixin.py:104} INFO - [2021-08-16 03:12:01,343] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 03:12:01,347] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:12:01,358] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.464 seconds
[2021-08-16 03:12:31,522] {scheduler_job.py:181} INFO - Started process (PID=92619) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:12:31,523] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 03:12:31,524] {logging_mixin.py:104} INFO - [2021-08-16 03:12:31,524] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:12:31,954] {logging_mixin.py:104} INFO - [2021-08-16 03:12:31,952] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 03:12:31,956] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:12:31,967] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.447 seconds
[2021-08-16 03:13:02,131] {scheduler_job.py:181} INFO - Started process (PID=92661) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:13:02,132] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 03:13:02,133] {logging_mixin.py:104} INFO - [2021-08-16 03:13:02,133] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:13:02,594] {logging_mixin.py:104} INFO - [2021-08-16 03:13:02,592] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 03:13:02,596] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:13:02,611] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.481 seconds
[2021-08-16 03:13:32,787] {scheduler_job.py:181} INFO - Started process (PID=92699) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:13:32,788] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 03:13:32,789] {logging_mixin.py:104} INFO - [2021-08-16 03:13:32,789] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:13:33,238] {logging_mixin.py:104} INFO - [2021-08-16 03:13:33,236] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 03:13:33,241] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:13:33,258] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.473 seconds
[2021-08-16 03:14:03,447] {scheduler_job.py:181} INFO - Started process (PID=92738) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:14:03,448] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 03:14:03,448] {logging_mixin.py:104} INFO - [2021-08-16 03:14:03,448] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:14:03,886] {logging_mixin.py:104} INFO - [2021-08-16 03:14:03,884] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 03:14:03,889] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:14:03,908] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.463 seconds
[2021-08-16 03:14:34,083] {scheduler_job.py:181} INFO - Started process (PID=92766) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:14:34,084] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 03:14:34,084] {logging_mixin.py:104} INFO - [2021-08-16 03:14:34,084] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:14:34,528] {logging_mixin.py:104} INFO - [2021-08-16 03:14:34,526] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 03:14:34,531] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:14:34,543] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.463 seconds
[2021-08-16 03:15:04,704] {scheduler_job.py:181} INFO - Started process (PID=92805) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:15:04,705] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 03:15:04,706] {logging_mixin.py:104} INFO - [2021-08-16 03:15:04,706] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:15:05,145] {logging_mixin.py:104} INFO - [2021-08-16 03:15:05,144] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 03:15:05,148] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:15:05,159] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.457 seconds
[2021-08-16 03:15:35,366] {scheduler_job.py:181} INFO - Started process (PID=92843) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:15:35,368] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 03:15:35,368] {logging_mixin.py:104} INFO - [2021-08-16 03:15:35,368] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:15:35,793] {logging_mixin.py:104} INFO - [2021-08-16 03:15:35,792] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 03:15:35,796] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:15:35,809] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.444 seconds
[2021-08-16 03:16:05,978] {scheduler_job.py:181} INFO - Started process (PID=92884) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:16:05,979] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 03:16:05,980] {logging_mixin.py:104} INFO - [2021-08-16 03:16:05,980] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:16:06,478] {logging_mixin.py:104} INFO - [2021-08-16 03:16:06,476] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 03:16:06,481] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:16:06,493] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.516 seconds
[2021-08-16 03:16:36,651] {scheduler_job.py:181} INFO - Started process (PID=92916) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:16:36,653] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 03:16:36,653] {logging_mixin.py:104} INFO - [2021-08-16 03:16:36,653] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:16:37,092] {logging_mixin.py:104} INFO - [2021-08-16 03:16:37,091] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 03:16:37,094] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:16:37,106] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.457 seconds
[2021-08-16 03:17:07,280] {scheduler_job.py:181} INFO - Started process (PID=92956) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:17:07,281] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 03:17:07,282] {logging_mixin.py:104} INFO - [2021-08-16 03:17:07,282] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:17:07,728] {logging_mixin.py:104} INFO - [2021-08-16 03:17:07,726] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 03:17:07,731] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:17:07,742] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.464 seconds
[2021-08-16 03:17:37,904] {scheduler_job.py:181} INFO - Started process (PID=92994) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:17:37,905] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 03:17:37,906] {logging_mixin.py:104} INFO - [2021-08-16 03:17:37,905] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:17:38,342] {logging_mixin.py:104} INFO - [2021-08-16 03:17:38,340] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 03:17:38,344] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:17:38,356] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.453 seconds
[2021-08-16 03:18:08,527] {scheduler_job.py:181} INFO - Started process (PID=93037) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:18:08,529] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 03:18:08,529] {logging_mixin.py:104} INFO - [2021-08-16 03:18:08,529] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:18:09,118] {logging_mixin.py:104} INFO - [2021-08-16 03:18:09,117] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 03:18:09,121] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:18:09,132] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.607 seconds
[2021-08-16 03:18:39,301] {scheduler_job.py:181} INFO - Started process (PID=93076) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:18:39,302] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 03:18:39,302] {logging_mixin.py:104} INFO - [2021-08-16 03:18:39,302] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:18:39,741] {logging_mixin.py:104} INFO - [2021-08-16 03:18:39,740] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 03:18:39,744] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:18:39,756] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.457 seconds
[2021-08-16 03:19:09,947] {scheduler_job.py:181} INFO - Started process (PID=93105) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:19:09,948] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 03:19:09,948] {logging_mixin.py:104} INFO - [2021-08-16 03:19:09,948] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:19:10,380] {logging_mixin.py:104} INFO - [2021-08-16 03:19:10,378] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 03:19:10,382] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:19:10,394] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.449 seconds
[2021-08-16 03:19:40,558] {scheduler_job.py:181} INFO - Started process (PID=93143) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:19:40,559] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 03:19:40,560] {logging_mixin.py:104} INFO - [2021-08-16 03:19:40,560] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:19:41,001] {logging_mixin.py:104} INFO - [2021-08-16 03:19:40,999] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 03:19:41,003] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:19:41,021] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.465 seconds
[2021-08-16 03:20:11,216] {scheduler_job.py:181} INFO - Started process (PID=93183) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:20:11,216] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 03:20:11,217] {logging_mixin.py:104} INFO - [2021-08-16 03:20:11,217] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:20:12,159] {logging_mixin.py:104} INFO - [2021-08-16 03:20:12,157] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 03:20:12,161] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:20:12,173] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.959 seconds
[2021-08-16 03:20:42,407] {scheduler_job.py:181} INFO - Started process (PID=93223) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:20:42,408] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 03:20:42,409] {logging_mixin.py:104} INFO - [2021-08-16 03:20:42,409] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:20:43,343] {logging_mixin.py:104} INFO - [2021-08-16 03:20:43,342] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 03:20:43,346] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:20:43,357] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.951 seconds
[2021-08-16 03:21:13,586] {scheduler_job.py:181} INFO - Started process (PID=93261) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:21:13,587] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 03:21:13,587] {logging_mixin.py:104} INFO - [2021-08-16 03:21:13,587] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:21:14,080] {logging_mixin.py:104} INFO - [2021-08-16 03:21:14,076] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 03:21:14,083] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:21:14,095] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.512 seconds
[2021-08-16 03:21:44,130] {scheduler_job.py:181} INFO - Started process (PID=93292) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:21:44,131] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 03:21:44,133] {logging_mixin.py:104} INFO - [2021-08-16 03:21:44,132] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:21:44,655] {logging_mixin.py:104} INFO - [2021-08-16 03:21:44,654] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 03:21:44,658] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:21:44,669] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.541 seconds
[2021-08-16 03:22:14,845] {scheduler_job.py:181} INFO - Started process (PID=93329) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:22:14,846] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 03:22:14,847] {logging_mixin.py:104} INFO - [2021-08-16 03:22:14,847] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:22:15,818] {logging_mixin.py:104} INFO - [2021-08-16 03:22:15,816] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 03:22:15,821] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:22:15,839] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.996 seconds
[2021-08-16 03:22:46,028] {scheduler_job.py:181} INFO - Started process (PID=93368) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:22:46,029] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 03:22:46,030] {logging_mixin.py:104} INFO - [2021-08-16 03:22:46,029] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:22:46,459] {logging_mixin.py:104} INFO - [2021-08-16 03:22:46,457] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 03:22:46,462] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:22:46,475] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.449 seconds
[2021-08-16 03:23:16,702] {scheduler_job.py:181} INFO - Started process (PID=93409) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:23:16,703] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 03:23:16,704] {logging_mixin.py:104} INFO - [2021-08-16 03:23:16,704] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:23:17,147] {logging_mixin.py:104} INFO - [2021-08-16 03:23:17,143] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 03:23:17,150] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:23:17,163] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.463 seconds
[2021-08-16 03:23:47,866] {scheduler_job.py:181} INFO - Started process (PID=93438) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:23:47,867] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 03:23:47,868] {logging_mixin.py:104} INFO - [2021-08-16 03:23:47,868] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:23:48,290] {logging_mixin.py:104} INFO - [2021-08-16 03:23:48,288] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 03:23:48,292] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:23:48,301] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.436 seconds
[2021-08-16 03:24:18,533] {scheduler_job.py:181} INFO - Started process (PID=93475) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:24:18,534] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 03:24:18,534] {logging_mixin.py:104} INFO - [2021-08-16 03:24:18,534] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:24:18,962] {logging_mixin.py:104} INFO - [2021-08-16 03:24:18,960] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 03:24:18,964] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:24:18,975] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.444 seconds
[2021-08-16 03:24:49,703] {scheduler_job.py:181} INFO - Started process (PID=93514) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:24:49,704] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 03:24:49,704] {logging_mixin.py:104} INFO - [2021-08-16 03:24:49,704] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:24:50,164] {logging_mixin.py:104} INFO - [2021-08-16 03:24:50,163] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 03:24:50,167] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:24:50,178] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.477 seconds
[2021-08-16 03:25:20,312] {scheduler_job.py:181} INFO - Started process (PID=93556) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:25:20,313] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 03:25:20,314] {logging_mixin.py:104} INFO - [2021-08-16 03:25:20,314] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:25:20,745] {logging_mixin.py:104} INFO - [2021-08-16 03:25:20,744] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 03:25:20,748] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:25:20,759] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.449 seconds
[2021-08-16 03:25:51,490] {scheduler_job.py:181} INFO - Started process (PID=93594) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:25:51,491] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 03:25:51,491] {logging_mixin.py:104} INFO - [2021-08-16 03:25:51,491] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:25:51,950] {logging_mixin.py:104} INFO - [2021-08-16 03:25:51,948] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 03:25:51,953] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:25:51,963] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.475 seconds
[2021-08-16 03:26:22,075] {scheduler_job.py:181} INFO - Started process (PID=93626) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:26:22,076] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 03:26:22,077] {logging_mixin.py:104} INFO - [2021-08-16 03:26:22,077] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:26:22,503] {logging_mixin.py:104} INFO - [2021-08-16 03:26:22,501] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 03:26:22,505] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:26:22,516] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.443 seconds
[2021-08-16 03:26:53,242] {scheduler_job.py:181} INFO - Started process (PID=93668) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:26:53,243] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 03:26:53,244] {logging_mixin.py:104} INFO - [2021-08-16 03:26:53,244] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:26:53,699] {logging_mixin.py:104} INFO - [2021-08-16 03:26:53,698] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 03:26:53,702] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:26:53,712] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.472 seconds
[2021-08-16 03:27:23,861] {scheduler_job.py:181} INFO - Started process (PID=93709) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:27:23,862] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 03:27:23,863] {logging_mixin.py:104} INFO - [2021-08-16 03:27:23,863] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:27:24,300] {logging_mixin.py:104} INFO - [2021-08-16 03:27:24,298] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 03:27:24,302] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:27:24,313] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.453 seconds
[2021-08-16 03:27:55,032] {scheduler_job.py:181} INFO - Started process (PID=93747) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:27:55,032] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 03:27:55,033] {logging_mixin.py:104} INFO - [2021-08-16 03:27:55,033] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:27:55,474] {logging_mixin.py:104} INFO - [2021-08-16 03:27:55,472] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 03:27:55,477] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:27:55,488] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.458 seconds
[2021-08-16 03:28:25,634] {scheduler_job.py:181} INFO - Started process (PID=93788) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:28:25,635] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 03:28:25,636] {logging_mixin.py:104} INFO - [2021-08-16 03:28:25,636] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:28:26,106] {logging_mixin.py:104} INFO - [2021-08-16 03:28:26,103] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 03:28:26,109] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:28:26,123] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.490 seconds
[2021-08-16 03:28:56,853] {scheduler_job.py:181} INFO - Started process (PID=93815) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:28:56,854] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 03:28:56,855] {logging_mixin.py:104} INFO - [2021-08-16 03:28:56,854] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:28:57,297] {logging_mixin.py:104} INFO - [2021-08-16 03:28:57,295] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 03:28:57,300] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:28:57,311] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.460 seconds
[2021-08-16 03:29:27,447] {scheduler_job.py:181} INFO - Started process (PID=93858) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:29:27,448] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 03:29:27,449] {logging_mixin.py:104} INFO - [2021-08-16 03:29:27,449] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:29:27,874] {logging_mixin.py:104} INFO - [2021-08-16 03:29:27,873] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 03:29:27,877] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:29:27,888] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.442 seconds
[2021-08-16 03:29:58,625] {scheduler_job.py:181} INFO - Started process (PID=93895) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:29:58,626] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 03:29:58,627] {logging_mixin.py:104} INFO - [2021-08-16 03:29:58,627] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:29:59,064] {logging_mixin.py:104} INFO - [2021-08-16 03:29:59,062] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 03:29:59,066] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:29:59,077] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.454 seconds
[2021-08-16 03:30:29,220] {scheduler_job.py:181} INFO - Started process (PID=93931) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:30:29,221] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 03:30:29,222] {logging_mixin.py:104} INFO - [2021-08-16 03:30:29,222] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:30:29,673] {logging_mixin.py:104} INFO - [2021-08-16 03:30:29,672] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 03:30:29,676] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:30:29,687] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.469 seconds
[2021-08-16 03:31:00,388] {scheduler_job.py:181} INFO - Started process (PID=93971) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:31:00,389] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 03:31:00,390] {logging_mixin.py:104} INFO - [2021-08-16 03:31:00,390] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:31:00,869] {logging_mixin.py:104} INFO - [2021-08-16 03:31:00,867] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 03:31:00,871] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:31:00,882] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.496 seconds
[2021-08-16 03:31:31,011] {scheduler_job.py:181} INFO - Started process (PID=93998) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:31:31,012] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 03:31:31,013] {logging_mixin.py:104} INFO - [2021-08-16 03:31:31,013] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:31:31,447] {logging_mixin.py:104} INFO - [2021-08-16 03:31:31,446] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 03:31:31,450] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:31:31,460] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.451 seconds
[2021-08-16 03:32:02,180] {scheduler_job.py:181} INFO - Started process (PID=94035) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:32:02,181] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 03:32:02,182] {logging_mixin.py:104} INFO - [2021-08-16 03:32:02,182] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:32:02,605] {logging_mixin.py:104} INFO - [2021-08-16 03:32:02,603] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 03:32:02,607] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:32:02,619] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.441 seconds
[2021-08-16 03:32:32,772] {scheduler_job.py:181} INFO - Started process (PID=94072) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:32:32,773] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 03:32:32,774] {logging_mixin.py:104} INFO - [2021-08-16 03:32:32,774] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:32:33,192] {logging_mixin.py:104} INFO - [2021-08-16 03:32:33,190] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 03:32:33,195] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:32:33,206] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.435 seconds
[2021-08-16 03:33:04,003] {scheduler_job.py:181} INFO - Started process (PID=94109) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:33:04,004] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 03:33:04,005] {logging_mixin.py:104} INFO - [2021-08-16 03:33:04,005] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:33:04,455] {logging_mixin.py:104} INFO - [2021-08-16 03:33:04,454] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 03:33:04,458] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:33:04,470] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.468 seconds
[2021-08-16 03:33:34,550] {scheduler_job.py:181} INFO - Started process (PID=94138) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:33:34,551] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 03:33:34,552] {logging_mixin.py:104} INFO - [2021-08-16 03:33:34,552] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:33:35,008] {logging_mixin.py:104} INFO - [2021-08-16 03:33:35,007] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 03:33:35,010] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:33:35,021] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.473 seconds
[2021-08-16 03:34:05,742] {scheduler_job.py:181} INFO - Started process (PID=94178) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:34:05,743] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 03:34:05,744] {logging_mixin.py:104} INFO - [2021-08-16 03:34:05,744] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:34:06,180] {logging_mixin.py:104} INFO - [2021-08-16 03:34:06,178] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 03:34:06,182] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:34:06,193] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.453 seconds
[2021-08-16 03:34:36,301] {scheduler_job.py:181} INFO - Started process (PID=94215) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:34:36,303] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 03:34:36,304] {logging_mixin.py:104} INFO - [2021-08-16 03:34:36,303] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:34:36,777] {logging_mixin.py:104} INFO - [2021-08-16 03:34:36,775] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 03:34:36,779] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:34:36,793] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.494 seconds
[2021-08-16 03:35:07,474] {scheduler_job.py:181} INFO - Started process (PID=94254) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:35:07,475] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 03:35:07,476] {logging_mixin.py:104} INFO - [2021-08-16 03:35:07,476] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:35:07,899] {logging_mixin.py:104} INFO - [2021-08-16 03:35:07,897] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 03:35:07,902] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:35:07,914] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.441 seconds
[2021-08-16 03:35:38,075] {scheduler_job.py:181} INFO - Started process (PID=94290) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:35:38,076] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 03:35:38,077] {logging_mixin.py:104} INFO - [2021-08-16 03:35:38,077] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:35:38,506] {logging_mixin.py:104} INFO - [2021-08-16 03:35:38,504] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 03:35:38,508] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:35:38,520] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.447 seconds
[2021-08-16 03:36:09,257] {scheduler_job.py:181} INFO - Started process (PID=94316) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:36:09,258] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 03:36:09,258] {logging_mixin.py:104} INFO - [2021-08-16 03:36:09,258] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:36:10,179] {logging_mixin.py:104} INFO - [2021-08-16 03:36:10,177] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 03:36:10,182] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:36:10,199] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.944 seconds
[2021-08-16 03:36:40,392] {scheduler_job.py:181} INFO - Started process (PID=94356) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:36:40,394] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 03:36:40,394] {logging_mixin.py:104} INFO - [2021-08-16 03:36:40,394] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:36:40,826] {logging_mixin.py:104} INFO - [2021-08-16 03:36:40,824] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 03:36:40,829] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:36:40,839] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.449 seconds
[2021-08-16 03:37:10,961] {scheduler_job.py:181} INFO - Started process (PID=94394) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:37:10,962] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 03:37:10,962] {logging_mixin.py:104} INFO - [2021-08-16 03:37:10,962] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:37:11,389] {logging_mixin.py:104} INFO - [2021-08-16 03:37:11,387] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 03:37:11,391] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:37:11,403] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.444 seconds
[2021-08-16 03:37:42,133] {scheduler_job.py:181} INFO - Started process (PID=94434) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:37:42,134] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 03:37:42,134] {logging_mixin.py:104} INFO - [2021-08-16 03:37:42,134] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:37:42,591] {logging_mixin.py:104} INFO - [2021-08-16 03:37:42,590] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 03:37:42,594] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:37:42,606] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.475 seconds
[2021-08-16 03:38:12,739] {scheduler_job.py:181} INFO - Started process (PID=94472) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:38:12,741] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 03:38:12,742] {logging_mixin.py:104} INFO - [2021-08-16 03:38:12,741] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:38:13,172] {logging_mixin.py:104} INFO - [2021-08-16 03:38:13,171] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 03:38:13,175] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:38:13,187] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.450 seconds
[2021-08-16 03:38:43,912] {scheduler_job.py:181} INFO - Started process (PID=94503) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:38:43,913] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 03:38:43,914] {logging_mixin.py:104} INFO - [2021-08-16 03:38:43,914] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:38:44,339] {logging_mixin.py:104} INFO - [2021-08-16 03:38:44,337] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 03:38:44,341] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:38:44,353] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.442 seconds
[2021-08-16 03:39:14,504] {scheduler_job.py:181} INFO - Started process (PID=94544) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:39:14,505] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 03:39:14,506] {logging_mixin.py:104} INFO - [2021-08-16 03:39:14,505] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:39:14,928] {logging_mixin.py:104} INFO - [2021-08-16 03:39:14,926] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 03:39:14,930] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:39:14,942] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.440 seconds
[2021-08-16 03:39:45,681] {scheduler_job.py:181} INFO - Started process (PID=94580) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:39:45,682] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 03:39:45,683] {logging_mixin.py:104} INFO - [2021-08-16 03:39:45,683] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:39:46,123] {logging_mixin.py:104} INFO - [2021-08-16 03:39:46,121] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 03:39:46,125] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:39:46,136] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.456 seconds
[2021-08-16 03:40:16,166] {scheduler_job.py:181} INFO - Started process (PID=94618) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:40:16,167] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 03:40:16,168] {logging_mixin.py:104} INFO - [2021-08-16 03:40:16,168] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:40:16,597] {logging_mixin.py:104} INFO - [2021-08-16 03:40:16,595] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 03:40:16,599] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:40:16,611] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.447 seconds
[2021-08-16 03:40:46,830] {scheduler_job.py:181} INFO - Started process (PID=94646) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:40:46,831] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 03:40:46,832] {logging_mixin.py:104} INFO - [2021-08-16 03:40:46,832] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:40:47,267] {logging_mixin.py:104} INFO - [2021-08-16 03:40:47,266] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 03:40:47,270] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:40:47,281] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.453 seconds
[2021-08-16 03:41:18,072] {scheduler_job.py:181} INFO - Started process (PID=94688) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:41:18,073] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 03:41:18,074] {logging_mixin.py:104} INFO - [2021-08-16 03:41:18,074] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:41:18,500] {logging_mixin.py:104} INFO - [2021-08-16 03:41:18,498] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 03:41:18,502] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:41:18,516] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.446 seconds
[2021-08-16 03:41:48,623] {scheduler_job.py:181} INFO - Started process (PID=94726) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:41:48,624] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 03:41:48,625] {logging_mixin.py:104} INFO - [2021-08-16 03:41:48,625] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:41:49,049] {logging_mixin.py:104} INFO - [2021-08-16 03:41:49,047] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 03:41:49,054] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:41:49,084] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.463 seconds
[2021-08-16 03:42:19,793] {scheduler_job.py:181} INFO - Started process (PID=94764) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:42:19,794] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 03:42:19,795] {logging_mixin.py:104} INFO - [2021-08-16 03:42:19,795] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:42:20,263] {logging_mixin.py:104} INFO - [2021-08-16 03:42:20,262] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 03:42:20,266] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:42:20,285] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.494 seconds
[2021-08-16 03:42:50,413] {scheduler_job.py:181} INFO - Started process (PID=94802) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:42:50,414] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 03:42:50,415] {logging_mixin.py:104} INFO - [2021-08-16 03:42:50,415] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:42:50,836] {logging_mixin.py:104} INFO - [2021-08-16 03:42:50,834] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 03:42:50,839] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:42:50,851] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.440 seconds
[2021-08-16 03:43:21,581] {scheduler_job.py:181} INFO - Started process (PID=94828) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:43:21,582] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 03:43:21,582] {logging_mixin.py:104} INFO - [2021-08-16 03:43:21,582] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:43:22,023] {logging_mixin.py:104} INFO - [2021-08-16 03:43:22,022] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 03:43:22,026] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:43:22,039] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.460 seconds
[2021-08-16 03:43:52,204] {scheduler_job.py:181} INFO - Started process (PID=94868) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:43:52,205] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 03:43:52,206] {logging_mixin.py:104} INFO - [2021-08-16 03:43:52,206] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:43:52,666] {logging_mixin.py:104} INFO - [2021-08-16 03:43:52,665] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 03:43:52,669] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:43:52,681] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.480 seconds
[2021-08-16 03:44:23,445] {scheduler_job.py:181} INFO - Started process (PID=94909) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:44:23,446] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 03:44:23,448] {logging_mixin.py:104} INFO - [2021-08-16 03:44:23,447] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:44:24,501] {logging_mixin.py:104} INFO - [2021-08-16 03:44:24,496] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 03:44:24,506] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:44:24,532] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 1.090 seconds
[2021-08-16 03:44:54,784] {scheduler_job.py:181} INFO - Started process (PID=94947) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:44:54,788] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 03:44:54,789] {logging_mixin.py:104} INFO - [2021-08-16 03:44:54,789] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:44:55,229] {logging_mixin.py:104} INFO - [2021-08-16 03:44:55,227] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 03:44:55,232] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:44:55,243] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.465 seconds
[2021-08-16 03:45:26,018] {scheduler_job.py:181} INFO - Started process (PID=94983) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:45:26,019] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 03:45:26,020] {logging_mixin.py:104} INFO - [2021-08-16 03:45:26,020] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:45:26,466] {logging_mixin.py:104} INFO - [2021-08-16 03:45:26,464] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 03:45:26,469] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:45:26,481] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.464 seconds
[2021-08-16 03:45:57,284] {scheduler_job.py:181} INFO - Started process (PID=95025) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:45:57,286] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 03:45:57,288] {logging_mixin.py:104} INFO - [2021-08-16 03:45:57,288] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:45:57,825] {logging_mixin.py:104} INFO - [2021-08-16 03:45:57,823] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 03:45:57,828] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:45:57,840] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.558 seconds
[2021-08-16 03:46:27,939] {scheduler_job.py:181} INFO - Started process (PID=95055) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:46:27,940] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 03:46:27,941] {logging_mixin.py:104} INFO - [2021-08-16 03:46:27,941] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:46:28,370] {logging_mixin.py:104} INFO - [2021-08-16 03:46:28,369] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 03:46:28,373] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:46:28,384] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.447 seconds
[2021-08-16 03:46:58,483] {scheduler_job.py:181} INFO - Started process (PID=95094) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:46:58,485] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 03:46:58,486] {logging_mixin.py:104} INFO - [2021-08-16 03:46:58,485] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:46:58,936] {logging_mixin.py:104} INFO - [2021-08-16 03:46:58,934] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 03:46:58,939] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:46:58,950] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.469 seconds
[2021-08-16 03:47:29,051] {scheduler_job.py:181} INFO - Started process (PID=95134) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:47:29,052] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 03:47:29,053] {logging_mixin.py:104} INFO - [2021-08-16 03:47:29,053] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:47:29,505] {logging_mixin.py:104} INFO - [2021-08-16 03:47:29,504] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 03:47:29,508] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:47:29,520] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.472 seconds
[2021-08-16 03:47:59,617] {scheduler_job.py:181} INFO - Started process (PID=95174) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:47:59,620] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 03:47:59,621] {logging_mixin.py:104} INFO - [2021-08-16 03:47:59,621] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:48:00,108] {logging_mixin.py:104} INFO - [2021-08-16 03:48:00,106] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 03:48:00,110] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:48:00,124] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.508 seconds
[2021-08-16 03:48:30,944] {scheduler_job.py:181} INFO - Started process (PID=95203) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:48:30,948] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 03:48:30,949] {logging_mixin.py:104} INFO - [2021-08-16 03:48:30,948] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:48:31,381] {logging_mixin.py:104} INFO - [2021-08-16 03:48:31,379] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 03:48:31,383] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:48:31,397] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.456 seconds
[2021-08-16 03:49:01,587] {scheduler_job.py:181} INFO - Started process (PID=95242) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:49:01,588] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 03:49:01,589] {logging_mixin.py:104} INFO - [2021-08-16 03:49:01,589] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:49:02,032] {logging_mixin.py:104} INFO - [2021-08-16 03:49:02,030] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 03:49:02,035] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:49:02,045] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.460 seconds
[2021-08-16 03:49:32,203] {scheduler_job.py:181} INFO - Started process (PID=95286) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:49:32,203] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 03:49:32,204] {logging_mixin.py:104} INFO - [2021-08-16 03:49:32,204] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:49:32,644] {logging_mixin.py:104} INFO - [2021-08-16 03:49:32,642] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 03:49:32,646] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:49:32,658] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.457 seconds
[2021-08-16 03:50:02,815] {scheduler_job.py:181} INFO - Started process (PID=95323) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:50:02,816] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 03:50:02,817] {logging_mixin.py:104} INFO - [2021-08-16 03:50:02,817] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:50:03,282] {logging_mixin.py:104} INFO - [2021-08-16 03:50:03,280] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 03:50:03,284] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:50:03,297] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.484 seconds
[2021-08-16 03:50:33,464] {scheduler_job.py:181} INFO - Started process (PID=95353) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:50:33,465] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 03:50:33,465] {logging_mixin.py:104} INFO - [2021-08-16 03:50:33,465] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:50:33,900] {logging_mixin.py:104} INFO - [2021-08-16 03:50:33,895] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 03:50:33,903] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:50:33,916] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.454 seconds
[2021-08-16 03:51:04,082] {scheduler_job.py:181} INFO - Started process (PID=95390) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:51:04,083] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 03:51:04,084] {logging_mixin.py:104} INFO - [2021-08-16 03:51:04,084] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:51:04,513] {logging_mixin.py:104} INFO - [2021-08-16 03:51:04,511] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 03:51:04,517] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:51:04,528] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.448 seconds
[2021-08-16 03:51:34,684] {scheduler_job.py:181} INFO - Started process (PID=95428) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:51:34,685] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 03:51:34,686] {logging_mixin.py:104} INFO - [2021-08-16 03:51:34,686] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:51:35,118] {logging_mixin.py:104} INFO - [2021-08-16 03:51:35,116] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 03:51:35,120] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:51:35,131] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.449 seconds
[2021-08-16 03:52:05,321] {scheduler_job.py:181} INFO - Started process (PID=95469) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:52:05,322] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 03:52:05,323] {logging_mixin.py:104} INFO - [2021-08-16 03:52:05,323] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:52:05,763] {logging_mixin.py:104} INFO - [2021-08-16 03:52:05,762] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 03:52:05,767] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:52:05,777] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.458 seconds
[2021-08-16 03:52:35,925] {scheduler_job.py:181} INFO - Started process (PID=95498) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:52:35,926] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 03:52:35,927] {logging_mixin.py:104} INFO - [2021-08-16 03:52:35,927] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:52:36,365] {logging_mixin.py:104} INFO - [2021-08-16 03:52:36,364] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 03:52:36,368] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:52:36,379] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.456 seconds
[2021-08-16 03:53:06,551] {scheduler_job.py:181} INFO - Started process (PID=95541) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:53:06,552] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 03:53:06,553] {logging_mixin.py:104} INFO - [2021-08-16 03:53:06,553] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:53:06,976] {logging_mixin.py:104} INFO - [2021-08-16 03:53:06,974] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 03:53:06,978] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:53:06,990] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.440 seconds
[2021-08-16 03:53:37,139] {scheduler_job.py:181} INFO - Started process (PID=95583) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:53:37,140] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 03:53:37,141] {logging_mixin.py:104} INFO - [2021-08-16 03:53:37,141] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:53:37,568] {logging_mixin.py:104} INFO - [2021-08-16 03:53:37,567] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 03:53:37,571] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:53:37,588] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.450 seconds
[2021-08-16 03:54:07,762] {scheduler_job.py:181} INFO - Started process (PID=95622) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:54:07,763] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 03:54:07,764] {logging_mixin.py:104} INFO - [2021-08-16 03:54:07,764] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:54:08,202] {logging_mixin.py:104} INFO - [2021-08-16 03:54:08,201] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 03:54:08,205] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:54:08,219] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.458 seconds
[2021-08-16 03:54:38,372] {scheduler_job.py:181} INFO - Started process (PID=95650) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:54:38,373] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 03:54:38,374] {logging_mixin.py:104} INFO - [2021-08-16 03:54:38,374] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:54:38,809] {logging_mixin.py:104} INFO - [2021-08-16 03:54:38,807] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 03:54:38,811] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:54:38,823] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.452 seconds
[2021-08-16 03:55:08,989] {scheduler_job.py:181} INFO - Started process (PID=95692) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:55:08,990] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 03:55:08,991] {logging_mixin.py:104} INFO - [2021-08-16 03:55:08,991] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:55:09,421] {logging_mixin.py:104} INFO - [2021-08-16 03:55:09,420] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 03:55:09,424] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:55:09,435] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.447 seconds
[2021-08-16 03:55:39,587] {scheduler_job.py:181} INFO - Started process (PID=95732) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:55:39,588] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 03:55:39,588] {logging_mixin.py:104} INFO - [2021-08-16 03:55:39,588] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:55:40,018] {logging_mixin.py:104} INFO - [2021-08-16 03:55:40,016] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 03:55:40,020] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:55:40,031] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.446 seconds
[2021-08-16 03:56:10,188] {scheduler_job.py:181} INFO - Started process (PID=95770) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:56:10,189] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 03:56:10,190] {logging_mixin.py:104} INFO - [2021-08-16 03:56:10,190] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:56:10,620] {logging_mixin.py:104} INFO - [2021-08-16 03:56:10,618] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 03:56:10,623] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:56:10,635] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.448 seconds
[2021-08-16 03:56:41,449] {scheduler_job.py:181} INFO - Started process (PID=95795) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:56:41,451] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 03:56:41,451] {logging_mixin.py:104} INFO - [2021-08-16 03:56:41,451] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:56:41,885] {logging_mixin.py:104} INFO - [2021-08-16 03:56:41,884] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 03:56:41,888] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:56:41,898] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.451 seconds
[2021-08-16 03:57:12,058] {scheduler_job.py:181} INFO - Started process (PID=95834) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:57:12,059] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 03:57:12,060] {logging_mixin.py:104} INFO - [2021-08-16 03:57:12,060] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:57:12,511] {logging_mixin.py:104} INFO - [2021-08-16 03:57:12,509] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 03:57:12,514] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:57:12,525] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.468 seconds
[2021-08-16 03:57:42,681] {scheduler_job.py:181} INFO - Started process (PID=95873) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:57:42,683] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 03:57:42,683] {logging_mixin.py:104} INFO - [2021-08-16 03:57:42,683] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:57:43,143] {logging_mixin.py:104} INFO - [2021-08-16 03:57:43,141] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 03:57:43,146] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:57:43,161] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.481 seconds
[2021-08-16 03:58:13,324] {scheduler_job.py:181} INFO - Started process (PID=95910) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:58:13,326] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 03:58:13,327] {logging_mixin.py:104} INFO - [2021-08-16 03:58:13,327] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:58:13,755] {logging_mixin.py:104} INFO - [2021-08-16 03:58:13,753] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 03:58:13,758] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:58:13,768] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.446 seconds
[2021-08-16 03:58:43,922] {scheduler_job.py:181} INFO - Started process (PID=95938) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:58:43,923] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 03:58:43,924] {logging_mixin.py:104} INFO - [2021-08-16 03:58:43,924] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:58:44,392] {logging_mixin.py:104} INFO - [2021-08-16 03:58:44,390] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 03:58:44,394] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 03:58:44,405] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.486 seconds
[2021-08-16 04:03:42,632] {scheduler_job.py:181} INFO - Started process (PID=95965) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 04:03:42,633] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 04:03:42,634] {logging_mixin.py:104} INFO - [2021-08-16 04:03:42,634] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 04:03:46,084] {logging_mixin.py:104} INFO - [2021-08-16 04:03:46,082] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 04:03:46,085] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 04:03:46,095] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 3.466 seconds
[2021-08-16 04:04:16,499] {scheduler_job.py:181} INFO - Started process (PID=96007) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 04:04:16,500] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 04:04:16,501] {logging_mixin.py:104} INFO - [2021-08-16 04:04:16,501] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 04:04:16,915] {logging_mixin.py:104} INFO - [2021-08-16 04:04:16,913] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 04:04:16,917] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 04:04:16,929] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.431 seconds
[2021-08-16 04:04:46,955] {scheduler_job.py:181} INFO - Started process (PID=96035) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 04:04:46,956] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 04:04:46,957] {logging_mixin.py:104} INFO - [2021-08-16 04:04:46,957] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 04:04:47,384] {logging_mixin.py:104} INFO - [2021-08-16 04:04:47,383] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 04:04:47,387] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 04:04:47,405] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.452 seconds
[2021-08-16 04:05:18,297] {scheduler_job.py:181} INFO - Started process (PID=96075) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 04:05:18,298] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 04:05:18,298] {logging_mixin.py:104} INFO - [2021-08-16 04:05:18,298] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 04:05:18,760] {logging_mixin.py:104} INFO - [2021-08-16 04:05:18,758] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 04:05:18,762] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 04:05:18,774] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.479 seconds
[2021-08-16 04:05:48,822] {scheduler_job.py:181} INFO - Started process (PID=96114) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 04:05:48,824] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 04:05:48,825] {logging_mixin.py:104} INFO - [2021-08-16 04:05:48,825] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 04:05:49,344] {logging_mixin.py:104} INFO - [2021-08-16 04:05:49,342] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 04:05:49,348] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 04:05:49,382] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.562 seconds
[2021-08-16 04:06:19,675] {scheduler_job.py:181} INFO - Started process (PID=96152) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 04:06:19,676] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 04:06:19,676] {logging_mixin.py:104} INFO - [2021-08-16 04:06:19,676] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 04:06:20,618] {logging_mixin.py:104} INFO - [2021-08-16 04:06:20,616] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 04:06:20,621] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 04:06:20,635] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.962 seconds
[2021-08-16 04:06:50,856] {scheduler_job.py:181} INFO - Started process (PID=96190) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 04:06:50,857] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 04:06:50,858] {logging_mixin.py:104} INFO - [2021-08-16 04:06:50,858] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 04:06:51,288] {logging_mixin.py:104} INFO - [2021-08-16 04:06:51,286] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 04:06:51,291] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 04:06:51,302] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.447 seconds
[2021-08-16 04:07:21,325] {scheduler_job.py:181} INFO - Started process (PID=96218) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 04:07:21,326] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 04:07:21,327] {logging_mixin.py:104} INFO - [2021-08-16 04:07:21,327] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 04:07:21,745] {logging_mixin.py:104} INFO - [2021-08-16 04:07:21,744] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 04:07:21,748] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 04:07:21,758] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.434 seconds
[2021-08-16 08:21:21,994] {scheduler_job.py:181} INFO - Started process (PID=96254) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 08:21:21,997] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 08:21:21,998] {logging_mixin.py:104} INFO - [2021-08-16 08:21:21,998] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 08:21:25,715] {logging_mixin.py:104} INFO - [2021-08-16 08:21:25,713] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2351, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 08:21:25,716] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 08:21:25,726] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 3.749 seconds
[2021-08-16 15:29:01,918] {scheduler_job.py:182} INFO - Started process (PID=30) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 15:29:01,920] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 15:29:01,922] {logging_mixin.py:104} INFO - [2021-08-16 15:29:01,921] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 15:29:02,600] {logging_mixin.py:104} INFO - [2021-08-16 15:29:02,598] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 15:29:02,606] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 15:29:02,628] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.713 seconds
[2021-08-16 15:29:32,815] {scheduler_job.py:182} INFO - Started process (PID=62) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 15:29:32,816] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 15:29:32,817] {logging_mixin.py:104} INFO - [2021-08-16 15:29:32,817] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 15:29:33,470] {logging_mixin.py:104} INFO - [2021-08-16 15:29:33,467] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 15:29:33,476] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 15:29:33,491] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.678 seconds
[2021-08-16 15:30:03,516] {scheduler_job.py:182} INFO - Started process (PID=100) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 15:30:03,517] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 15:30:03,517] {logging_mixin.py:104} INFO - [2021-08-16 15:30:03,517] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 15:30:03,927] {logging_mixin.py:104} INFO - [2021-08-16 15:30:03,926] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 15:30:03,931] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 15:30:03,940] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.426 seconds
[2021-08-16 15:30:34,387] {scheduler_job.py:182} INFO - Started process (PID=138) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 15:30:34,388] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 15:30:34,389] {logging_mixin.py:104} INFO - [2021-08-16 15:30:34,389] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 15:30:34,797] {logging_mixin.py:104} INFO - [2021-08-16 15:30:34,795] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 15:30:34,800] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 15:30:34,811] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.426 seconds
[2021-08-16 15:31:05,608] {scheduler_job.py:182} INFO - Started process (PID=170) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 15:31:05,609] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 15:31:05,609] {logging_mixin.py:104} INFO - [2021-08-16 15:31:05,609] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 15:31:05,992] {logging_mixin.py:104} INFO - [2021-08-16 15:31:05,991] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 15:31:05,995] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 15:31:06,006] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.400 seconds
[2021-08-16 15:31:36,063] {scheduler_job.py:182} INFO - Started process (PID=205) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 15:31:36,064] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 15:31:36,065] {logging_mixin.py:104} INFO - [2021-08-16 15:31:36,065] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 15:31:36,516] {logging_mixin.py:104} INFO - [2021-08-16 15:31:36,513] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 15:31:36,518] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 15:31:36,539] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.479 seconds
[2021-08-16 15:32:35,491] {scheduler_job.py:182} INFO - Started process (PID=22) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 15:32:35,496] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 15:32:35,500] {logging_mixin.py:104} INFO - [2021-08-16 15:32:35,499] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 15:32:36,963] {logging_mixin.py:104} INFO - [2021-08-16 15:32:36,957] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 15:32:36,985] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 15:32:37,035] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 1.563 seconds
[2021-08-16 15:33:07,117] {scheduler_job.py:182} INFO - Started process (PID=57) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 15:33:07,119] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 15:33:07,120] {logging_mixin.py:104} INFO - [2021-08-16 15:33:07,120] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 15:33:08,207] {logging_mixin.py:104} INFO - [2021-08-16 15:33:08,202] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 15:33:08,233] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 15:33:08,247] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 1.134 seconds
[2021-08-16 15:33:38,347] {scheduler_job.py:182} INFO - Started process (PID=96) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 15:33:38,348] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 15:33:38,350] {logging_mixin.py:104} INFO - [2021-08-16 15:33:38,350] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 15:33:38,994] {logging_mixin.py:104} INFO - [2021-08-16 15:33:38,992] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 15:33:39,002] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 15:33:39,014] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.672 seconds
[2021-08-16 15:34:09,082] {scheduler_job.py:182} INFO - Started process (PID=138) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 15:34:09,083] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 15:34:09,084] {logging_mixin.py:104} INFO - [2021-08-16 15:34:09,084] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 15:34:09,505] {logging_mixin.py:104} INFO - [2021-08-16 15:34:09,502] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 15:34:09,508] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 15:34:09,521] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.440 seconds
[2021-08-16 15:34:40,346] {scheduler_job.py:182} INFO - Started process (PID=182) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 15:34:40,348] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 15:34:40,351] {logging_mixin.py:104} INFO - [2021-08-16 15:34:40,350] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 15:34:41,183] {logging_mixin.py:104} INFO - [2021-08-16 15:34:41,172] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 15:34:41,201] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 15:34:41,232] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.888 seconds
[2021-08-16 15:35:11,780] {scheduler_job.py:182} INFO - Started process (PID=221) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 15:35:11,781] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 15:35:11,783] {logging_mixin.py:104} INFO - [2021-08-16 15:35:11,783] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 15:35:12,614] {logging_mixin.py:104} INFO - [2021-08-16 15:35:12,611] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 15:35:12,618] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 15:35:12,640] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.862 seconds
[2021-08-16 15:35:43,044] {scheduler_job.py:182} INFO - Started process (PID=247) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 15:35:43,046] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 15:35:43,047] {logging_mixin.py:104} INFO - [2021-08-16 15:35:43,046] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 15:35:44,706] {logging_mixin.py:104} INFO - [2021-08-16 15:35:44,703] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 15:35:44,711] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 15:35:44,735] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 1.693 seconds
[2021-08-16 15:36:15,342] {scheduler_job.py:182} INFO - Started process (PID=286) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 15:36:15,343] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 15:36:15,344] {logging_mixin.py:104} INFO - [2021-08-16 15:36:15,344] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 15:36:15,856] {logging_mixin.py:104} INFO - [2021-08-16 15:36:15,854] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 15:36:15,859] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 15:36:15,874] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.533 seconds
[2021-08-16 15:36:46,611] {scheduler_job.py:182} INFO - Started process (PID=324) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 15:36:46,612] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 15:36:46,613] {logging_mixin.py:104} INFO - [2021-08-16 15:36:46,613] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 15:36:47,014] {logging_mixin.py:104} INFO - [2021-08-16 15:36:47,012] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 15:36:47,018] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 15:36:47,030] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.421 seconds
[2021-08-16 15:37:17,913] {scheduler_job.py:182} INFO - Started process (PID=366) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 15:37:17,913] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 15:37:17,914] {logging_mixin.py:104} INFO - [2021-08-16 15:37:17,914] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 15:37:18,290] {logging_mixin.py:104} INFO - [2021-08-16 15:37:18,289] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 15:37:18,293] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 15:37:18,305] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.394 seconds
[2021-08-16 15:37:49,118] {scheduler_job.py:182} INFO - Started process (PID=404) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 15:37:49,120] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 15:37:49,120] {logging_mixin.py:104} INFO - [2021-08-16 15:37:49,120] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 15:37:49,508] {logging_mixin.py:104} INFO - [2021-08-16 15:37:49,506] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 15:37:49,511] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 15:37:49,522] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.405 seconds
[2021-08-16 15:38:20,361] {scheduler_job.py:182} INFO - Started process (PID=441) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 15:38:20,362] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 15:38:20,363] {logging_mixin.py:104} INFO - [2021-08-16 15:38:20,363] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 15:38:20,749] {logging_mixin.py:104} INFO - [2021-08-16 15:38:20,747] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 15:38:20,752] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 15:38:20,764] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.404 seconds
[2021-08-16 15:42:43,603] {scheduler_job.py:182} INFO - Started process (PID=35) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 15:42:43,604] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 15:42:43,606] {logging_mixin.py:104} INFO - [2021-08-16 15:42:43,606] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 15:42:44,630] {logging_mixin.py:104} INFO - [2021-08-16 15:42:44,627] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 15:42:44,634] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 15:42:44,678] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 1.079 seconds
[2021-08-16 15:43:14,980] {scheduler_job.py:182} INFO - Started process (PID=106) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 15:43:14,981] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 15:43:14,981] {logging_mixin.py:104} INFO - [2021-08-16 15:43:14,981] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 15:43:15,730] {logging_mixin.py:104} INFO - [2021-08-16 15:43:15,726] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 15:43:15,754] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 15:43:15,769] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.791 seconds
[2021-08-16 15:43:46,066] {scheduler_job.py:182} INFO - Started process (PID=171) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 15:43:46,068] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 15:43:46,069] {logging_mixin.py:104} INFO - [2021-08-16 15:43:46,069] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 15:43:46,583] {logging_mixin.py:104} INFO - [2021-08-16 15:43:46,580] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 15:43:46,589] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 15:43:46,602] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.537 seconds
[2021-08-16 15:44:17,484] {scheduler_job.py:182} INFO - Started process (PID=241) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 15:44:17,485] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 15:44:17,485] {logging_mixin.py:104} INFO - [2021-08-16 15:44:17,485] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 15:44:18,027] {logging_mixin.py:104} INFO - [2021-08-16 15:44:18,025] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 15:44:18,031] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 15:44:18,045] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.563 seconds
[2021-08-16 15:44:48,249] {scheduler_job.py:182} INFO - Started process (PID=318) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 15:44:48,250] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 15:44:48,251] {logging_mixin.py:104} INFO - [2021-08-16 15:44:48,251] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 15:44:49,019] {logging_mixin.py:104} INFO - [2021-08-16 15:44:49,016] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 15:44:49,022] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 15:44:49,033] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.785 seconds
[2021-08-16 15:45:19,376] {scheduler_job.py:182} INFO - Started process (PID=384) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 15:45:19,378] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 15:45:19,378] {logging_mixin.py:104} INFO - [2021-08-16 15:45:19,378] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 15:45:19,896] {logging_mixin.py:104} INFO - [2021-08-16 15:45:19,893] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 15:45:19,899] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 15:45:19,912] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.537 seconds
[2021-08-16 15:45:50,738] {scheduler_job.py:182} INFO - Started process (PID=452) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 15:45:50,739] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 15:45:50,739] {logging_mixin.py:104} INFO - [2021-08-16 15:45:50,739] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 15:45:51,240] {logging_mixin.py:104} INFO - [2021-08-16 15:45:51,237] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 15:45:51,243] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 15:45:51,255] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.519 seconds
[2021-08-16 15:46:22,055] {scheduler_job.py:182} INFO - Started process (PID=516) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 15:46:22,057] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 15:46:22,058] {logging_mixin.py:104} INFO - [2021-08-16 15:46:22,058] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 15:46:22,541] {logging_mixin.py:104} INFO - [2021-08-16 15:46:22,538] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 15:46:22,544] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 15:46:22,555] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.502 seconds
[2021-08-16 15:46:54,657] {scheduler_job.py:182} INFO - Started process (PID=569) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 15:46:54,670] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 15:46:54,685] {logging_mixin.py:104} INFO - [2021-08-16 15:46:54,681] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 15:47:04,433] {logging_mixin.py:104} INFO - [2021-08-16 15:47:04,412] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 15:47:04,538] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 15:47:04,636] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 10.081 seconds
[2021-08-16 15:47:35,344] {scheduler_job.py:182} INFO - Started process (PID=634) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 15:47:35,347] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 15:47:35,354] {logging_mixin.py:104} INFO - [2021-08-16 15:47:35,352] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 15:47:36,935] {logging_mixin.py:104} INFO - [2021-08-16 15:47:36,924] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 15:47:36,989] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 15:47:37,030] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 1.692 seconds
[2021-08-16 15:48:07,229] {scheduler_job.py:182} INFO - Started process (PID=686) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 15:48:07,230] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 15:48:07,231] {logging_mixin.py:104} INFO - [2021-08-16 15:48:07,231] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 15:48:08,066] {logging_mixin.py:104} INFO - [2021-08-16 15:48:08,062] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 15:48:08,071] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 15:48:08,086] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.859 seconds
[2021-08-16 15:48:58,833] {scheduler_job.py:182} INFO - Started process (PID=737) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 15:48:58,840] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 15:48:58,841] {logging_mixin.py:104} INFO - [2021-08-16 15:48:58,841] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 15:49:00,081] {logging_mixin.py:104} INFO - [2021-08-16 15:49:00,068] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 15:49:00,143] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 15:49:00,159] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 1.333 seconds
[2021-08-16 15:49:30,908] {scheduler_job.py:182} INFO - Started process (PID=793) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 15:49:30,909] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 15:49:30,909] {logging_mixin.py:104} INFO - [2021-08-16 15:49:30,909] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 15:49:32,572] {logging_mixin.py:104} INFO - [2021-08-16 15:49:32,548] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 15:49:32,621] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 15:49:32,707] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 1.801 seconds
[2021-08-16 15:50:03,074] {scheduler_job.py:182} INFO - Started process (PID=846) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 15:50:03,075] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 15:50:03,076] {logging_mixin.py:104} INFO - [2021-08-16 15:50:03,076] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 15:50:03,651] {logging_mixin.py:104} INFO - [2021-08-16 15:50:03,647] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 15:50:03,654] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 15:50:03,677] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.606 seconds
[2021-08-16 15:50:34,536] {scheduler_job.py:182} INFO - Started process (PID=907) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 15:50:34,537] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 15:50:34,538] {logging_mixin.py:104} INFO - [2021-08-16 15:50:34,538] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 15:50:35,134] {logging_mixin.py:104} INFO - [2021-08-16 15:50:35,131] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 15:50:35,137] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 15:50:35,157] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.622 seconds
[2021-08-16 15:51:05,542] {scheduler_job.py:182} INFO - Started process (PID=973) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 15:51:05,543] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 15:51:05,544] {logging_mixin.py:104} INFO - [2021-08-16 15:51:05,544] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 15:51:06,048] {logging_mixin.py:104} INFO - [2021-08-16 15:51:06,045] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 15:51:06,051] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 15:51:06,064] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.524 seconds
[2021-08-16 15:51:36,843] {scheduler_job.py:182} INFO - Started process (PID=1036) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 15:51:36,844] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 15:51:36,844] {logging_mixin.py:104} INFO - [2021-08-16 15:51:36,844] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 15:51:37,337] {logging_mixin.py:104} INFO - [2021-08-16 15:51:37,334] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 15:51:37,340] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 15:51:37,354] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.513 seconds
[2021-08-16 15:52:08,061] {scheduler_job.py:182} INFO - Started process (PID=1088) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 15:52:08,063] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 15:52:08,064] {logging_mixin.py:104} INFO - [2021-08-16 15:52:08,064] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 15:52:08,539] {logging_mixin.py:104} INFO - [2021-08-16 15:52:08,537] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 15:52:08,542] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 15:52:08,555] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.495 seconds
[2021-08-16 15:52:39,463] {scheduler_job.py:182} INFO - Started process (PID=1151) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 15:52:39,465] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 15:52:39,466] {logging_mixin.py:104} INFO - [2021-08-16 15:52:39,466] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 15:52:39,969] {logging_mixin.py:104} INFO - [2021-08-16 15:52:39,966] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 15:52:39,972] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 15:52:39,987] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.526 seconds
[2021-08-16 15:53:55,092] {scheduler_job.py:182} INFO - Started process (PID=1204) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 15:53:55,093] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 15:53:55,094] {logging_mixin.py:104} INFO - [2021-08-16 15:53:55,094] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 15:53:55,913] {logging_mixin.py:104} INFO - [2021-08-16 15:53:55,908] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 15:53:55,944] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 15:53:55,957] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.867 seconds
[2021-08-16 15:54:26,246] {scheduler_job.py:182} INFO - Started process (PID=1256) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 15:54:26,248] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 15:54:26,249] {logging_mixin.py:104} INFO - [2021-08-16 15:54:26,249] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 15:54:26,774] {logging_mixin.py:104} INFO - [2021-08-16 15:54:26,772] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 15:54:26,778] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 15:54:26,790] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.546 seconds
[2021-08-16 15:54:56,838] {scheduler_job.py:182} INFO - Started process (PID=1319) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 15:54:56,840] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 15:54:56,840] {logging_mixin.py:104} INFO - [2021-08-16 15:54:56,840] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 15:54:57,432] {logging_mixin.py:104} INFO - [2021-08-16 15:54:57,428] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 15:54:57,435] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 15:54:57,449] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.613 seconds
[2021-08-16 15:55:27,584] {scheduler_job.py:182} INFO - Started process (PID=1372) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 15:55:27,585] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 15:55:27,586] {logging_mixin.py:104} INFO - [2021-08-16 15:55:27,586] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 15:55:28,080] {logging_mixin.py:104} INFO - [2021-08-16 15:55:28,077] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 15:55:28,084] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 15:55:28,095] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.513 seconds
[2021-08-16 15:55:58,311] {scheduler_job.py:182} INFO - Started process (PID=1433) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 15:55:58,312] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 15:55:58,313] {logging_mixin.py:104} INFO - [2021-08-16 15:55:58,313] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 15:55:58,842] {logging_mixin.py:104} INFO - [2021-08-16 15:55:58,840] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 15:55:58,845] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 15:55:58,858] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.548 seconds
[2021-08-16 15:56:29,087] {scheduler_job.py:182} INFO - Started process (PID=1485) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 15:56:29,088] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 15:56:29,089] {logging_mixin.py:104} INFO - [2021-08-16 15:56:29,089] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 15:56:29,777] {logging_mixin.py:104} INFO - [2021-08-16 15:56:29,774] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 15:56:29,779] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 15:56:29,795] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.710 seconds
[2021-08-16 15:57:00,600] {scheduler_job.py:182} INFO - Started process (PID=1551) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 15:57:00,601] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 15:57:00,601] {logging_mixin.py:104} INFO - [2021-08-16 15:57:00,601] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 15:57:01,090] {logging_mixin.py:104} INFO - [2021-08-16 15:57:01,086] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 15:57:01,094] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 15:57:01,107] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.509 seconds
[2021-08-16 15:57:31,448] {scheduler_job.py:182} INFO - Started process (PID=1611) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 15:57:31,449] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 15:57:31,450] {logging_mixin.py:104} INFO - [2021-08-16 15:57:31,450] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 15:57:31,955] {logging_mixin.py:104} INFO - [2021-08-16 15:57:31,952] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 15:57:31,958] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 15:57:31,972] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.527 seconds
[2021-08-16 15:58:02,507] {scheduler_job.py:182} INFO - Started process (PID=1674) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 15:58:02,508] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 15:58:02,509] {logging_mixin.py:104} INFO - [2021-08-16 15:58:02,509] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 15:58:03,073] {logging_mixin.py:104} INFO - [2021-08-16 15:58:03,061] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 15:58:03,082] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 15:58:03,134] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.629 seconds
[2021-08-16 15:58:33,906] {scheduler_job.py:182} INFO - Started process (PID=1737) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 15:58:33,907] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 15:58:33,908] {logging_mixin.py:104} INFO - [2021-08-16 15:58:33,907] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 15:58:34,396] {logging_mixin.py:104} INFO - [2021-08-16 15:58:34,393] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 15:58:34,399] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 15:58:34,410] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.506 seconds
[2021-08-16 15:59:05,228] {scheduler_job.py:182} INFO - Started process (PID=1801) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 15:59:05,229] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 15:59:05,230] {logging_mixin.py:104} INFO - [2021-08-16 15:59:05,230] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 15:59:05,710] {logging_mixin.py:104} INFO - [2021-08-16 15:59:05,708] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 15:59:05,713] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 15:59:05,737] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.511 seconds
[2021-08-16 15:59:36,591] {scheduler_job.py:182} INFO - Started process (PID=1852) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 15:59:36,592] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 15:59:36,593] {logging_mixin.py:104} INFO - [2021-08-16 15:59:36,593] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 15:59:37,190] {logging_mixin.py:104} INFO - [2021-08-16 15:59:37,187] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 15:59:37,193] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 15:59:37,203] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.615 seconds
[2021-08-16 16:00:07,432] {scheduler_job.py:182} INFO - Started process (PID=1915) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:00:07,433] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 16:00:07,434] {logging_mixin.py:104} INFO - [2021-08-16 16:00:07,434] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:00:07,813] {logging_mixin.py:104} INFO - [2021-08-16 16:00:07,811] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 16:00:07,817] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:00:07,831] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.400 seconds
[2021-08-16 16:00:38,825] {scheduler_job.py:182} INFO - Started process (PID=1981) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:00:38,826] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 16:00:38,826] {logging_mixin.py:104} INFO - [2021-08-16 16:00:38,826] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:00:39,491] {logging_mixin.py:104} INFO - [2021-08-16 16:00:39,487] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 16:00:39,520] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:00:39,537] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.715 seconds
[2021-08-16 16:01:10,340] {scheduler_job.py:182} INFO - Started process (PID=2047) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:01:10,341] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 16:01:10,341] {logging_mixin.py:104} INFO - [2021-08-16 16:01:10,341] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:01:10,806] {logging_mixin.py:104} INFO - Upload Completed
[2021-08-16 16:01:10,812] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['upload_to_s3']) retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:01:10,828] {logging_mixin.py:104} INFO - [2021-08-16 16:01:10,828] {dag.py:1818} INFO - Sync 1 DAGs
[2021-08-16 16:01:10,836] {logging_mixin.py:104} INFO - [2021-08-16 16:01:10,836] {dag.py:1837} INFO - Creating ORM DAG for upload_to_s3
[2021-08-16 16:01:10,839] {logging_mixin.py:104} INFO - [2021-08-16 16:01:10,839] {dag.py:2273} INFO - Setting next_dagrun for upload_to_s3 to 2021-08-15 00:00:00+00:00
[2021-08-16 16:01:10,867] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.529 seconds
[2021-08-16 16:01:41,480] {scheduler_job.py:182} INFO - Started process (PID=2111) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:01:41,481] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 16:01:41,482] {logging_mixin.py:104} INFO - [2021-08-16 16:01:41,482] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:01:42,008] {logging_mixin.py:104} INFO - Upload Completed
[2021-08-16 16:01:42,014] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['upload_to_s3']) retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:01:42,029] {logging_mixin.py:104} INFO - [2021-08-16 16:01:42,029] {dag.py:1818} INFO - Sync 1 DAGs
[2021-08-16 16:01:42,042] {logging_mixin.py:104} INFO - [2021-08-16 16:01:42,041] {dag.py:2273} INFO - Setting next_dagrun for upload_to_s3 to 2021-08-15 00:00:00+00:00
[2021-08-16 16:01:42,048] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.570 seconds
[2021-08-16 16:02:12,595] {scheduler_job.py:182} INFO - Started process (PID=2175) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:02:12,597] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 16:02:12,598] {logging_mixin.py:104} INFO - [2021-08-16 16:02:12,598] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:02:13,024] {logging_mixin.py:104} INFO - Upload Completed
[2021-08-16 16:02:13,030] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['upload_to_s3']) retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:02:13,044] {logging_mixin.py:104} INFO - [2021-08-16 16:02:13,044] {dag.py:1818} INFO - Sync 1 DAGs
[2021-08-16 16:02:13,054] {logging_mixin.py:104} INFO - [2021-08-16 16:02:13,054] {dag.py:2273} INFO - Setting next_dagrun for upload_to_s3 to 2021-08-15 00:00:00+00:00
[2021-08-16 16:02:13,061] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.468 seconds
[2021-08-16 16:02:43,761] {scheduler_job.py:182} INFO - Started process (PID=2242) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:02:43,763] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 16:02:43,763] {logging_mixin.py:104} INFO - [2021-08-16 16:02:43,763] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:02:44,164] {logging_mixin.py:104} INFO - [2021-08-16 16:02:44,163] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("/data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/data/data.csv'
[2021-08-16 16:02:44,167] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:02:44,180] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.420 seconds
[2021-08-16 16:03:14,423] {scheduler_job.py:182} INFO - Started process (PID=2305) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:03:14,427] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 16:03:14,428] {logging_mixin.py:104} INFO - [2021-08-16 16:03:14,428] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:03:14,882] {logging_mixin.py:104} INFO - [2021-08-16 16:03:14,881] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-16 16:03:14,885] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:03:14,902] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.482 seconds
[2021-08-16 16:03:45,082] {scheduler_job.py:182} INFO - Started process (PID=2369) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:03:45,083] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 16:03:45,084] {logging_mixin.py:104} INFO - [2021-08-16 16:03:45,084] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:03:45,492] {logging_mixin.py:104} INFO - [2021-08-16 16:03:45,491] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-16 16:03:45,495] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:03:45,508] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.428 seconds
[2021-08-16 16:04:16,238] {scheduler_job.py:182} INFO - Started process (PID=2433) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:04:16,239] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 16:04:16,240] {logging_mixin.py:104} INFO - [2021-08-16 16:04:16,240] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:04:16,632] {logging_mixin.py:104} INFO - [2021-08-16 16:04:16,630] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-16 16:04:16,637] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:04:16,650] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.413 seconds
[2021-08-16 16:04:47,375] {scheduler_job.py:182} INFO - Started process (PID=2499) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:04:47,376] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 16:04:47,377] {logging_mixin.py:104} INFO - [2021-08-16 16:04:47,377] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:04:47,750] {logging_mixin.py:104} INFO - [2021-08-16 16:04:47,749] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-16 16:04:47,753] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:04:47,764] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.391 seconds
[2021-08-16 16:05:18,559] {scheduler_job.py:182} INFO - Started process (PID=2563) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:05:18,560] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 16:05:18,561] {logging_mixin.py:104} INFO - [2021-08-16 16:05:18,561] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:05:18,976] {logging_mixin.py:104} INFO - [2021-08-16 16:05:18,974] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-16 16:05:18,979] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:05:18,990] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.433 seconds
[2021-08-16 16:05:49,679] {scheduler_job.py:182} INFO - Started process (PID=2630) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:05:49,680] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 16:05:49,681] {logging_mixin.py:104} INFO - [2021-08-16 16:05:49,681] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:05:50,080] {logging_mixin.py:104} INFO - [2021-08-16 16:05:50,078] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-16 16:05:50,083] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:05:50,095] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.417 seconds
[2021-08-16 16:06:20,797] {scheduler_job.py:182} INFO - Started process (PID=2694) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:06:20,798] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 16:06:20,799] {logging_mixin.py:104} INFO - [2021-08-16 16:06:20,799] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:06:21,181] {logging_mixin.py:104} INFO - [2021-08-16 16:06:21,180] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-16 16:06:21,184] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:06:21,196] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.401 seconds
[2021-08-16 16:06:51,945] {scheduler_job.py:182} INFO - Started process (PID=2759) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:06:51,946] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 16:06:51,947] {logging_mixin.py:104} INFO - [2021-08-16 16:06:51,947] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:06:52,370] {logging_mixin.py:104} INFO - [2021-08-16 16:06:52,368] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-16 16:06:52,373] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:06:52,386] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.443 seconds
[2021-08-16 16:07:23,093] {scheduler_job.py:182} INFO - Started process (PID=2822) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:07:23,094] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 16:07:23,094] {logging_mixin.py:104} INFO - [2021-08-16 16:07:23,094] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:07:23,490] {logging_mixin.py:104} INFO - [2021-08-16 16:07:23,488] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-16 16:07:23,494] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:07:23,507] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.416 seconds
[2021-08-16 16:07:54,247] {scheduler_job.py:182} INFO - Started process (PID=2877) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:07:54,248] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 16:07:54,249] {logging_mixin.py:104} INFO - [2021-08-16 16:07:54,249] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:07:54,620] {logging_mixin.py:104} INFO - [2021-08-16 16:07:54,619] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-16 16:07:54,623] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:07:54,634] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.389 seconds
[2021-08-16 16:08:25,341] {scheduler_job.py:182} INFO - Started process (PID=2946) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:08:25,342] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 16:08:25,342] {logging_mixin.py:104} INFO - [2021-08-16 16:08:25,342] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:08:25,742] {logging_mixin.py:104} INFO - [2021-08-16 16:08:25,740] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-16 16:08:25,744] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:08:25,756] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.417 seconds
[2021-08-16 16:08:56,471] {scheduler_job.py:182} INFO - Started process (PID=3012) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:08:56,472] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 16:08:56,473] {logging_mixin.py:104} INFO - [2021-08-16 16:08:56,473] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:08:56,860] {logging_mixin.py:104} INFO - [2021-08-16 16:08:56,858] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-16 16:08:56,863] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:08:56,874] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.405 seconds
[2021-08-16 16:09:27,565] {scheduler_job.py:182} INFO - Started process (PID=3074) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:09:27,566] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 16:09:27,567] {logging_mixin.py:104} INFO - [2021-08-16 16:09:27,567] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:09:27,954] {logging_mixin.py:104} INFO - [2021-08-16 16:09:27,953] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-16 16:09:27,957] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:09:27,969] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.405 seconds
[2021-08-16 16:09:58,649] {scheduler_job.py:182} INFO - Started process (PID=3138) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:09:58,651] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 16:09:58,651] {logging_mixin.py:104} INFO - [2021-08-16 16:09:58,651] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:09:59,034] {logging_mixin.py:104} INFO - [2021-08-16 16:09:59,032] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-16 16:09:59,037] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:09:59,048] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.401 seconds
[2021-08-16 16:10:29,763] {scheduler_job.py:182} INFO - Started process (PID=3200) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:10:29,764] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 16:10:29,765] {logging_mixin.py:104} INFO - [2021-08-16 16:10:29,765] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:10:30,157] {logging_mixin.py:104} INFO - [2021-08-16 16:10:30,155] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-16 16:10:30,160] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:10:30,171] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.410 seconds
[2021-08-16 16:11:00,865] {scheduler_job.py:182} INFO - Started process (PID=3265) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:11:00,866] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 16:11:00,867] {logging_mixin.py:104} INFO - [2021-08-16 16:11:00,867] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:11:01,246] {logging_mixin.py:104} INFO - [2021-08-16 16:11:01,244] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-16 16:11:01,248] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:11:01,260] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.397 seconds
[2021-08-16 16:11:31,961] {scheduler_job.py:182} INFO - Started process (PID=3335) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:11:31,962] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 16:11:31,962] {logging_mixin.py:104} INFO - [2021-08-16 16:11:31,962] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:11:32,426] {logging_mixin.py:104} INFO - [2021-08-16 16:11:32,424] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-16 16:11:32,429] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:11:32,440] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.481 seconds
[2021-08-16 16:12:02,555] {scheduler_job.py:182} INFO - Started process (PID=3399) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:12:02,556] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 16:12:02,556] {logging_mixin.py:104} INFO - [2021-08-16 16:12:02,556] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:12:02,917] {logging_mixin.py:104} INFO - [2021-08-16 16:12:02,915] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-16 16:12:02,919] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:12:02,937] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.384 seconds
[2021-08-16 16:12:33,683] {scheduler_job.py:182} INFO - Started process (PID=3464) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:12:33,683] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 16:12:33,684] {logging_mixin.py:104} INFO - [2021-08-16 16:12:33,684] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:12:34,073] {logging_mixin.py:104} INFO - [2021-08-16 16:12:34,071] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-16 16:12:34,075] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:12:34,087] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.406 seconds
[2021-08-16 16:13:04,968] {scheduler_job.py:182} INFO - Started process (PID=3530) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:13:04,969] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 16:13:04,970] {logging_mixin.py:104} INFO - [2021-08-16 16:13:04,970] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:13:05,351] {logging_mixin.py:104} INFO - [2021-08-16 16:13:05,350] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-16 16:13:05,354] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:13:05,365] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.399 seconds
[2021-08-16 16:13:36,113] {scheduler_job.py:182} INFO - Started process (PID=3596) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:13:36,114] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 16:13:36,115] {logging_mixin.py:104} INFO - [2021-08-16 16:13:36,114] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:13:36,504] {logging_mixin.py:104} INFO - [2021-08-16 16:13:36,502] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-16 16:13:36,507] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:13:36,519] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.407 seconds
[2021-08-16 16:14:07,339] {scheduler_job.py:182} INFO - Started process (PID=3661) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:14:07,342] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 16:14:07,343] {logging_mixin.py:104} INFO - [2021-08-16 16:14:07,343] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:14:07,757] {logging_mixin.py:104} INFO - [2021-08-16 16:14:07,756] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-16 16:14:07,760] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:14:07,774] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.437 seconds
[2021-08-16 16:14:37,847] {scheduler_job.py:182} INFO - Started process (PID=3728) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:14:37,848] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 16:14:37,848] {logging_mixin.py:104} INFO - [2021-08-16 16:14:37,848] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:14:38,218] {logging_mixin.py:104} INFO - [2021-08-16 16:14:38,217] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-16 16:14:38,222] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:14:38,243] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.398 seconds
[2021-08-16 16:15:08,281] {scheduler_job.py:182} INFO - Started process (PID=3790) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:15:08,284] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 16:15:08,285] {logging_mixin.py:104} INFO - [2021-08-16 16:15:08,285] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:15:08,701] {logging_mixin.py:104} INFO - [2021-08-16 16:15:08,700] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-16 16:15:08,704] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:15:08,716] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.437 seconds
[2021-08-16 16:15:38,753] {scheduler_job.py:182} INFO - Started process (PID=3854) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:15:38,754] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 16:15:38,755] {logging_mixin.py:104} INFO - [2021-08-16 16:15:38,755] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:15:39,158] {logging_mixin.py:104} INFO - [2021-08-16 16:15:39,153] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-16 16:15:39,162] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:15:39,173] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.422 seconds
[2021-08-16 16:16:09,252] {scheduler_job.py:182} INFO - Started process (PID=3921) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:16:09,253] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 16:16:09,253] {logging_mixin.py:104} INFO - [2021-08-16 16:16:09,253] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:16:09,757] {logging_mixin.py:104} INFO - [2021-08-16 16:16:09,755] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-16 16:16:09,760] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:16:09,772] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.522 seconds
[2021-08-16 16:16:40,461] {scheduler_job.py:182} INFO - Started process (PID=3980) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:16:40,462] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 16:16:40,463] {logging_mixin.py:104} INFO - [2021-08-16 16:16:40,463] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:16:41,108] {logging_mixin.py:104} INFO - [2021-08-16 16:16:41,106] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-16 16:16:41,110] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:16:41,121] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.662 seconds
[2021-08-16 16:17:11,209] {scheduler_job.py:182} INFO - Started process (PID=4047) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:17:11,210] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 16:17:11,211] {logging_mixin.py:104} INFO - [2021-08-16 16:17:11,211] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:17:11,597] {logging_mixin.py:104} INFO - [2021-08-16 16:17:11,595] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-16 16:17:11,600] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:17:11,612] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.405 seconds
[2021-08-16 16:17:41,677] {scheduler_job.py:182} INFO - Started process (PID=4117) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:17:41,678] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 16:17:41,679] {logging_mixin.py:104} INFO - [2021-08-16 16:17:41,679] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:17:42,090] {logging_mixin.py:104} INFO - [2021-08-16 16:17:42,088] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-16 16:17:42,093] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:17:42,104] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.432 seconds
[2021-08-16 16:18:12,144] {scheduler_job.py:182} INFO - Started process (PID=4193) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:18:12,145] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 16:18:12,145] {logging_mixin.py:104} INFO - [2021-08-16 16:18:12,145] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:18:12,561] {logging_mixin.py:104} INFO - [2021-08-16 16:18:12,559] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-16 16:18:12,564] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:18:12,575] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.434 seconds
[2021-08-16 16:18:43,448] {scheduler_job.py:182} INFO - Started process (PID=4260) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:18:43,449] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 16:18:43,450] {logging_mixin.py:104} INFO - [2021-08-16 16:18:43,450] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:18:43,829] {logging_mixin.py:104} INFO - [2021-08-16 16:18:43,827] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-16 16:18:43,832] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:18:43,844] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.398 seconds
[2021-08-16 16:19:14,620] {scheduler_job.py:182} INFO - Started process (PID=4325) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:19:14,621] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 16:19:14,622] {logging_mixin.py:104} INFO - [2021-08-16 16:19:14,622] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:19:15,016] {logging_mixin.py:104} INFO - [2021-08-16 16:19:15,014] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-16 16:19:15,019] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:19:15,031] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.413 seconds
[2021-08-16 16:19:45,726] {scheduler_job.py:182} INFO - Started process (PID=4388) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:19:45,727] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 16:19:45,728] {logging_mixin.py:104} INFO - [2021-08-16 16:19:45,728] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:19:46,105] {logging_mixin.py:104} INFO - [2021-08-16 16:19:46,103] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-16 16:19:46,107] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:19:46,119] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.394 seconds
[2021-08-16 16:20:16,923] {scheduler_job.py:182} INFO - Started process (PID=4452) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:20:16,924] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 16:20:16,924] {logging_mixin.py:104} INFO - [2021-08-16 16:20:16,924] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:20:17,298] {logging_mixin.py:104} INFO - [2021-08-16 16:20:17,296] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-16 16:20:17,301] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:20:17,313] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.391 seconds
[2021-08-16 16:20:48,072] {scheduler_job.py:182} INFO - Started process (PID=4517) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:20:48,073] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 16:20:48,074] {logging_mixin.py:104} INFO - [2021-08-16 16:20:48,073] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:20:48,452] {logging_mixin.py:104} INFO - [2021-08-16 16:20:48,451] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-16 16:20:48,455] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:20:48,466] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.396 seconds
[2021-08-16 16:21:19,155] {scheduler_job.py:182} INFO - Started process (PID=4582) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:21:19,156] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 16:21:19,157] {logging_mixin.py:104} INFO - [2021-08-16 16:21:19,157] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:21:19,532] {logging_mixin.py:104} INFO - [2021-08-16 16:21:19,530] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-16 16:21:19,534] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:21:19,546] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.392 seconds
[2021-08-16 16:21:49,570] {scheduler_job.py:182} INFO - Started process (PID=4647) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:21:49,571] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 16:21:49,572] {logging_mixin.py:104} INFO - [2021-08-16 16:21:49,572] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:21:49,940] {logging_mixin.py:104} INFO - [2021-08-16 16:21:49,938] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-16 16:21:49,943] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:21:49,955] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.387 seconds
[2021-08-16 16:22:20,733] {scheduler_job.py:182} INFO - Started process (PID=4712) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:22:20,734] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 16:22:20,735] {logging_mixin.py:104} INFO - [2021-08-16 16:22:20,735] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:22:21,106] {logging_mixin.py:104} INFO - [2021-08-16 16:22:21,105] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-16 16:22:21,110] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:22:21,126] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.394 seconds
[2021-08-16 16:22:51,878] {scheduler_job.py:182} INFO - Started process (PID=4778) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:22:51,879] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 16:22:51,880] {logging_mixin.py:104} INFO - [2021-08-16 16:22:51,879] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:22:52,257] {logging_mixin.py:104} INFO - [2021-08-16 16:22:52,255] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-16 16:22:52,259] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:22:52,271] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.394 seconds
[2021-08-16 16:23:23,066] {scheduler_job.py:182} INFO - Started process (PID=4841) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:23:23,067] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 16:23:23,068] {logging_mixin.py:104} INFO - [2021-08-16 16:23:23,067] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:23:23,439] {logging_mixin.py:104} INFO - [2021-08-16 16:23:23,437] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-16 16:23:23,442] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:23:23,453] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.389 seconds
[2021-08-16 16:23:54,136] {scheduler_job.py:182} INFO - Started process (PID=4911) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:23:54,136] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 16:23:54,137] {logging_mixin.py:104} INFO - [2021-08-16 16:23:54,137] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:23:54,518] {logging_mixin.py:104} INFO - [2021-08-16 16:23:54,516] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-16 16:23:54,520] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:23:54,532] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.398 seconds
[2021-08-16 16:24:25,373] {scheduler_job.py:182} INFO - Started process (PID=4976) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:24:25,373] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 16:24:25,374] {logging_mixin.py:104} INFO - [2021-08-16 16:24:25,374] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:24:25,857] {logging_mixin.py:104} INFO - [2021-08-16 16:24:25,856] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-16 16:24:25,860] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:24:25,871] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.500 seconds
[2021-08-16 16:24:56,532] {scheduler_job.py:182} INFO - Started process (PID=5038) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:24:56,533] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 16:24:56,536] {logging_mixin.py:104} INFO - [2021-08-16 16:24:56,535] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:24:56,925] {logging_mixin.py:104} INFO - [2021-08-16 16:24:56,923] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-16 16:24:56,928] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:24:56,940] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.410 seconds
[2021-08-16 16:25:27,612] {scheduler_job.py:182} INFO - Started process (PID=5101) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:25:27,613] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 16:25:27,614] {logging_mixin.py:104} INFO - [2021-08-16 16:25:27,613] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:25:28,015] {logging_mixin.py:104} INFO - [2021-08-16 16:25:28,014] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-16 16:25:28,019] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:25:28,031] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.422 seconds
[2021-08-16 16:25:58,742] {scheduler_job.py:182} INFO - Started process (PID=5158) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:25:58,742] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 16:25:58,743] {logging_mixin.py:104} INFO - [2021-08-16 16:25:58,743] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:25:59,135] {logging_mixin.py:104} INFO - [2021-08-16 16:25:59,133] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-16 16:25:59,138] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:25:59,148] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.408 seconds
[2021-08-16 16:26:29,882] {scheduler_job.py:182} INFO - Started process (PID=5223) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:26:29,883] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 16:26:29,884] {logging_mixin.py:104} INFO - [2021-08-16 16:26:29,884] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:26:30,274] {logging_mixin.py:104} INFO - [2021-08-16 16:26:30,273] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-16 16:26:30,277] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:26:30,292] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.411 seconds
[2021-08-16 16:27:00,980] {scheduler_job.py:182} INFO - Started process (PID=5287) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:27:00,981] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 16:27:00,982] {logging_mixin.py:104} INFO - [2021-08-16 16:27:00,982] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:27:01,366] {logging_mixin.py:104} INFO - [2021-08-16 16:27:01,365] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-16 16:27:01,369] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:27:01,380] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.402 seconds
[2021-08-16 16:27:32,134] {scheduler_job.py:182} INFO - Started process (PID=5351) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:27:32,135] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 16:27:32,136] {logging_mixin.py:104} INFO - [2021-08-16 16:27:32,136] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:27:32,504] {logging_mixin.py:104} INFO - [2021-08-16 16:27:32,502] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-16 16:27:32,507] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:27:32,518] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.386 seconds
[2021-08-16 16:28:03,250] {scheduler_job.py:182} INFO - Started process (PID=5415) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:28:03,251] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 16:28:03,251] {logging_mixin.py:104} INFO - [2021-08-16 16:28:03,251] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:28:03,631] {logging_mixin.py:104} INFO - [2021-08-16 16:28:03,630] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-16 16:28:03,634] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:28:03,645] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.397 seconds
[2021-08-16 16:28:34,391] {scheduler_job.py:182} INFO - Started process (PID=5483) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:28:34,392] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 16:28:34,393] {logging_mixin.py:104} INFO - [2021-08-16 16:28:34,393] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:28:34,808] {logging_mixin.py:104} INFO - [2021-08-16 16:28:34,806] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-16 16:28:34,810] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:28:34,822] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.432 seconds
[2021-08-16 16:29:05,501] {scheduler_job.py:182} INFO - Started process (PID=5549) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:29:05,502] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 16:29:05,503] {logging_mixin.py:104} INFO - [2021-08-16 16:29:05,503] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:29:05,898] {logging_mixin.py:104} INFO - [2021-08-16 16:29:05,897] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-16 16:29:05,901] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:29:05,912] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.412 seconds
[2021-08-16 16:29:36,586] {scheduler_job.py:182} INFO - Started process (PID=5613) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:29:36,587] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 16:29:36,588] {logging_mixin.py:104} INFO - [2021-08-16 16:29:36,588] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:29:36,980] {logging_mixin.py:104} INFO - [2021-08-16 16:29:36,979] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-16 16:29:36,983] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:29:36,994] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.410 seconds
[2021-08-16 16:30:07,667] {scheduler_job.py:182} INFO - Started process (PID=5676) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:30:07,668] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 16:30:07,668] {logging_mixin.py:104} INFO - [2021-08-16 16:30:07,668] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:30:08,036] {logging_mixin.py:104} INFO - [2021-08-16 16:30:08,035] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-16 16:30:08,039] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:30:08,050] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.385 seconds
[2021-08-16 16:30:38,132] {scheduler_job.py:182} INFO - Started process (PID=5739) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:30:38,133] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 16:30:38,134] {logging_mixin.py:104} INFO - [2021-08-16 16:30:38,134] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:30:38,512] {logging_mixin.py:104} INFO - [2021-08-16 16:30:38,511] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-16 16:30:38,515] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:30:38,527] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.397 seconds
[2021-08-16 16:31:09,192] {scheduler_job.py:182} INFO - Started process (PID=5804) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:31:09,193] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 16:31:09,193] {logging_mixin.py:104} INFO - [2021-08-16 16:31:09,193] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:31:09,574] {logging_mixin.py:104} INFO - [2021-08-16 16:31:09,572] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-16 16:31:09,576] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:31:09,587] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.397 seconds
[2021-08-16 16:31:40,225] {scheduler_job.py:182} INFO - Started process (PID=5866) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:31:40,226] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 16:31:40,227] {logging_mixin.py:104} INFO - [2021-08-16 16:31:40,227] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:31:40,612] {logging_mixin.py:104} INFO - [2021-08-16 16:31:40,611] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-16 16:31:40,615] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:31:40,625] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.403 seconds
[2021-08-16 16:32:10,652] {scheduler_job.py:182} INFO - Started process (PID=5930) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:32:10,653] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 16:32:10,654] {logging_mixin.py:104} INFO - [2021-08-16 16:32:10,654] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:32:11,043] {logging_mixin.py:104} INFO - [2021-08-16 16:32:11,041] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-16 16:32:11,045] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:32:11,056] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.405 seconds
[2021-08-16 16:32:41,093] {scheduler_job.py:182} INFO - Started process (PID=5998) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:32:41,094] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 16:32:41,094] {logging_mixin.py:104} INFO - [2021-08-16 16:32:41,094] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:32:41,487] {logging_mixin.py:104} INFO - [2021-08-16 16:32:41,486] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-16 16:32:41,490] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:32:41,501] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.410 seconds
[2021-08-16 16:33:11,672] {scheduler_job.py:182} INFO - Started process (PID=6068) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:33:11,673] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 16:33:11,674] {logging_mixin.py:104} INFO - [2021-08-16 16:33:11,673] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:33:12,059] {logging_mixin.py:104} INFO - [2021-08-16 16:33:12,057] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-16 16:33:12,062] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:33:12,072] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.402 seconds
[2021-08-16 16:33:42,781] {scheduler_job.py:182} INFO - Started process (PID=6135) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:33:42,782] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 16:33:42,783] {logging_mixin.py:104} INFO - [2021-08-16 16:33:42,783] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:33:43,185] {logging_mixin.py:104} INFO - [2021-08-16 16:33:43,184] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-16 16:33:43,187] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:33:43,198] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.419 seconds
[2021-08-16 16:34:13,917] {scheduler_job.py:182} INFO - Started process (PID=6198) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:34:13,919] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 16:34:13,920] {logging_mixin.py:104} INFO - [2021-08-16 16:34:13,920] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:34:14,447] {logging_mixin.py:104} INFO - [2021-08-16 16:34:14,446] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-16 16:34:14,450] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:34:14,459] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.544 seconds
[2021-08-16 16:34:45,187] {scheduler_job.py:182} INFO - Started process (PID=6252) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:34:45,189] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 16:34:45,189] {logging_mixin.py:104} INFO - [2021-08-16 16:34:45,189] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:34:46,249] {logging_mixin.py:104} INFO - [2021-08-16 16:34:46,247] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-16 16:34:46,253] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:34:46,266] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 1.080 seconds
[2021-08-16 16:35:16,683] {scheduler_job.py:182} INFO - Started process (PID=6320) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:35:16,684] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 16:35:16,684] {logging_mixin.py:104} INFO - [2021-08-16 16:35:16,684] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:35:17,065] {logging_mixin.py:104} INFO - [2021-08-16 16:35:17,064] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-16 16:35:17,069] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:35:17,082] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.401 seconds
[2021-08-16 16:35:47,805] {scheduler_job.py:182} INFO - Started process (PID=6384) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:35:47,813] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 16:35:47,814] {logging_mixin.py:104} INFO - [2021-08-16 16:35:47,814] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:35:48,203] {logging_mixin.py:104} INFO - [2021-08-16 16:35:48,201] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-16 16:35:48,206] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:35:48,217] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.414 seconds
[2021-08-16 16:36:19,348] {scheduler_job.py:182} INFO - Started process (PID=6454) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:36:19,349] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 16:36:19,350] {logging_mixin.py:104} INFO - [2021-08-16 16:36:19,350] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:36:19,754] {logging_mixin.py:104} INFO - [2021-08-16 16:36:19,752] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-16 16:36:19,758] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:36:19,771] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.425 seconds
[2021-08-16 16:36:49,850] {scheduler_job.py:182} INFO - Started process (PID=6521) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:36:49,851] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 16:36:49,851] {logging_mixin.py:104} INFO - [2021-08-16 16:36:49,851] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:36:50,228] {logging_mixin.py:104} INFO - [2021-08-16 16:36:50,227] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-16 16:36:50,231] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:36:50,242] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.395 seconds
[2021-08-16 16:37:21,046] {scheduler_job.py:182} INFO - Started process (PID=6587) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:37:21,049] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 16:37:21,050] {logging_mixin.py:104} INFO - [2021-08-16 16:37:21,050] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:37:21,509] {logging_mixin.py:104} INFO - [2021-08-16 16:37:21,508] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-16 16:37:21,513] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:37:21,531] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.486 seconds
[2021-08-16 16:37:51,597] {scheduler_job.py:182} INFO - Started process (PID=6655) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:37:51,598] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 16:37:51,599] {logging_mixin.py:104} INFO - [2021-08-16 16:37:51,599] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:37:52,815] {logging_mixin.py:104} INFO - [2021-08-16 16:37:52,813] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-16 16:37:52,818] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:37:52,829] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 1.233 seconds
[2021-08-16 16:38:23,478] {scheduler_job.py:182} INFO - Started process (PID=6728) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:38:23,479] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 16:38:23,480] {logging_mixin.py:104} INFO - [2021-08-16 16:38:23,480] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:38:23,913] {logging_mixin.py:104} INFO - [2021-08-16 16:38:23,911] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-16 16:38:23,916] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:38:23,928] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.452 seconds
[2021-08-16 16:38:54,812] {scheduler_job.py:182} INFO - Started process (PID=6791) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:38:54,813] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 16:38:54,813] {logging_mixin.py:104} INFO - [2021-08-16 16:38:54,813] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:38:55,247] {logging_mixin.py:104} INFO - [2021-08-16 16:38:55,245] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-16 16:38:55,250] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:38:55,261] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.450 seconds
[2021-08-16 16:39:26,159] {scheduler_job.py:182} INFO - Started process (PID=6856) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:39:26,160] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 16:39:26,161] {logging_mixin.py:104} INFO - [2021-08-16 16:39:26,161] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:39:26,598] {logging_mixin.py:104} INFO - [2021-08-16 16:39:26,597] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-16 16:39:26,601] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:39:26,612] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.454 seconds
[2021-08-16 16:39:56,685] {scheduler_job.py:182} INFO - Started process (PID=6919) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:39:56,686] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 16:39:56,686] {logging_mixin.py:104} INFO - [2021-08-16 16:39:56,686] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:39:57,156] {logging_mixin.py:104} INFO - [2021-08-16 16:39:57,155] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-16 16:39:57,159] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:39:57,170] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.487 seconds
[2021-08-16 16:40:27,933] {scheduler_job.py:182} INFO - Started process (PID=6984) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:40:27,934] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 16:40:27,934] {logging_mixin.py:104} INFO - [2021-08-16 16:40:27,934] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:40:28,375] {logging_mixin.py:104} INFO - [2021-08-16 16:40:28,373] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-16 16:40:28,379] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:40:28,389] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.458 seconds
[2021-08-16 16:40:59,198] {scheduler_job.py:182} INFO - Started process (PID=7051) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:40:59,198] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 16:40:59,199] {logging_mixin.py:104} INFO - [2021-08-16 16:40:59,199] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:40:59,645] {logging_mixin.py:104} INFO - [2021-08-16 16:40:59,643] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-16 16:40:59,647] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:40:59,658] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.462 seconds
[2021-08-16 16:41:30,480] {scheduler_job.py:182} INFO - Started process (PID=7117) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:41:30,481] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 16:41:30,481] {logging_mixin.py:104} INFO - [2021-08-16 16:41:30,481] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:41:30,909] {logging_mixin.py:104} INFO - [2021-08-16 16:41:30,908] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-16 16:41:30,912] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:41:30,922] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.444 seconds
[2021-08-16 16:42:01,820] {scheduler_job.py:182} INFO - Started process (PID=7183) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:42:01,822] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 16:42:01,822] {logging_mixin.py:104} INFO - [2021-08-16 16:42:01,822] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:42:09,302] {logging_mixin.py:104} INFO - [2021-08-16 16:42:09,301] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-16 16:42:09,307] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:42:09,323] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 7.505 seconds
[2021-08-16 16:42:40,242] {scheduler_job.py:182} INFO - Started process (PID=7259) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:42:40,243] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 16:42:40,243] {logging_mixin.py:104} INFO - [2021-08-16 16:42:40,243] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:42:40,690] {logging_mixin.py:104} INFO - [2021-08-16 16:42:40,688] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-16 16:42:40,692] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:42:40,704] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.464 seconds
[2021-08-16 16:43:10,774] {scheduler_job.py:182} INFO - Started process (PID=7311) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:43:10,775] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 16:43:10,776] {logging_mixin.py:104} INFO - [2021-08-16 16:43:10,776] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:43:11,253] {logging_mixin.py:104} INFO - [2021-08-16 16:43:11,252] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-16 16:43:11,255] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:43:11,265] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.492 seconds
[2021-08-16 16:43:42,240] {scheduler_job.py:182} INFO - Started process (PID=7373) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:43:42,241] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 16:43:42,241] {logging_mixin.py:104} INFO - [2021-08-16 16:43:42,241] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:43:42,670] {logging_mixin.py:104} INFO - [2021-08-16 16:43:42,668] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-16 16:43:42,672] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:43:42,682] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.444 seconds
[2021-08-16 16:44:12,737] {scheduler_job.py:182} INFO - Started process (PID=7437) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:44:12,738] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 16:44:12,739] {logging_mixin.py:104} INFO - [2021-08-16 16:44:12,739] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:44:13,172] {logging_mixin.py:104} INFO - [2021-08-16 16:44:13,171] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-16 16:44:13,175] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:44:13,186] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.451 seconds
[2021-08-16 16:44:43,385] {scheduler_job.py:182} INFO - Started process (PID=7499) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:44:43,387] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 16:44:43,387] {logging_mixin.py:104} INFO - [2021-08-16 16:44:43,387] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:44:43,809] {logging_mixin.py:104} INFO - [2021-08-16 16:44:43,807] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-16 16:44:43,811] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:44:43,821] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.437 seconds
[2021-08-16 16:45:14,170] {scheduler_job.py:182} INFO - Started process (PID=7568) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:45:14,171] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 16:45:14,172] {logging_mixin.py:104} INFO - [2021-08-16 16:45:14,171] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:45:14,597] {logging_mixin.py:104} INFO - [2021-08-16 16:45:14,596] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-16 16:45:14,600] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:45:14,611] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.443 seconds
[2021-08-16 16:45:45,563] {scheduler_job.py:182} INFO - Started process (PID=7637) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:45:45,564] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 16:45:45,565] {logging_mixin.py:104} INFO - [2021-08-16 16:45:45,565] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:45:46,000] {logging_mixin.py:104} INFO - [2021-08-16 16:45:45,998] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-16 16:45:46,003] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:45:46,014] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.452 seconds
[2021-08-16 16:46:16,079] {scheduler_job.py:182} INFO - Started process (PID=7702) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:46:16,080] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 16:46:16,081] {logging_mixin.py:104} INFO - [2021-08-16 16:46:16,081] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:46:16,516] {logging_mixin.py:104} INFO - [2021-08-16 16:46:16,514] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-16 16:46:16,518] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:46:16,528] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.451 seconds
[2021-08-16 16:46:47,412] {scheduler_job.py:182} INFO - Started process (PID=7769) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:46:47,413] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 16:46:47,413] {logging_mixin.py:104} INFO - [2021-08-16 16:46:47,413] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:46:47,847] {logging_mixin.py:104} INFO - [2021-08-16 16:46:47,846] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-16 16:46:47,850] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:46:47,862] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.452 seconds
[2021-08-16 16:47:18,768] {scheduler_job.py:182} INFO - Started process (PID=7835) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:47:18,769] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 16:47:18,770] {logging_mixin.py:104} INFO - [2021-08-16 16:47:18,770] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:47:19,201] {logging_mixin.py:104} INFO - [2021-08-16 16:47:19,200] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-16 16:47:19,204] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:47:19,216] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.449 seconds
[2021-08-16 16:47:49,260] {scheduler_job.py:182} INFO - Started process (PID=7903) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:47:49,262] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 16:47:49,262] {logging_mixin.py:104} INFO - [2021-08-16 16:47:49,262] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:47:49,702] {logging_mixin.py:104} INFO - [2021-08-16 16:47:49,700] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-16 16:47:49,704] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:47:49,716] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.457 seconds
[2021-08-16 16:48:20,634] {scheduler_job.py:182} INFO - Started process (PID=7973) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:48:20,635] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 16:48:20,636] {logging_mixin.py:104} INFO - [2021-08-16 16:48:20,635] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:48:21,055] {logging_mixin.py:104} INFO - [2021-08-16 16:48:21,054] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-16 16:48:21,058] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:48:21,068] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.436 seconds
[2021-08-16 16:48:51,938] {scheduler_job.py:182} INFO - Started process (PID=8037) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:48:51,939] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 16:48:51,940] {logging_mixin.py:104} INFO - [2021-08-16 16:48:51,940] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:48:52,393] {logging_mixin.py:104} INFO - [2021-08-16 16:48:52,391] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-16 16:48:52,395] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:48:52,407] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.471 seconds
[2021-08-16 16:49:22,434] {scheduler_job.py:182} INFO - Started process (PID=8100) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:49:22,434] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 16:49:22,435] {logging_mixin.py:104} INFO - [2021-08-16 16:49:22,435] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:49:22,846] {logging_mixin.py:104} INFO - [2021-08-16 16:49:22,844] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-16 16:49:22,849] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:49:22,860] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.429 seconds
[2021-08-16 16:49:53,743] {scheduler_job.py:182} INFO - Started process (PID=8165) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:49:53,745] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 16:49:53,745] {logging_mixin.py:104} INFO - [2021-08-16 16:49:53,745] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:49:54,187] {logging_mixin.py:104} INFO - [2021-08-16 16:49:54,185] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-16 16:49:54,189] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:49:54,199] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.458 seconds
[2021-08-16 16:50:24,245] {scheduler_job.py:182} INFO - Started process (PID=8232) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:50:24,246] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 16:50:24,247] {logging_mixin.py:104} INFO - [2021-08-16 16:50:24,247] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:50:24,675] {logging_mixin.py:104} INFO - [2021-08-16 16:50:24,674] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-16 16:50:24,678] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:50:24,697] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.453 seconds
[2021-08-16 16:50:55,583] {scheduler_job.py:182} INFO - Started process (PID=8298) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:50:55,585] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 16:50:55,585] {logging_mixin.py:104} INFO - [2021-08-16 16:50:55,585] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:50:56,027] {logging_mixin.py:104} INFO - [2021-08-16 16:50:56,025] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-16 16:50:56,030] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:50:56,041] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.460 seconds
[2021-08-16 16:51:27,045] {scheduler_job.py:182} INFO - Started process (PID=8363) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:51:27,046] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 16:51:27,046] {logging_mixin.py:104} INFO - [2021-08-16 16:51:27,046] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:51:27,497] {logging_mixin.py:104} INFO - [2021-08-16 16:51:27,495] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-16 16:51:27,499] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:51:27,510] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.467 seconds
[2021-08-16 16:51:57,569] {scheduler_job.py:182} INFO - Started process (PID=8426) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:51:57,570] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 16:51:57,571] {logging_mixin.py:104} INFO - [2021-08-16 16:51:57,571] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:51:58,078] {logging_mixin.py:104} INFO - [2021-08-16 16:51:58,076] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-16 16:51:58,081] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:51:58,091] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.524 seconds
[2021-08-16 16:52:28,139] {scheduler_job.py:182} INFO - Started process (PID=8484) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:52:28,140] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 16:52:28,141] {logging_mixin.py:104} INFO - [2021-08-16 16:52:28,141] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:52:28,591] {logging_mixin.py:104} INFO - [2021-08-16 16:52:28,590] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-16 16:52:28,594] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:52:28,610] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.473 seconds
[2021-08-16 16:52:58,657] {scheduler_job.py:182} INFO - Started process (PID=8552) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:52:58,658] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 16:52:58,658] {logging_mixin.py:104} INFO - [2021-08-16 16:52:58,658] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:52:59,109] {logging_mixin.py:104} INFO - [2021-08-16 16:52:59,108] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-16 16:52:59,112] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:52:59,123] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.468 seconds
[2021-08-16 16:53:30,040] {scheduler_job.py:182} INFO - Started process (PID=8615) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:53:30,041] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 16:53:30,042] {logging_mixin.py:104} INFO - [2021-08-16 16:53:30,042] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:53:30,502] {logging_mixin.py:104} INFO - [2021-08-16 16:53:30,501] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-16 16:53:30,505] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:53:30,519] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.481 seconds
[2021-08-16 16:54:01,446] {scheduler_job.py:182} INFO - Started process (PID=8682) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:54:01,447] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 16:54:01,448] {logging_mixin.py:104} INFO - [2021-08-16 16:54:01,448] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:54:01,927] {logging_mixin.py:104} INFO - [2021-08-16 16:54:01,926] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-16 16:54:01,930] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:54:01,941] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.497 seconds
[2021-08-16 16:54:32,798] {scheduler_job.py:182} INFO - Started process (PID=8748) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:54:32,798] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 16:54:32,799] {logging_mixin.py:104} INFO - [2021-08-16 16:54:32,799] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:54:33,226] {logging_mixin.py:104} INFO - [2021-08-16 16:54:33,225] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-16 16:54:33,229] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:54:33,240] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.444 seconds
[2021-08-16 16:55:03,363] {scheduler_job.py:182} INFO - Started process (PID=8811) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:55:03,365] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 16:55:03,365] {logging_mixin.py:104} INFO - [2021-08-16 16:55:03,365] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:55:03,800] {logging_mixin.py:104} INFO - [2021-08-16 16:55:03,799] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-16 16:55:03,803] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:55:03,813] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.452 seconds
[2021-08-16 16:55:34,904] {scheduler_job.py:182} INFO - Started process (PID=8889) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:55:34,905] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 16:55:34,906] {logging_mixin.py:104} INFO - [2021-08-16 16:55:34,905] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:55:35,404] {logging_mixin.py:104} INFO - [2021-08-16 16:55:35,402] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-16 16:55:35,406] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:55:35,418] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.516 seconds
[2021-08-16 16:56:06,500] {scheduler_job.py:182} INFO - Started process (PID=8959) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:56:06,501] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 16:56:06,502] {logging_mixin.py:104} INFO - [2021-08-16 16:56:06,502] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:56:07,140] {logging_mixin.py:104} INFO - [2021-08-16 16:56:07,138] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-16 16:56:07,143] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:56:07,155] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.657 seconds
[2021-08-16 16:56:37,231] {scheduler_job.py:182} INFO - Started process (PID=9024) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:56:37,232] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 16:56:37,233] {logging_mixin.py:104} INFO - [2021-08-16 16:56:37,233] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:56:37,826] {logging_mixin.py:104} INFO - [2021-08-16 16:56:37,825] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-16 16:56:37,829] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:56:37,839] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.610 seconds
[2021-08-16 16:57:07,977] {scheduler_job.py:182} INFO - Started process (PID=9097) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:57:07,980] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 16:57:07,980] {logging_mixin.py:104} INFO - [2021-08-16 16:57:07,980] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:57:08,501] {logging_mixin.py:104} INFO - [2021-08-16 16:57:08,499] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-16 16:57:08,504] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:57:08,515] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.541 seconds
[2021-08-16 16:57:39,297] {scheduler_job.py:182} INFO - Started process (PID=9162) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:57:39,297] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 16:57:39,298] {logging_mixin.py:104} INFO - [2021-08-16 16:57:39,298] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:57:39,763] {logging_mixin.py:104} INFO - [2021-08-16 16:57:39,762] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-16 16:57:39,766] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:57:39,777] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.482 seconds
[2021-08-16 16:58:10,446] {scheduler_job.py:182} INFO - Started process (PID=9226) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:58:10,447] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 16:58:10,448] {logging_mixin.py:104} INFO - [2021-08-16 16:58:10,448] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:58:10,922] {logging_mixin.py:104} INFO - [2021-08-16 16:58:10,921] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-16 16:58:10,925] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:58:10,935] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.491 seconds
[2021-08-16 16:58:41,494] {scheduler_job.py:182} INFO - Started process (PID=9291) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:58:41,495] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 16:58:41,496] {logging_mixin.py:104} INFO - [2021-08-16 16:58:41,495] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:58:42,455] {logging_mixin.py:104} INFO - [2021-08-16 16:58:42,453] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-16 16:58:42,457] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:58:42,467] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.975 seconds
[2021-08-16 16:59:12,628] {scheduler_job.py:182} INFO - Started process (PID=9357) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:59:12,630] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 16:59:12,631] {logging_mixin.py:104} INFO - [2021-08-16 16:59:12,631] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:59:13,575] {logging_mixin.py:104} INFO - [2021-08-16 16:59:13,573] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-16 16:59:13,577] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:59:13,588] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.962 seconds
[2021-08-16 16:59:43,738] {scheduler_job.py:182} INFO - Started process (PID=9424) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:59:43,739] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 16:59:43,740] {logging_mixin.py:104} INFO - [2021-08-16 16:59:43,740] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:59:44,168] {logging_mixin.py:104} INFO - [2021-08-16 16:59:44,167] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-16 16:59:44,172] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 16:59:44,183] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.447 seconds
[2021-08-16 17:00:14,823] {scheduler_job.py:182} INFO - Started process (PID=9487) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 17:00:14,824] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 17:00:14,825] {logging_mixin.py:104} INFO - [2021-08-16 17:00:14,825] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 17:00:15,257] {logging_mixin.py:104} INFO - [2021-08-16 17:00:15,255] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-16 17:00:15,259] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 17:00:15,270] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.449 seconds
[2021-08-16 17:00:46,178] {scheduler_job.py:182} INFO - Started process (PID=9550) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 17:00:46,179] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 17:00:46,180] {logging_mixin.py:104} INFO - [2021-08-16 17:00:46,180] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 17:00:46,657] {logging_mixin.py:104} INFO - [2021-08-16 17:00:46,655] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-16 17:00:46,659] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 17:00:46,670] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.494 seconds
[2021-08-16 17:01:16,717] {scheduler_job.py:182} INFO - Started process (PID=9614) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 17:01:16,718] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 17:01:16,719] {logging_mixin.py:104} INFO - [2021-08-16 17:01:16,718] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 17:01:17,179] {logging_mixin.py:104} INFO - [2021-08-16 17:01:17,177] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-16 17:01:17,181] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 17:01:17,192] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.477 seconds
[2021-08-16 17:01:47,231] {scheduler_job.py:182} INFO - Started process (PID=9679) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 17:01:47,231] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 17:01:47,232] {logging_mixin.py:104} INFO - [2021-08-16 17:01:47,232] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 17:01:47,716] {logging_mixin.py:104} INFO - [2021-08-16 17:01:47,714] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-16 17:01:47,720] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 17:01:47,730] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.501 seconds
[2021-08-16 17:02:17,766] {scheduler_job.py:182} INFO - Started process (PID=9732) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 17:02:17,772] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 17:02:17,773] {logging_mixin.py:104} INFO - [2021-08-16 17:02:17,773] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 17:02:18,265] {logging_mixin.py:104} INFO - [2021-08-16 17:02:18,264] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-16 17:02:18,268] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 17:02:18,278] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.514 seconds
[2021-08-16 17:02:48,379] {scheduler_job.py:182} INFO - Started process (PID=9795) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 17:02:48,380] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 17:02:48,381] {logging_mixin.py:104} INFO - [2021-08-16 17:02:48,381] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 17:02:48,832] {logging_mixin.py:104} INFO - [2021-08-16 17:02:48,831] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-16 17:02:48,835] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 17:02:48,853] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.476 seconds
[2021-08-16 17:03:19,515] {scheduler_job.py:182} INFO - Started process (PID=9860) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 17:03:19,516] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 17:03:19,517] {logging_mixin.py:104} INFO - [2021-08-16 17:03:19,517] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 17:03:19,942] {logging_mixin.py:104} INFO - [2021-08-16 17:03:19,940] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-16 17:03:19,944] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 17:03:19,956] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.442 seconds
[2021-08-16 17:03:50,675] {scheduler_job.py:182} INFO - Started process (PID=9922) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 17:03:50,676] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 17:03:50,676] {logging_mixin.py:104} INFO - [2021-08-16 17:03:50,676] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 17:03:51,117] {logging_mixin.py:104} INFO - [2021-08-16 17:03:51,116] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-16 17:03:51,120] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 17:03:51,132] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.459 seconds
[2021-08-16 17:04:21,787] {scheduler_job.py:182} INFO - Started process (PID=9987) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 17:04:21,788] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 17:04:21,789] {logging_mixin.py:104} INFO - [2021-08-16 17:04:21,789] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 17:04:22,204] {logging_mixin.py:104} INFO - [2021-08-16 17:04:22,202] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-16 17:04:22,206] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 17:04:22,219] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.433 seconds
[2021-08-16 17:04:52,873] {scheduler_job.py:182} INFO - Started process (PID=10052) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 17:04:52,874] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 17:04:52,875] {logging_mixin.py:104} INFO - [2021-08-16 17:04:52,875] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 17:04:53,302] {logging_mixin.py:104} INFO - [2021-08-16 17:04:53,300] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-16 17:04:53,304] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 17:04:53,316] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.445 seconds
[2021-08-16 17:05:24,017] {scheduler_job.py:182} INFO - Started process (PID=10115) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 17:05:24,018] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 17:05:24,019] {logging_mixin.py:104} INFO - [2021-08-16 17:05:24,019] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 17:05:24,464] {logging_mixin.py:104} INFO - [2021-08-16 17:05:24,463] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-16 17:05:24,467] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 17:05:24,479] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.463 seconds
[2021-08-16 17:05:55,115] {scheduler_job.py:182} INFO - Started process (PID=10179) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 17:05:55,116] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 17:05:55,116] {logging_mixin.py:104} INFO - [2021-08-16 17:05:55,116] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 17:05:55,557] {logging_mixin.py:104} INFO - [2021-08-16 17:05:55,556] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-16 17:05:55,559] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 17:05:55,572] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.458 seconds
[2021-08-16 17:06:26,234] {scheduler_job.py:182} INFO - Started process (PID=10243) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 17:06:26,235] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 17:06:26,236] {logging_mixin.py:104} INFO - [2021-08-16 17:06:26,236] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 17:06:26,698] {logging_mixin.py:104} INFO - [2021-08-16 17:06:26,697] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-16 17:06:26,701] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 17:06:26,713] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.481 seconds
[2021-08-16 17:06:57,329] {scheduler_job.py:182} INFO - Started process (PID=10307) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 17:06:57,330] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 17:06:57,331] {logging_mixin.py:104} INFO - [2021-08-16 17:06:57,330] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 17:06:57,753] {logging_mixin.py:104} INFO - [2021-08-16 17:06:57,751] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-16 17:06:57,755] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 17:06:57,766] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.439 seconds
[2021-08-16 17:07:28,458] {scheduler_job.py:182} INFO - Started process (PID=10369) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 17:07:28,459] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 17:07:28,460] {logging_mixin.py:104} INFO - [2021-08-16 17:07:28,459] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 17:07:28,899] {logging_mixin.py:104} INFO - [2021-08-16 17:07:28,897] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-16 17:07:28,903] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 17:07:28,918] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.462 seconds
[2021-08-16 17:07:59,632] {scheduler_job.py:182} INFO - Started process (PID=10433) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 17:07:59,633] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 17:07:59,634] {logging_mixin.py:104} INFO - [2021-08-16 17:07:59,634] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 17:08:00,076] {logging_mixin.py:104} INFO - [2021-08-16 17:08:00,074] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-16 17:08:00,079] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 17:08:00,089] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.459 seconds
[2021-08-16 17:08:30,671] {scheduler_job.py:182} INFO - Started process (PID=10497) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 17:08:30,672] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 17:08:30,673] {logging_mixin.py:104} INFO - [2021-08-16 17:08:30,673] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 17:08:31,101] {logging_mixin.py:104} INFO - [2021-08-16 17:08:31,099] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-16 17:08:31,103] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 17:08:31,113] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.444 seconds
[2021-08-16 17:09:01,802] {scheduler_job.py:182} INFO - Started process (PID=10562) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 17:09:01,803] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 17:09:01,803] {logging_mixin.py:104} INFO - [2021-08-16 17:09:01,803] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 17:09:02,238] {logging_mixin.py:104} INFO - [2021-08-16 17:09:02,237] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-16 17:09:02,241] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 17:09:02,257] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.457 seconds
[2021-08-16 17:09:32,906] {scheduler_job.py:182} INFO - Started process (PID=10628) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 17:09:32,907] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 17:09:32,907] {logging_mixin.py:104} INFO - [2021-08-16 17:09:32,907] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 17:09:33,343] {logging_mixin.py:104} INFO - [2021-08-16 17:09:33,341] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-16 17:09:33,345] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 17:09:33,357] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.453 seconds
[2021-08-16 17:10:04,107] {scheduler_job.py:182} INFO - Started process (PID=10693) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 17:10:04,108] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 17:10:04,109] {logging_mixin.py:104} INFO - [2021-08-16 17:10:04,109] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 17:10:04,525] {logging_mixin.py:104} INFO - [2021-08-16 17:10:04,524] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-16 17:10:04,528] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 17:10:04,538] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.434 seconds
[2021-08-16 17:10:35,256] {scheduler_job.py:182} INFO - Started process (PID=10755) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 17:10:35,257] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 17:10:35,258] {logging_mixin.py:104} INFO - [2021-08-16 17:10:35,258] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 17:10:35,689] {logging_mixin.py:104} INFO - [2021-08-16 17:10:35,687] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-16 17:10:35,691] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 17:10:35,710] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.455 seconds
[2021-08-16 17:11:06,513] {scheduler_job.py:182} INFO - Started process (PID=10821) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 17:11:06,514] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 17:11:06,515] {logging_mixin.py:104} INFO - [2021-08-16 17:11:06,515] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 17:11:06,974] {logging_mixin.py:104} INFO - [2021-08-16 17:11:06,972] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-16 17:11:06,976] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 17:11:06,987] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.476 seconds
[2021-08-16 17:11:37,506] {scheduler_job.py:182} INFO - Started process (PID=10883) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 17:11:37,507] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 17:11:37,507] {logging_mixin.py:104} INFO - [2021-08-16 17:11:37,507] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 17:11:37,946] {logging_mixin.py:104} INFO - [2021-08-16 17:11:37,945] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-16 17:11:37,949] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 17:11:37,959] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.455 seconds
[2021-08-16 17:12:08,000] {scheduler_job.py:182} INFO - Started process (PID=10947) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 17:12:08,001] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 17:12:08,002] {logging_mixin.py:104} INFO - [2021-08-16 17:12:08,001] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 17:12:08,415] {logging_mixin.py:104} INFO - [2021-08-16 17:12:08,414] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-16 17:12:08,418] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 17:12:08,436] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.438 seconds
[2021-08-16 17:12:39,386] {scheduler_job.py:182} INFO - Started process (PID=11013) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 17:12:39,387] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 17:12:39,389] {logging_mixin.py:104} INFO - [2021-08-16 17:12:39,389] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 17:12:39,859] {logging_mixin.py:104} INFO - [2021-08-16 17:12:39,858] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-16 17:12:39,862] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 17:12:39,873] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.488 seconds
[2021-08-16 17:13:10,846] {scheduler_job.py:182} INFO - Started process (PID=11079) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 17:13:10,846] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 17:13:10,847] {logging_mixin.py:104} INFO - [2021-08-16 17:13:10,847] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 17:13:11,278] {logging_mixin.py:104} INFO - [2021-08-16 17:13:11,277] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-16 17:13:11,281] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 17:13:11,291] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.448 seconds
[2021-08-16 17:13:42,266] {scheduler_job.py:182} INFO - Started process (PID=11145) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 17:13:42,267] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 17:13:42,268] {logging_mixin.py:104} INFO - [2021-08-16 17:13:42,267] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 17:13:42,698] {logging_mixin.py:104} INFO - [2021-08-16 17:13:42,697] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-16 17:13:42,701] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 17:13:42,711] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.447 seconds
[2021-08-16 17:14:13,685] {scheduler_job.py:182} INFO - Started process (PID=11211) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 17:14:13,686] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 17:14:13,686] {logging_mixin.py:104} INFO - [2021-08-16 17:14:13,686] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 17:14:14,100] {logging_mixin.py:104} INFO - [2021-08-16 17:14:14,099] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-16 17:14:14,103] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 17:14:14,114] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.431 seconds
[2021-08-16 17:14:44,164] {scheduler_job.py:182} INFO - Started process (PID=11263) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 17:14:44,164] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 17:14:44,165] {logging_mixin.py:104} INFO - [2021-08-16 17:14:44,165] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 17:14:44,610] {logging_mixin.py:104} INFO - [2021-08-16 17:14:44,609] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-16 17:14:44,612] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 17:14:44,622] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.460 seconds
[2021-08-16 17:15:14,922] {scheduler_job.py:182} INFO - Started process (PID=11329) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 17:15:14,923] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 17:15:14,924] {logging_mixin.py:104} INFO - [2021-08-16 17:15:14,923] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 17:15:15,376] {logging_mixin.py:104} INFO - [2021-08-16 17:15:15,374] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-16 17:15:15,378] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 17:15:15,388] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.476 seconds
[2021-08-16 17:15:45,421] {scheduler_job.py:182} INFO - Started process (PID=11400) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 17:15:45,422] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 17:15:45,422] {logging_mixin.py:104} INFO - [2021-08-16 17:15:45,422] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 17:15:45,850] {logging_mixin.py:104} INFO - [2021-08-16 17:15:45,849] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-16 17:15:45,852] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 17:15:45,870] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.451 seconds
[2021-08-16 17:16:16,526] {scheduler_job.py:182} INFO - Started process (PID=11462) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 17:16:16,527] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 17:16:16,527] {logging_mixin.py:104} INFO - [2021-08-16 17:16:16,527] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 17:16:16,979] {logging_mixin.py:104} INFO - [2021-08-16 17:16:16,977] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-16 17:16:16,981] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 17:16:16,991] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.467 seconds
[2021-08-16 17:16:47,945] {scheduler_job.py:182} INFO - Started process (PID=11543) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 17:16:47,946] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 17:16:47,947] {logging_mixin.py:104} INFO - [2021-08-16 17:16:47,947] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 17:16:48,429] {logging_mixin.py:104} INFO - [2021-08-16 17:16:48,427] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-16 17:16:48,431] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 17:16:48,441] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.498 seconds
[2021-08-16 17:17:19,255] {scheduler_job.py:182} INFO - Started process (PID=11614) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 17:17:19,256] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 17:17:19,257] {logging_mixin.py:104} INFO - [2021-08-16 17:17:19,257] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 17:17:19,683] {logging_mixin.py:104} INFO - [2021-08-16 17:17:19,680] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-16 17:17:19,688] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 17:17:19,699] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.445 seconds
[2021-08-16 17:17:50,673] {scheduler_job.py:182} INFO - Started process (PID=11683) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 17:17:50,674] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 17:17:50,675] {logging_mixin.py:104} INFO - [2021-08-16 17:17:50,675] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 17:17:51,119] {logging_mixin.py:104} INFO - [2021-08-16 17:17:51,118] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-16 17:17:51,122] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 17:17:51,133] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.462 seconds
[2021-08-16 17:18:22,105] {scheduler_job.py:182} INFO - Started process (PID=11748) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 17:18:22,106] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 17:18:22,107] {logging_mixin.py:104} INFO - [2021-08-16 17:18:22,107] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 17:18:22,532] {logging_mixin.py:104} INFO - [2021-08-16 17:18:22,531] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-16 17:18:22,535] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 17:18:22,553] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.449 seconds
[2021-08-16 17:18:53,490] {scheduler_job.py:182} INFO - Started process (PID=11812) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 17:18:53,491] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 17:18:53,492] {logging_mixin.py:104} INFO - [2021-08-16 17:18:53,492] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 17:18:53,914] {logging_mixin.py:104} INFO - [2021-08-16 17:18:53,912] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-16 17:18:53,916] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 17:18:53,927] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.439 seconds
[2021-08-16 17:19:24,838] {scheduler_job.py:182} INFO - Started process (PID=11876) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 17:19:24,839] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 17:19:24,840] {logging_mixin.py:104} INFO - [2021-08-16 17:19:24,840] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 17:19:25,426] {logging_mixin.py:104} INFO - [2021-08-16 17:19:25,425] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-16 17:19:25,429] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 17:19:25,439] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.603 seconds
[2021-08-16 17:19:56,384] {scheduler_job.py:182} INFO - Started process (PID=11942) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 17:19:56,385] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 17:19:56,386] {logging_mixin.py:104} INFO - [2021-08-16 17:19:56,386] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 17:19:56,814] {logging_mixin.py:104} INFO - [2021-08-16 17:19:56,812] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-16 17:19:56,816] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 17:19:56,827] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.444 seconds
[2021-08-16 17:20:27,765] {scheduler_job.py:182} INFO - Started process (PID=12005) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 17:20:27,766] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 17:20:27,767] {logging_mixin.py:104} INFO - [2021-08-16 17:20:27,767] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 17:20:28,188] {logging_mixin.py:104} INFO - [2021-08-16 17:20:28,186] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-16 17:20:28,191] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 17:20:28,203] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.439 seconds
[2021-08-16 17:20:59,149] {scheduler_job.py:182} INFO - Started process (PID=12071) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 17:20:59,150] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 17:20:59,150] {logging_mixin.py:104} INFO - [2021-08-16 17:20:59,150] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 17:20:59,579] {logging_mixin.py:104} INFO - [2021-08-16 17:20:59,578] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-16 17:20:59,582] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 17:20:59,593] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.446 seconds
[2021-08-16 17:21:30,552] {scheduler_job.py:182} INFO - Started process (PID=12137) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 17:21:30,553] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 17:21:30,554] {logging_mixin.py:104} INFO - [2021-08-16 17:21:30,554] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 17:21:31,012] {logging_mixin.py:104} INFO - [2021-08-16 17:21:31,010] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-16 17:21:31,014] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 17:21:31,033] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.482 seconds
[2021-08-16 17:22:01,987] {scheduler_job.py:182} INFO - Started process (PID=12205) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 17:22:01,988] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 17:22:01,988] {logging_mixin.py:104} INFO - [2021-08-16 17:22:01,988] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 17:22:02,409] {logging_mixin.py:104} INFO - [2021-08-16 17:22:02,408] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-16 17:22:02,412] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 17:22:02,422] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.437 seconds
[2021-08-16 17:22:33,372] {scheduler_job.py:182} INFO - Started process (PID=12273) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 17:22:33,373] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 17:22:33,373] {logging_mixin.py:104} INFO - [2021-08-16 17:22:33,373] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 17:22:33,854] {logging_mixin.py:104} INFO - [2021-08-16 17:22:33,853] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-16 17:22:33,857] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 17:22:33,868] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.499 seconds
[2021-08-16 17:23:04,569] {scheduler_job.py:182} INFO - Started process (PID=12335) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 17:23:04,570] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 17:23:04,571] {logging_mixin.py:104} INFO - [2021-08-16 17:23:04,571] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 17:23:04,999] {logging_mixin.py:104} INFO - [2021-08-16 17:23:04,998] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-16 17:23:05,002] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 17:23:05,012] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.444 seconds
[2021-08-16 17:23:35,667] {scheduler_job.py:182} INFO - Started process (PID=12397) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 17:23:35,668] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 17:23:35,669] {logging_mixin.py:104} INFO - [2021-08-16 17:23:35,669] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 17:23:36,117] {logging_mixin.py:104} INFO - [2021-08-16 17:23:36,103] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-16 17:23:36,119] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 17:23:36,129] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.464 seconds
[2021-08-16 17:24:06,805] {scheduler_job.py:182} INFO - Started process (PID=12463) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 17:24:06,805] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 17:24:06,806] {logging_mixin.py:104} INFO - [2021-08-16 17:24:06,806] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 17:24:07,268] {logging_mixin.py:104} INFO - [2021-08-16 17:24:07,266] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-16 17:24:07,270] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 17:24:07,280] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.478 seconds
[2021-08-16 17:24:37,959] {scheduler_job.py:182} INFO - Started process (PID=12530) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 17:24:37,960] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 17:24:37,963] {logging_mixin.py:104} INFO - [2021-08-16 17:24:37,963] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 17:24:38,398] {logging_mixin.py:104} INFO - [2021-08-16 17:24:38,396] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-16 17:24:38,401] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 17:24:38,423] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.466 seconds
[2021-08-16 17:25:09,208] {scheduler_job.py:182} INFO - Started process (PID=12596) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 17:25:09,209] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 17:25:09,210] {logging_mixin.py:104} INFO - [2021-08-16 17:25:09,210] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 17:25:09,675] {logging_mixin.py:104} INFO - [2021-08-16 17:25:09,673] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-16 17:25:09,678] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 17:25:09,693] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.487 seconds
[2021-08-16 17:25:40,202] {scheduler_job.py:182} INFO - Started process (PID=12663) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 17:25:40,203] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 17:25:40,204] {logging_mixin.py:104} INFO - [2021-08-16 17:25:40,203] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 17:25:41,120] {logging_mixin.py:104} INFO - [2021-08-16 17:25:41,119] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-16 17:25:41,123] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 17:25:41,135] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.935 seconds
[2021-08-16 17:26:11,229] {scheduler_job.py:182} INFO - Started process (PID=12728) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 17:26:11,229] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 17:26:11,230] {logging_mixin.py:104} INFO - [2021-08-16 17:26:11,230] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 17:26:11,699] {logging_mixin.py:104} INFO - [2021-08-16 17:26:11,697] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-16 17:26:11,702] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 17:26:11,720] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.493 seconds
[2021-08-16 17:26:42,182] {scheduler_job.py:182} INFO - Started process (PID=12792) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 17:26:42,183] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 17:26:42,184] {logging_mixin.py:104} INFO - [2021-08-16 17:26:42,184] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 17:26:42,625] {logging_mixin.py:104} INFO - [2021-08-16 17:26:42,624] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-16 17:26:42,628] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 17:26:42,640] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.459 seconds
[2021-08-16 17:27:12,887] {scheduler_job.py:182} INFO - Started process (PID=12857) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 17:27:12,888] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 17:27:12,889] {logging_mixin.py:104} INFO - [2021-08-16 17:27:12,889] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 17:27:13,418] {logging_mixin.py:104} INFO - [2021-08-16 17:27:13,417] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-16 17:27:13,421] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 17:27:13,431] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.548 seconds
[2021-08-16 17:27:43,727] {scheduler_job.py:182} INFO - Started process (PID=12923) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 17:27:43,728] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 17:27:43,729] {logging_mixin.py:104} INFO - [2021-08-16 17:27:43,729] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 17:27:44,144] {logging_mixin.py:104} INFO - [2021-08-16 17:27:44,142] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-16 17:27:44,146] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 17:27:44,157] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.431 seconds
[2021-08-16 17:28:14,189] {scheduler_job.py:182} INFO - Started process (PID=12985) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 17:28:14,190] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 17:28:14,191] {logging_mixin.py:104} INFO - [2021-08-16 17:28:14,191] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 17:28:14,637] {logging_mixin.py:104} INFO - [2021-08-16 17:28:14,636] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-16 17:28:14,640] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 17:28:14,650] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.463 seconds
[2021-08-16 17:28:45,282] {scheduler_job.py:182} INFO - Started process (PID=13046) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 17:28:45,283] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 17:28:45,283] {logging_mixin.py:104} INFO - [2021-08-16 17:28:45,283] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 17:28:45,696] {logging_mixin.py:104} INFO - [2021-08-16 17:28:45,695] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-16 17:28:45,698] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 17:28:45,708] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.428 seconds
[2021-08-16 17:29:15,777] {scheduler_job.py:182} INFO - Started process (PID=13105) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 17:29:15,778] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 17:29:15,778] {logging_mixin.py:104} INFO - [2021-08-16 17:29:15,778] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 17:29:16,231] {logging_mixin.py:104} INFO - [2021-08-16 17:29:16,230] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-16 17:29:16,234] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 17:29:16,243] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.468 seconds
[2021-08-16 17:29:46,359] {scheduler_job.py:182} INFO - Started process (PID=13170) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 17:29:46,360] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 17:29:46,362] {logging_mixin.py:104} INFO - [2021-08-16 17:29:46,362] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 17:29:46,796] {logging_mixin.py:104} INFO - [2021-08-16 17:29:46,794] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-16 17:29:46,798] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 17:29:46,815] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.458 seconds
[2021-08-16 17:30:17,320] {scheduler_job.py:182} INFO - Started process (PID=13234) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 17:30:17,321] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 17:30:17,321] {logging_mixin.py:104} INFO - [2021-08-16 17:30:17,321] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 17:30:17,788] {logging_mixin.py:104} INFO - [2021-08-16 17:30:17,786] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-16 17:30:17,790] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 17:30:17,801] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.483 seconds
[2021-08-16 17:30:48,402] {scheduler_job.py:182} INFO - Started process (PID=13300) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 17:30:48,403] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 17:30:48,403] {logging_mixin.py:104} INFO - [2021-08-16 17:30:48,403] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 17:30:48,828] {logging_mixin.py:104} INFO - [2021-08-16 17:30:48,826] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-16 17:30:48,831] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 17:30:48,841] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.442 seconds
[2021-08-16 17:31:19,435] {scheduler_job.py:182} INFO - Started process (PID=13363) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 17:31:19,439] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 17:31:19,440] {logging_mixin.py:104} INFO - [2021-08-16 17:31:19,440] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 17:31:19,858] {logging_mixin.py:104} INFO - [2021-08-16 17:31:19,857] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-16 17:31:19,861] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 17:31:19,872] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.438 seconds
[2021-08-16 17:31:50,665] {scheduler_job.py:182} INFO - Started process (PID=13430) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 17:31:50,666] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 17:31:50,666] {logging_mixin.py:104} INFO - [2021-08-16 17:31:50,666] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 17:31:51,079] {logging_mixin.py:104} INFO - [2021-08-16 17:31:51,078] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-16 17:31:51,082] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 17:31:51,094] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.431 seconds
[2021-08-16 17:32:21,870] {scheduler_job.py:182} INFO - Started process (PID=13496) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 17:32:21,871] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 17:32:21,872] {logging_mixin.py:104} INFO - [2021-08-16 17:32:21,871] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 17:32:22,303] {logging_mixin.py:104} INFO - [2021-08-16 17:32:22,301] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-16 17:32:22,305] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 17:32:22,316] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.448 seconds
[2021-08-16 17:32:53,062] {scheduler_job.py:182} INFO - Started process (PID=13562) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 17:32:53,063] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 17:32:53,063] {logging_mixin.py:104} INFO - [2021-08-16 17:32:53,063] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 17:32:53,752] {logging_mixin.py:104} INFO - [2021-08-16 17:32:53,750] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-16 17:32:53,754] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 17:32:53,764] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.704 seconds
[2021-08-16 17:33:24,153] {scheduler_job.py:182} INFO - Started process (PID=13625) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 17:33:24,154] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 17:33:24,154] {logging_mixin.py:104} INFO - [2021-08-16 17:33:24,154] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 17:33:24,622] {logging_mixin.py:104} INFO - [2021-08-16 17:33:24,621] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-16 17:33:24,625] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 17:33:24,642] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.491 seconds
[2021-08-16 17:33:55,344] {scheduler_job.py:182} INFO - Started process (PID=13690) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 17:33:55,345] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 17:33:55,346] {logging_mixin.py:104} INFO - [2021-08-16 17:33:55,346] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 17:33:55,777] {logging_mixin.py:104} INFO - [2021-08-16 17:33:55,776] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-16 17:33:55,780] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 17:33:55,791] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.448 seconds
[2021-08-16 17:34:25,825] {scheduler_job.py:182} INFO - Started process (PID=13759) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 17:34:25,830] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 17:34:25,831] {logging_mixin.py:104} INFO - [2021-08-16 17:34:25,831] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 17:34:26,267] {logging_mixin.py:104} INFO - [2021-08-16 17:34:26,265] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-16 17:34:26,270] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 17:34:26,280] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.457 seconds
[2021-08-16 17:34:57,117] {scheduler_job.py:182} INFO - Started process (PID=13825) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 17:34:57,118] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 17:34:57,119] {logging_mixin.py:104} INFO - [2021-08-16 17:34:57,119] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 17:34:57,594] {logging_mixin.py:104} INFO - [2021-08-16 17:34:57,592] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-16 17:34:57,596] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 17:34:57,606] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.492 seconds
[2021-08-16 17:35:27,646] {scheduler_job.py:182} INFO - Started process (PID=13898) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 17:35:27,647] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 17:35:27,648] {logging_mixin.py:104} INFO - [2021-08-16 17:35:27,648] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 17:35:28,080] {logging_mixin.py:104} INFO - [2021-08-16 17:35:28,079] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-16 17:35:28,083] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 17:35:28,101] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.456 seconds
[2021-08-16 17:35:58,978] {scheduler_job.py:182} INFO - Started process (PID=13963) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 17:35:58,979] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 17:35:58,980] {logging_mixin.py:104} INFO - [2021-08-16 17:35:58,980] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 17:35:59,419] {logging_mixin.py:104} INFO - [2021-08-16 17:35:59,417] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-16 17:35:59,422] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 17:35:59,435] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.459 seconds
[2021-08-16 17:36:30,157] {scheduler_job.py:182} INFO - Started process (PID=14030) to work on /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 17:36:30,158] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/create_dag_s3_upload.py for tasks to queue
[2021-08-16 17:36:30,159] {logging_mixin.py:104} INFO - [2021-08-16 17:36:30,159] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 17:36:30,872] {logging_mixin.py:104} INFO - [2021-08-16 17:36:30,871] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/create_dag_s3_upload.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 22, in <module>
    dag = upload_to_s3()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 2318, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/create_dag_s3_upload.py", line 16, in upload_to_s3
    with open("../data/data.csv", "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data.csv'
[2021-08-16 17:36:30,875] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/create_dag_s3_upload.py
[2021-08-16 17:36:30,886] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/create_dag_s3_upload.py took 0.731 seconds
